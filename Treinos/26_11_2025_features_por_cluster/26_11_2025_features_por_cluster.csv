treino_id,unique_id,ds,y,y_pred,diferença_%,flag,dataset,modelo,comentario,data_treino
V43_cluster_0_2020,Aguanil,2019-12-31T00:00:00,1.8000000000000005,2.3806407,32.25781917572019,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Alfenas,2019-12-31T00:00:00,1.7572173913043478,2.6057382,48.287751753936185,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Alto_Caparao,2019-12-31T00:00:00,1.32,1.6118504,22.10987734072136,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Alto_Jequitiba,2019-12-31T00:00:00,1.5,1.5586054,3.907028834025065,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Amparo_do_Serra,2019-12-31T00:00:00,1.260869565217391,1.5304953,21.38410888869191,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Araponga,2019-12-31T00:00:00,0.9,1.456948,61.88311576843262,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Astolfo_Dutra,2019-12-31T00:00:00,1.2,1.747104,45.592004060745246,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Bambui,2019-12-31T00:00:00,1.26,1.9116206,51.71592197720967,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Boa_Esperanca,2019-12-31T00:00:00,1.92,2.584329,34.60046301285426,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Bom_Jesus_do_Galho,2019-12-31T00:00:00,1.080232558139535,1.8181586,68.31177813116265,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Bom_Sucesso,2019-12-31T00:00:00,1.5,1.7508825,16.725500424702965,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Caete,2019-12-31T00:00:00,1.3125,1.7189809,30.96997397286551,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Caiana,2019-12-31T00:00:00,1.080049875311721,1.3534497,25.31362978698087,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Cajuri,2019-12-31T00:00:00,1.184993531694696,1.6123123,36.06085381653632,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Camacho,2019-12-31T00:00:00,1.5,2.1001606,40.01070658365886,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Campo_do_Meio,2019-12-31T00:00:00,1.619877049180328,2.5794625,59.23816746054834,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Campos_Altos,2019-12-31T00:00:00,1.199978657560559,2.1404743,78.37603243789233,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Campos_Gerais,2019-12-31T00:00:00,1.5913557213930347,2.6843288,68.68188289979396,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Cana_Verde,2019-12-31T00:00:00,1.2,1.5946512,32.887601852417,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Canaa,2019-12-31T00:00:00,1.26,1.5683572,24.4727959708562,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Candeias,2019-12-31T00:00:00,1.5,2.3166087,54.44057782491048,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Caparao,2019-12-31T00:00:00,1.32,1.6309152,23.55417916269013,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Capitolio,2019-12-31T00:00:00,1.500213219616205,1.8820119,25.449627146522968,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Caputira,2019-12-31T00:00:00,1.2,1.3296841,10.807011524836229,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Carangola,2019-12-31T00:00:00,1.26,1.4177133,12.516927340674023,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Caratinga,2019-12-31T00:00:00,0.9960199004975124,2.0712993,107.95762348365592,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Carmo_da_Mata,2019-12-31T00:00:00,1.080487804878049,1.4490402,34.10981298838455,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Carmo_do_Rio_Claro,2019-12-31T00:00:00,1.937142857142857,2.45938,26.959139970199907,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Carmopolis_de_Minas,2019-12-31T00:00:00,1.5,1.9507071,30.04713853200277,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Cassia,2019-12-31T00:00:00,1.563673469387755,2.1566327,37.92090893911962,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Catas_Altas_da_Noruega,2019-12-31T00:00:00,0.75,1.1024063,46.98750178019206,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Chale,2019-12-31T00:00:00,1.2,1.5795138,31.626149018605552,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Claudio,2019-12-31T00:00:00,1.44,1.5514481,7.73945185873244,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Conceicao_da_Barra_de_Minas,2019-12-31T00:00:00,1.6656441717791413,2.4911802,49.56256706631204,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Conceicao_de_Ipanema,2019-12-31T00:00:00,1.185699039487727,1.6338034,37.7924172326748,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Coqueiral,2019-12-31T00:00:00,1.5,1.9677252,31.18167718251546,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Corrego_Danta,2019-12-31T00:00:00,1.5,1.7824116,18.827438354492188,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Cristais,2019-12-31T00:00:00,1.739953810623557,2.5458636,46.317885730258304,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Desterro_de_Entre_Rios,2019-12-31T00:00:00,1.8000000000000005,3.0279756,68.22086440192327,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Divinesia,2019-12-31T00:00:00,2.0,3.8722482,93.61240863800052,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Divino,2019-12-31T00:00:00,1.079956453368816,1.400986,29.7261525519646,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Doresopolis,2019-12-31T00:00:00,1.7400000000000002,1.7947316,3.1454952283837203,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Durande,2019-12-31T00:00:00,1.32,2.0136938,52.5525613264604,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Eloi_Mendes,2019-12-31T00:00:00,1.5,2.3330045,55.53363164265951,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Entre_Folhas,2019-12-31T00:00:00,0.8400000000000001,1.1943182,42.180735156649625,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Entre_Rios_de_Minas,2019-12-31T00:00:00,1.921428571428572,2.678199,39.38582430984896,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ervalia,2019-12-31T00:00:00,1.199920191540303,1.8306332,52.56291013006601,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Espera_Feliz,2019-12-31T00:00:00,0.9,1.7380321,93.11467806498209,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Faria_Lemos,2019-12-31T00:00:00,1.0796875,1.2859617,19.104995396306315,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ferros,2019-12-31T00:00:00,0.8363636363636363,1.2223817,46.15433501160664,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Fervedouro,2019-12-31T00:00:00,1.079947575360419,1.3080715,21.123610436916387,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Guape,2019-12-31T00:00:00,1.6177358490566045,2.2705834,40.35563299865576,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ibituruna,2019-12-31T00:00:00,1.6599999999999997,1.8195659,9.61240314575565,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ilicinea,2019-12-31T00:00:00,1.8601303639326447,2.7888253,49.92633460472759,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Itapecerica,2019-12-31T00:00:00,1.2,2.1724675,81.03895584742229,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ituiutaba,2019-12-31T00:00:00,1.076923076923077,1.7493846,62.44285958153858,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Itumirim,2019-12-31T00:00:00,1.601593625498008,1.711981,6.892349648831486,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Lajinha,2019-12-31T00:00:00,1.055939660590823,1.746919,65.4373920318627,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Lavras,2019-12-31T00:00:00,1.5,2.112709,40.84726969401042,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Luisburgo,2019-12-31T00:00:00,1.6399999999999997,1.6223164,-1.0782707028272482,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Machado,2019-12-31T00:00:00,1.5270920664493093,2.0888085,36.783405691203455,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Manhuacu,2019-12-31T00:00:00,1.019980879541109,1.4290836,40.10886031335046,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Manhumirim,2019-12-31T00:00:00,1.2,1.7198176,43.3181365331014,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Martins_Soares,2019-12-31T00:00:00,1.6199186991869925,1.7861593,10.262279079729195,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Matipo,2019-12-31T00:00:00,1.32,1.36887,3.7022742358120952,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Medeiros,2019-12-31T00:00:00,1.199936224489796,2.1654334,80.46237480250755,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Miradouro,2019-12-31T00:00:00,1.32,1.7448804,32.18791195840546,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Mirai,2019-12-31T00:00:00,1.2,1.2191026,1.5918850898742714,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Moeda,2019-12-31T00:00:00,1.0,1.7798992,77.98992395401001,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Muriae,2019-12-31T00:00:00,1.02054794520548,1.5702479,53.8632159265095,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Mutum,2019-12-31T00:00:00,1.4430666666666667,1.5390358,6.65036014407793,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Nazareno,2019-12-31T00:00:00,1.680203045685279,1.9205657,14.305573323702175,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Nepomuceno,2019-12-31T00:00:00,1.5,1.9253576,28.3571720123291,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Oliveira,2019-12-31T00:00:00,1.56,1.8027058,15.55806184426332,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Orizania,2019-12-31T00:00:00,1.379912663755459,1.6292143,18.066478379165023,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Paraguacu,2019-12-31T00:00:00,1.5599709934735322,2.247857,44.09608276150131,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Passa_Tempo,2019-12-31T00:00:00,1.5,1.8752513,25.01675287882487,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Perdoes,2019-12-31T00:00:00,1.7399328859060397,1.9714872,13.308230476416218,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Pimenta,2019-12-31T00:00:00,1.5,2.497871,66.52472813924155,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Piranga,2019-12-31T00:00:00,2.1,2.2405903,6.69477780659993,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Piumhi,2019-12-31T00:00:00,1.3199752300070773,1.9399999,46.97245023308261,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ponte_Nova,2019-12-31T00:00:00,1.166666666666667,1.5127604,29.66517720903666,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Porto_Firme,2019-12-31T00:00:00,1.119607843137255,1.2898965,15.209668822547387,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Raul_Soares,2019-12-31T00:00:00,1.2,1.2350291,2.919091780980432,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Reduto,2019-12-31T00:00:00,1.259851301115242,1.607242,27.57394358836712,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ribeirao_Vermelho,2019-12-31T00:00:00,1.5,1.7653131,17.68754323323568,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ritapolis,2019-12-31T00:00:00,1.8008849557522122,1.8571458,3.124065774078756,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Rosario_da_Limeira,2019-12-31T00:00:00,1.2,1.412579,17.71492163340251,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santa_Barbara_do_Leste,2019-12-31T00:00:00,1.139892904953146,1.5576463,36.64847529081476,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santa_Margarida,2019-12-31T00:00:00,1.2,1.5420492,28.504097461700447,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santa_Rita_de_Minas,2019-12-31T00:00:00,1.26,1.6014435,27.09869278801812,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santa_Rita_do_Itueto,2019-12-31T00:00:00,1.649769585253456,1.4209018,-13.872713616440402,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santana_da_Vargem,2019-12-31T00:00:00,1.7999440402909912,2.2300065,23.893099255163737,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santana_do_Jacare,2019-12-31T00:00:00,1.2,1.86896,55.74666857719423,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santana_do_Manhuacu,2019-12-31T00:00:00,1.5,1.5314243,2.0949522654215498,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Domingos_das_Dores,2019-12-31T00:00:00,1.296118830857691,1.8934262,46.0843045257596,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Francisco_de_Paula,2019-12-31T00:00:00,1.6399999999999997,1.8468182,12.610866383808435,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Francisco_do_Gloria,2019-12-31T00:00:00,0.9,1.4310006,59.000065591600205,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Joao_do_Manhuacu,2019-12-31T00:00:00,1.320060560181681,1.6043763,21.53808427165985,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Jose_do_Mantimento,2019-12-31T00:00:00,1.56039603960396,1.4348903,-8.043199686834631,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Roque_de_Minas,2019-12-31T00:00:00,1.5000955109837628,1.7337482,15.575853994693292,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Tiago,2019-12-31T00:00:00,1.679886685552408,2.5384712,51.10966970305418,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Tomas_de_Aquino,2019-12-31T00:00:00,1.560034623469766,2.3857608,52.9299893897776,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Senador_Firmino,2019-12-31T00:00:00,1.32258064516129,2.2931576,73.38508512915638,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Senhora_de_Oliveira,2019-12-31T00:00:00,1.6625,1.8988645,14.217413995498996,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sericita,2019-12-31T00:00:00,0.9,1.5145705,68.28560829162598,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Simonesia,2019-12-31T00:00:00,1.32,1.4154737,7.232856028007734,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Tapirai,2019-12-31T00:00:00,1.679835390946502,1.8945181,12.779987086156376,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Tombos,2019-12-31T00:00:00,0.96,1.3237951,37.89532085259758,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Tres_Pontas,2019-12-31T00:00:00,1.7400000000000002,2.5128198,44.4149291378328,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ubaporanga,2019-12-31T00:00:00,1.320030895983522,1.5504546,17.455933892473467,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Vargem_Bonita,2019-12-31T00:00:00,2.1,2.4911144,18.6244941893078,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Vermelho_Novo,2019-12-31T00:00:00,1.079912663755459,1.4017406,29.801288385695823,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Vicosa,2019-12-31T00:00:00,0.8395833333333333,1.6194788,92.89077777720564,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Vieiras,2019-12-31T00:00:00,1.019736842105263,1.5707331,54.03317851404992,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Aguanil,2020-12-31T00:00:00,2.1644859813084114,2.6053479,20.367971623705653,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Alfenas,2020-12-31T00:00:00,2.364130434782609,2.574504,8.898555711768132,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Alto_Caparao,2020-12-31T00:00:00,1.92,1.5104231,-21.33213207125664,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Alto_Jequitiba,2020-12-31T00:00:00,1.8000000000000005,1.5700037,-12.777569558885377,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Amparo_do_Serra,2020-12-31T00:00:00,1.4392156862745098,1.5900834,10.482631327345846,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Araponga,2020-12-31T00:00:00,1.8000000000000005,1.3947803,-22.51220676634048,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Astolfo_Dutra,2020-12-31T00:00:00,1.75,1.8059381,3.196464266095843,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Bambui,2020-12-31T00:00:00,1.7998829724985372,1.8648643,3.610311217983921,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Boa_Esperanca,2020-12-31T00:00:00,2.063248407643312,2.7218707,31.92161693660731,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Bom_Jesus_do_Galho,2020-12-31T00:00:00,1.44,1.6957811,17.76257720258501,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Bom_Sucesso,2020-12-31T00:00:00,2.1,1.7155259,-18.308292116437645,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Caete,2020-12-31T00:00:00,1.2,1.6962669,41.35557413101197,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Caiana,2020-12-31T00:00:00,1.5,1.3307011,-11.286592483520508,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Cajuri,2020-12-31T00:00:00,1.8000000000000005,1.6893137,-6.14924165937637,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Camacho,2020-12-31T00:00:00,2.1,2.481152,18.150097983224043,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Campo_do_Meio,2020-12-31T00:00:00,2.4,2.6730194,11.375808715820316,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Campos_Altos,2020-12-31T00:00:00,2.1000529941706416,2.0980728,-0.0942941401216032,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Campos_Gerais,2020-12-31T00:00:00,2.690649114843395,2.5887542,-3.787002072762641,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Cana_Verde,2020-12-31T00:00:00,1.5,1.4855254,-0.964975357055664,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Canaa,2020-12-31T00:00:00,1.8000000000000005,1.6481102,-8.438324928283706,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Candeias,2020-12-31T00:00:00,1.859937013094646,2.4403691,31.207084541025043,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Caparao,2020-12-31T00:00:00,1.9199600798403191,1.6589336,-13.595409772043864,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Capitolio,2020-12-31T00:00:00,2.1,1.9063364,-9.22207491738456,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Caputira,2020-12-31T00:00:00,1.8000000000000005,1.2847645,-28.624192873636893,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Carangola,2020-12-31T00:00:00,1.5,1.4929267,-0.4715522130330403,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Caratinga,2020-12-31T00:00:00,2.040022111663903,1.9132625,-6.213639767987091,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Carmo_da_Mata,2020-12-31T00:00:00,1.68,1.4237204,-15.254740487961538,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Carmo_do_Rio_Claro,2020-12-31T00:00:00,2.7847803881511743,2.5407186,-8.764132128306477,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Carmopolis_de_Minas,2020-12-31T00:00:00,1.981818181818182,1.9695255,-0.6202751343403441,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Cassia,2020-12-31T00:00:00,2.1679245283018864,2.2648404,4.470443269083889,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Catas_Altas_da_Noruega,2020-12-31T00:00:00,1.0,1.0678782,6.787824630737305,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Chale,2020-12-31T00:00:00,1.71015625,1.4312071,-16.311327645418146,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Claudio,2020-12-31T00:00:00,2.76,1.7156398,-37.83913660740507,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Conceicao_da_Barra_de_Minas,2020-12-31T00:00:00,1.911042944785276,2.5214324,31.9401223625073,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Conceicao_de_Ipanema,2020-12-31T00:00:00,1.500533617929563,1.622653,8.138397441988781,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Coqueiral,2020-12-31T00:00:00,2.160028248587571,1.9237406,-10.939098753019008,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Corrego_Danta,2020-12-31T00:00:00,1.8000000000000005,1.8046744,0.2596881654527304,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Cristais,2020-12-31T00:00:00,1.92,2.7909498,45.361969868342086,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Desterro_de_Entre_Rios,2020-12-31T00:00:00,2.4,2.4846964,3.5290161768595416,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Divinesia,2020-12-31T00:00:00,2.1,3.6031415,71.57816886901854,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Divino,2020-12-31T00:00:00,1.8000483851457605,1.3543938,-24.7579203418775,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Doresopolis,2020-12-31T00:00:00,1.8000000000000005,1.9861333,10.340740945604097,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Durande,2020-12-31T00:00:00,2.4,1.836111,-23.495377103487648,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Eloi_Mendes,2020-12-31T00:00:00,2.109128416709644,2.2316504,5.809126404902576,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Entre_Folhas,2020-12-31T00:00:00,1.26046511627907,1.1771786,-6.6076001557916975,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Entre_Rios_de_Minas,2020-12-31T00:00:00,1.8000000000000005,2.4821143,37.89523972405326,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ervalia,2020-12-31T00:00:00,1.7999614197530858,1.7547725,-2.510546912284328,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Espera_Feliz,2020-12-31T00:00:00,2.04,1.5637344,-23.346352343465767,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Faria_Lemos,2020-12-31T00:00:00,1.44031007751938,1.2961562,-10.008533008645257,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ferros,2020-12-31T00:00:00,1.2,1.055772,-12.019004424413042,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Fervedouro,2020-12-31T00:00:00,1.5,1.2537776,-16.414825121561684,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Guape,2020-12-31T00:00:00,1.847986942328618,2.255484,22.050868028017327,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ibituruna,2020-12-31T00:00:00,1.8000000000000005,1.7441288,-3.1039542622036547,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ilicinea,2020-12-31T00:00:00,2.09995817649519,2.8639135,36.379551179996426,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Itapecerica,2020-12-31T00:00:00,1.8000000000000005,2.1157193,17.53996213277179,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ituiutaba,2020-12-31T00:00:00,0.75,1.7718594,136.24792098999023,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Itumirim,2020-12-31T00:00:00,2.050724637681159,1.6945138,-17.369998554458878,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Lajinha,2020-12-31T00:00:00,1.9200446677833607,1.5548949,-19.017773375090165,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Lavras,2020-12-31T00:00:00,1.8000000000000005,1.8753397,4.185541470845525,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Luisburgo,2020-12-31T00:00:00,2.1,1.7467101,-16.823330379667738,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Machado,2020-12-31T00:00:00,2.211839166046165,1.8943528,-14.353953814831586,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Manhuacu,2020-12-31T00:00:00,1.6800182481751822,1.4159367,-15.718968529758968,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Manhumirim,2020-12-31T00:00:00,1.68,1.5766319,-6.152862878072826,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Martins_Soares,2020-12-31T00:00:00,1.8000000000000005,1.7141817,-4.767685466342516,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Matipo,2020-12-31T00:00:00,1.56,1.3773997,-11.705148525727104,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Medeiros,2020-12-31T00:00:00,1.980113636363636,2.2197928,12.10431573722766,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Miradouro,2020-12-31T00:00:00,1.5,1.5300554,2.0036935806274414,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Mirai,2020-12-31T00:00:00,1.5011494252873558,1.2954687,-13.701549879807216,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Moeda,2020-12-31T00:00:00,1.2,1.8177867,51.48222446441652,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Muriae,2020-12-31T00:00:00,1.56,1.4672855,-5.943236289880218,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Mutum,2020-12-31T00:00:00,1.65,1.6075408,-2.5732820684259536,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Nazareno,2020-12-31T00:00:00,2.1,1.9363699,-7.791909717378166,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Nepomuceno,2020-12-31T00:00:00,1.920040743570155,1.8433597,-3.993719145853242,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Oliveira,2020-12-31T00:00:00,1.947151898734177,1.9981745,2.620373348792215,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Orizania,2020-12-31T00:00:00,1.679901960784314,1.6517653,-1.6748962090667434,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Paraguacu,2020-12-31T00:00:00,2.3413259668508286,2.2095647,-5.627635062131878,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Passa_Tempo,2020-12-31T00:00:00,1.511111111111111,1.8724985,23.915342723622047,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Perdoes,2020-12-31T00:00:00,1.92,1.9131271,-0.3579653799533807,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Pimenta,2020-12-31T00:00:00,1.8000000000000005,2.4522722,36.23734315236408,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Piranga,2020-12-31T00:00:00,2.4,2.749824,14.576001962025964,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Piumhi,2020-12-31T00:00:00,1.7399966931216928,1.9060718,9.544563483765984,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ponte_Nova,2020-12-31T00:00:00,1.333333333333333,1.4534684,9.010133147239708,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Porto_Firme,2020-12-31T00:00:00,1.56,1.2616025,-19.12804352931488,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Raul_Soares,2020-12-31T00:00:00,1.320083682008368,1.3107748,-0.7051733896584744,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Reduto,2020-12-31T00:00:00,1.8000000000000005,1.6273074,-9.594032499525296,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ribeirao_Vermelho,2020-12-31T00:00:00,1.92,1.6979651,-11.564315358797703,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ritapolis,2020-12-31T00:00:00,2.101769911504425,1.9069259,-9.2704721751966,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Rosario_da_Limeira,2020-12-31T00:00:00,1.5,1.3544781,-9.7014586130778,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santa_Barbara_do_Leste,2020-12-31T00:00:00,1.4400953029271608,1.554505,7.944591404331781,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santa_Margarida,2020-12-31T00:00:00,1.8000000000000005,1.5003564,-16.646864679124633,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santa_Rita_de_Minas,2020-12-31T00:00:00,1.5,1.5785193,5.234622955322266,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santa_Rita_do_Itueto,2020-12-31T00:00:00,1.77,1.6740948,-5.418373097134176,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santana_da_Vargem,2020-12-31T00:00:00,2.22,2.3232584,4.651279277629692,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santana_do_Jacare,2020-12-31T00:00:00,1.8000000000000005,1.6698194,-7.232258054945218,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Santana_do_Manhuacu,2020-12-31T00:00:00,1.8000000000000005,1.561725,-13.237498866187211,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Domingos_das_Dores,2020-12-31T00:00:00,1.56,1.831885,17.4285243719052,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Francisco_de_Paula,2020-12-31T00:00:00,1.62,2.180882,34.6223442642777,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Francisco_do_Gloria,2020-12-31T00:00:00,1.679693486590038,1.3549938,-19.330887985925585,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Joao_do_Manhuacu,2020-12-31T00:00:00,1.8000000000000005,1.6376071,-9.021827909681546,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Jose_do_Mantimento,2020-12-31T00:00:00,1.8000000000000005,1.5599587,-13.335627979702434,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Roque_de_Minas,2020-12-31T00:00:00,1.8000000000000005,1.8119701,0.665006372663695,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Tiago,2020-12-31T00:00:00,2.69971671388102,2.542323,-5.830004332823627,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sao_Tomas_de_Aquino,2020-12-31T00:00:00,2.099966151415999,2.5186088,19.93568595470779,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Senador_Firmino,2020-12-31T00:00:00,1.376237623762376,2.203817,60.13345752688621,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Senhora_de_Oliveira,2020-12-31T00:00:00,1.8000000000000005,2.2041354,22.45196766323512,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Sericita,2020-12-31T00:00:00,2.5200000000000005,1.4973726,-40.58045129927379,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Simonesia,2020-12-31T00:00:00,1.8000000000000005,1.3465633,-25.190925598144545,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Tapirai,2020-12-31T00:00:00,1.799716914366596,1.8689344,3.846020338528735,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Tombos,2020-12-31T00:00:00,1.5,1.2782882,-14.780783653259276,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Tres_Pontas,2020-12-31T00:00:00,2.26,2.6193898,15.902202319254927,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Ubaporanga,2020-12-31T00:00:00,1.6200873362445412,1.5142065,-6.535499982756726,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Vargem_Bonita,2020-12-31T00:00:00,1.8031222896790973,2.8597536,58.60009191126824,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Vermelho_Novo,2020-12-31T00:00:00,1.320080321285141,1.3920946,5.455296141853906,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Vicosa,2020-12-31T00:00:00,1.8000000000000005,1.6095638,-10.579787360297322,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_0_2020,Vieiras,2020-12-31T00:00:00,1.8000000000000005,1.3665152,-24.082491132948142,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:25
V43_cluster_1_2020,Almenara,2019-12-31T00:00:00,0.7857142857142858,1.3569377660751345,72.70117022774434,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Alpinopolis,2019-12-31T00:00:00,2.1000392310710083,2.3376657962799072,11.315339337147082,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Alterosa,2019-12-31T00:00:00,1.739944346066279,1.7535524368286133,0.7820991972013346,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Andradas,2019-12-31T00:00:00,1.62,1.6191093921661377,-0.054975792213729,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Araguari,2019-12-31T00:00:00,1.680014528284754,2.892338275909424,72.16150379737591,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Arapua,2019-12-31T00:00:00,1.2,1.682241439819336,40.186786651611335,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Araxa,2019-12-31T00:00:00,1.387894736842105,2.003191471099853,44.33309803146463,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Arceburgo,2019-12-31T00:00:00,1.5,1.6949275732040403,12.995171546936035,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Areado,2019-12-31T00:00:00,1.9231597845601445,1.641707181930542,-14.634904748383915,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Bom_Jesus_da_Penha,2019-12-31T00:00:00,2.219967266775777,2.055363416671753,-7.414697169976316,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Botelhos,2019-12-31T00:00:00,1.92,1.7006478309631348,-11.424592137336727,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Botumirim,2019-12-31T00:00:00,0.7199999999999999,1.1708699464797974,62.62082589997189,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Cabo_Verde,2019-12-31T00:00:00,2.040029112081514,1.7561886310577393,-13.913550514686634,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Campestre,2019-12-31T00:00:00,1.5499999999999998,1.5873621702194214,2.410462594801392,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Capetinga,2019-12-31T00:00:00,2.04,2.0639026165008545,1.171696887296787,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Carmo_do_Paranaiba,2019-12-31T00:00:00,1.793633952254642,2.064271211624145,15.0887676400921,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Cascalho_Rico,2019-12-31T00:00:00,1.8000000000000005,2.1467318534851074,19.262880749172616,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Claraval,2019-12-31T00:00:00,1.680106729914023,2.082918643951416,23.9753764963495,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Conceicao_da_Aparecida,2019-12-31T00:00:00,1.968025889967637,2.04067325592041,3.691382634908718,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Coromandel,2019-12-31T00:00:00,1.6463414634146338,2.593918561935425,57.55653487311472,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Corrego_Fundo,2019-12-31T00:00:00,1.804347826086957,2.884244918823242,59.84971839261338,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Cruzeiro_da_Fortaleza,2019-12-31T00:00:00,1.5,2.293956995010376,52.93046633402506,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Delfinopolis,2019-12-31T00:00:00,1.558823529411765,1.4984536170959473,-3.872786827807171,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Divisa_Nova,2019-12-31T00:00:00,1.799757281553398,1.534938097000122,-14.714161029797664,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Dom_Cavati,2019-12-31T00:00:00,0.7826086956521741,1.2171950340270996,55.53047657012936,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Dores_do_Turvo,2019-12-31T00:00:00,1.5,1.111319899559021,-25.912006696065266,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Estrela_do_Indaia,2019-12-31T00:00:00,1.62,1.830410718917847,12.98831598258312,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Estrela_do_Sul,2019-12-31T00:00:00,1.679876706296786,2.617979049682617,55.84352350797436,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Guaranesia,2019-12-31T00:00:00,1.260049474335189,2.034004211425781,61.422567355852095,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Guarani,2019-12-31T00:00:00,1.8000000000000005,2.407235145568848,33.73528586493596,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Guarda-Mor,2019-12-31T00:00:00,1.7992125984251972,2.228936195373535,23.883981099535628,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Guaxupe,2019-12-31T00:00:00,1.32,1.631237506866455,23.57859900503447,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Guimarania,2019-12-31T00:00:00,1.560154738878143,1.7674810886383057,13.288832485247228,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Ibia,2019-12-31T00:00:00,1.199972848221559,1.842468738555908,53.54253567375058,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Ibiraci,2019-12-31T00:00:00,1.283972495924009,2.6710307598114014,108.0286585803536,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Indianopolis,2019-12-31T00:00:00,1.8000000000000005,2.616300106048584,45.35000589158798,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Itamogi,2019-12-31T00:00:00,1.849947396107312,1.947937250137329,5.296899481369526,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Itanhomi,2019-12-31T00:00:00,0.96,1.391327142715454,44.929910699526495,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Jacui,2019-12-31T00:00:00,1.68,1.920559883117676,14.31904066176642,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Jacutinga,2019-12-31T00:00:00,1.6801232665639447,1.5105478763580322,-10.09303267091317,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Juruaia,2019-12-31T00:00:00,1.68,1.8394780158996584,9.492739041646326,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Lagoa_Dourada,2019-12-31T00:00:00,2.7000000000000006,2.420939922332764,-10.335558432119884,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Lagoa_Formosa,2019-12-31T00:00:00,2.25,2.0440893173217773,-9.151585896809896,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Lagoa_Grande,2019-12-31T00:00:00,1.2,2.798880100250244,133.240008354187,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Matutina,2019-12-31T00:00:00,1.8000000000000005,1.8578253984451287,3.2125221358405067,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Monte_Belo,2019-12-31T00:00:00,1.640077821011673,1.6642855405807495,1.476010422123995,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Monte_Carmelo,2019-12-31T00:00:00,1.6200304645849195,2.8588995933532715,76.47196493220095,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Monte_Santo_de_Minas,2019-12-31T00:00:00,1.589970501474926,1.6604512929916382,4.432836423778365,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Muzambinho,2019-12-31T00:00:00,2.1,1.5482020378112793,-26.27609343755813,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Nova_Resende,2019-12-31T00:00:00,2.1150040551500404,1.9246200323104856,-9.00159138588737,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Passos,2019-12-31T00:00:00,1.56,2.499682664871216,60.23606826097537,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Patis,2019-12-31T00:00:00,3.0,5.052216529846191,68.4072176615397,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Patos_de_Minas,2019-12-31T00:00:00,1.62,1.8440587520599363,13.830787164193604,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Patrocinio,2019-12-31T00:00:00,1.384841075794621,2.735252141952514,97.51379344254563,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Pedrinopolis,2019-12-31T00:00:00,1.5,1.596137762069702,6.409184137980144,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Perdizes,2019-12-31T00:00:00,1.199035812672176,2.1812071800231934,81.91343052232494,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Piracema,2019-12-31T00:00:00,1.166666666666667,1.5815244913101196,35.559242112295934,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Ponto_dos_Volantes,2019-12-31T00:00:00,0.6000000000000001,1.0072911977767944,67.88186629613237,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Pratapolis,2019-12-31T00:00:00,1.738461538461539,2.4391610622406006,40.30572481914955,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Pratinha,2019-12-31T00:00:00,1.7400000000000002,1.6580407619476318,-4.710301037492435,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Presidente_Kubitschek,2019-12-31T00:00:00,1.315789473684211,2.037059545516968,54.81652545928949,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Presidente_Olegario,2019-12-31T00:00:00,1.8693227091633469,2.2712957859039307,21.50367482137393,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Quartel_Geral,2019-12-31T00:00:00,3.0,4.403886318206787,46.7962106068929,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Rio_Paranaiba,2019-12-31T00:00:00,1.142998097117485,1.899174213409424,66.1572506725017,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Rio_Vermelho,2019-12-31T00:00:00,1.2,1.227612018585205,2.301001548767094,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Romaria,2019-12-31T00:00:00,2.2,2.18326997756958,-0.7604555650190954,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sacramento,2019-12-31T00:00:00,1.231428571428572,1.6073346138000488,30.52601272158163,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Santa_Rosa_da_Serra,2019-12-31T00:00:00,1.44,2.0194408893585205,40.23895064989726,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Santo_Antonio_do_Amparo,2019-12-31T00:00:00,1.639983909895414,2.1327121257781982,30.044698177203863,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sao_Goncalo_do_Abaete,2019-12-31T00:00:00,1.92,2.4155187606811523,25.80826878547669,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sao_Gotardo,2019-12-31T00:00:00,1.379944289693593,1.8365731239318848,33.090381810970285,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sao_Joao_Batista_do_Gloria,2019-12-31T00:00:00,1.68,1.798887848854065,7.076657669884821,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sao_Pedro_da_Uniao,2019-12-31T00:00:00,1.62,1.98926043510437,22.79385401878827,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sao_Sebastiao_do_Paraiso,2019-12-31T00:00:00,1.470008496176721,1.6333296298980713,11.11021699167895,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Serra_do_Salitre,2019-12-31T00:00:00,1.4904255319148938,2.0910472869873047,40.29867592919816,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Tapira,2019-12-31T00:00:00,1.8000000000000005,2.0973494052886963,16.519411404927553,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Tiros,2019-12-31T00:00:00,1.5,2.372698307037353,58.17988713582357,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Tupaciguara,2019-12-31T00:00:00,2.4,2.340194702148437,-2.4918874104817674,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Uberaba,2019-12-31T00:00:00,2.476744186046512,1.8974369764328003,-23.389868557173337,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Uberlandia,2019-12-31T00:00:00,2.015625,2.2790868282318115,13.070974423903827,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Unai,2019-12-31T00:00:00,2.819938392607113,2.793637752532959,-0.9326671867408574,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Varginha,2019-12-31T00:00:00,1.5600442722744878,1.6218565702438354,3.962214346598481,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Varjao_de_Minas,2019-12-31T00:00:00,2.494512195121952,2.491351127624512,-0.1267208676558532,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Virginopolis,2019-12-31T00:00:00,1.5066666666666668,1.2842087745666504,-14.764904342921442,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Almenara,2020-12-31T00:00:00,0.78,1.428519368171692,83.1435087399605,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Alpinopolis,2020-12-31T00:00:00,2.765998457979954,2.556339263916016,-7.579873859259322,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Alterosa,2020-12-31T00:00:00,1.980023501762632,2.292104005813598,15.761454536936077,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Andradas,2020-12-31T00:00:00,2.568,1.5860447883605957,-38.238131294369325,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Araguari,2020-12-31T00:00:00,1.979964695498676,2.743356943130493,38.5558514940868,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Arapua,2020-12-31T00:00:00,1.5,1.597216010093689,6.481067339579265,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Araxa,2020-12-31T00:00:00,1.786008230452675,1.956467032432556,9.54412186200717,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Arceburgo,2020-12-31T00:00:00,1.8387096774193543,2.119676351547241,15.280643680639452,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Areado,2020-12-31T00:00:00,2.078746484531941,2.0736653804779053,-0.2444311555951857,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Bom_Jesus_da_Penha,2020-12-31T00:00:00,1.986087924318308,2.307565927505493,16.18649402430295,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Botelhos,2020-12-31T00:00:00,1.716062736614386,2.4265120029449463,41.399958822729474,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Botumirim,2020-12-31T00:00:00,0.9200000000000002,0.9749127626419068,5.968778548033324,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Cabo_Verde,2020-12-31T00:00:00,2.249052581714827,1.83519184589386,-18.401558913549813,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Campestre,2020-12-31T00:00:00,2.138000770416025,1.7658066749572754,-17.408510820429964,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Capetinga,2020-12-31T00:00:00,2.213808463251671,2.759223937988281,24.63697667572816,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Carmo_do_Paranaiba,2020-12-31T00:00:00,1.947480785653288,2.079303741455078,6.768896349217118,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Cascalho_Rico,2020-12-31T00:00:00,2.478504672897196,2.1503374576568604,-13.24053243993812,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Claraval,2020-12-31T00:00:00,2.796008294453085,3.20692777633667,14.696647456260962,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Conceicao_da_Aparecida,2020-12-31T00:00:00,2.243948871362524,2.138814926147461,-4.685220173988447,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Coromandel,2020-12-31T00:00:00,1.818934240362812,2.1046221256256104,15.706333902748154,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Corrego_Fundo,2020-12-31T00:00:00,1.5,2.580917358398437,72.0611572265625,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Cruzeiro_da_Fortaleza,2020-12-31T00:00:00,2.1,2.0682573318481445,-1.511555626278836,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Delfinopolis,2020-12-31T00:00:00,1.8000000000000005,1.8388643264770508,2.159129248725028,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Divisa_Nova,2020-12-31T00:00:00,1.8000000000000005,2.280259609222412,26.6810894012451,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Dom_Cavati,2020-12-31T00:00:00,0.7894736842105263,1.6299619674682615,106.46184921264648,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Dores_do_Turvo,2020-12-31T00:00:00,1.625,1.1699721813201904,-28.00171191875751,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Estrela_do_Indaia,2020-12-31T00:00:00,1.8000000000000005,1.95956027507782,8.86445972654553,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Estrela_do_Sul,2020-12-31T00:00:00,2.0627027027027025,2.240647792816162,8.626792890720658,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Guaranesia,2020-12-31T00:00:00,1.564686285397002,2.100790500640869,34.26272858957432,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Guarani,2020-12-31T00:00:00,1.127272727272727,2.24378514289856,99.04545622487228,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Guarda-Mor,2020-12-31T00:00:00,1.7994350282485878,2.0803351402282715,15.61046148207347,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Guaxupe,2020-12-31T00:00:00,1.7400000000000002,1.6220271587371826,-6.780048348437792,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Guimarania,2020-12-31T00:00:00,2.149930843706777,1.7951693534851074,-16.501065197521037,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Ibia,2020-12-31T00:00:00,1.746,1.91414475440979,9.630283757719932,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Ibiraci,2020-12-31T00:00:00,2.6315194346289745,2.756007194519043,4.730641858536011,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Indianopolis,2020-12-31T00:00:00,1.8000000000000005,3.13806676864624,74.33704270256888,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Itamogi,2020-12-31T00:00:00,2.400049176297025,2.2204430103302,-7.483436912069222,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Itanhomi,2020-12-31T00:00:00,1.26,1.6630572080612185,31.98866730644589,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Jacui,2020-12-31T00:00:00,1.68,1.9107367992401123,13.734333288101928,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Jacutinga,2020-12-31T00:00:00,1.8000000000000005,1.8717055320739744,3.983640670776352,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Juruaia,2020-12-31T00:00:00,1.92,1.8456567525863647,-3.8720441361268327,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Lagoa_Dourada,2020-12-31T00:00:00,2.1,2.185454130172729,4.069244293939495,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Lagoa_Formosa,2020-12-31T00:00:00,2.5494505494505484,2.0919971466064453,-17.94321537017819,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Lagoa_Grande,2020-12-31T00:00:00,2.4,2.60438871383667,8.516196409861251,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Matutina,2020-12-31T00:00:00,1.82995951417004,2.024505138397217,10.63114362480368,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Monte_Belo,2020-12-31T00:00:00,1.8000000000000005,2.1171765327453613,17.62091848585339,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Monte_Carmelo,2020-12-31T00:00:00,1.98,2.78605318069458,40.709756600736384,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Monte_Santo_de_Minas,2020-12-31T00:00:00,2.123987903619159,2.093224048614502,-1.4484006689603666,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Muzambinho,2020-12-31T00:00:00,1.764006791171477,2.03383207321167,15.296158914501795,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Nova_Resende,2020-12-31T00:00:00,2.353040067245727,1.9881805181503296,-15.50587914648098,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Passos,2020-12-31T00:00:00,1.62,2.644775867462158,63.25776959642951,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Patis,2020-12-31T00:00:00,3.6000000000000005,5.322327136993408,47.842420472039095,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Patos_de_Minas,2020-12-31T00:00:00,1.941759465478842,1.875825047492981,-3.395601729156572,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Patrocinio,2020-12-31T00:00:00,1.7479986236953782,2.248984336853028,28.66053247219006,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Pedrinopolis,2020-12-31T00:00:00,2.158490566037736,2.63107705116272,21.894303943727405,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Perdizes,2020-12-31T00:00:00,2.050845253576073,2.5361385345458984,23.66308623839933,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Piracema,2020-12-31T00:00:00,1.333333333333333,1.3424487113952637,0.6836533546447978,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Ponto_dos_Volantes,2020-12-31T00:00:00,0.631578947368421,0.7630486488342285,20.81603606541952,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Pratapolis,2020-12-31T00:00:00,2.402298850574712,2.018826961517334,-15.96270542966118,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Pratinha,2020-12-31T00:00:00,2.1,1.7190152406692505,-18.14213139670236,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Presidente_Kubitschek,2020-12-31T00:00:00,1.789473684210526,1.397333025932312,-21.913742668488435,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Presidente_Olegario,2020-12-31T00:00:00,1.9814229249011863,2.154977798461914,8.759102934542998,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Quartel_Geral,2020-12-31T00:00:00,3.6000000000000005,5.21827507019043,44.95208528306748,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Rio_Paranaiba,2020-12-31T00:00:00,1.818897637795276,1.7899467945098877,-1.5916697390667978,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Rio_Vermelho,2020-12-31T00:00:00,0.9333333333333332,1.1704646348953247,25.40692516735625,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Romaria,2020-12-31T00:00:00,2.330769230769231,2.856032609939575,22.53605257166493,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sacramento,2020-12-31T00:00:00,1.8321428571428573,1.95137906074524,6.508018910071529,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Santa_Rosa_da_Serra,2020-12-31T00:00:00,2.1,1.7491230964660645,-16.708423977806458,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Santo_Antonio_do_Amparo,2020-12-31T00:00:00,2.1,2.262460708618164,7.73622421991257,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sao_Goncalo_do_Abaete,2020-12-31T00:00:00,2.44,2.316751480102539,-5.0511688482565935,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sao_Gotardo,2020-12-31T00:00:00,1.38027397260274,1.7969322204589844,30.186633677556408,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sao_Joao_Batista_do_Gloria,2020-12-31T00:00:00,1.5,2.0905747413635254,39.37164942423503,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sao_Pedro_da_Uniao,2020-12-31T00:00:00,2.1,1.9448256492614744,-7.389254797072642,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Sao_Sebastiao_do_Paraiso,2020-12-31T00:00:00,1.929071661237785,1.8160429000854488,-5.85923081156099,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Serra_do_Salitre,2020-12-31T00:00:00,1.8000000000000005,2.223042726516724,23.50237369537352,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Tapira,2020-12-31T00:00:00,2.1013698630137,1.9958629608154297,-5.020863012042832,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Tiros,2020-12-31T00:00:00,1.740235294117647,2.322097063064575,33.43581014094704,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Tupaciguara,2020-12-31T00:00:00,2.1,2.469029903411865,17.572852543422147,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Uberaba,2020-12-31T00:00:00,2.5325581395348844,3.294124126434326,30.071016929913668,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Uberlandia,2020-12-31T00:00:00,1.920754716981132,3.3511404991149902,74.46998669262722,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Unai,2020-12-31T00:00:00,2.3398907103825146,2.775644063949585,18.62280796421621,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Varginha,2020-12-31T00:00:00,1.899977968715576,2.376645565032959,25.08805913363409,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Varjao_de_Minas,2020-12-31T00:00:00,2.519786096256685,2.549893856048584,1.1948537947973432,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_1_2020,Virginopolis,2020-12-31T00:00:00,1.626666666666667,1.528537392616272,-6.032537339163623,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:52:59
V43_cluster_2_2020,Abre_Campo,2019-12-31T00:00:00,1.5,1.246139407157898,-16.9240395228068,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Aimores,2019-12-31T00:00:00,1.49025069637883,1.227672100067139,-17.61976001418639,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Alvarenga,2019-12-31T00:00:00,0.6601705237515224,0.7850736379623413,18.91982597178641,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Andrelandia,2019-12-31T00:00:00,1.5,2.933701992034912,95.58013280232748,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Antonio_Dias,2019-12-31T00:00:00,1.0,1.1595386266708374,15.95386266708374,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Antonio_Prado_de_Minas,2019-12-31T00:00:00,0.597560975609756,1.8043720722198489,201.95614269801555,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Bocaiuva,2019-12-31T00:00:00,1.6230769230769229,2.002021312713623,23.34728466955973,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Bom_Jesus_do_Amparo,2019-12-31T00:00:00,1.8000000000000005,4.759524822235107,164.41804567972815,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Campo_Belo,2019-12-31T00:00:00,1.26,3.3571865558624268,166.44337744939895,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Capela_Nova,2019-12-31T00:00:00,1.8000000000000005,2.173189163208008,20.73273128933375,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Capitao_Eneas,2019-12-31T00:00:00,0.5333333333333333,1.5344898700714111,187.7168506383896,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Casa_Grande,2019-12-31T00:00:00,1.5,1.52679705619812,1.7864704132080078,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Cataguases,2019-12-31T00:00:00,0.5,1.326697587966919,165.3395175933838,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Caxambu,2019-12-31T00:00:00,0.8979591836734695,1.7604398727416992,96.04898582805284,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Coimbra,2019-12-31T00:00:00,1.5,1.7812410593032837,18.74940395355225,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Conselheiro_Pena,2019-12-31T00:00:00,1.3,1.7815487384796145,37.042210652278015,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Corrego_Novo,2019-12-31T00:00:00,1.145454545454546,0.9512160420417786,-16.95732966301937,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Cruzilia,2019-12-31T00:00:00,1.2,1.5387585163116455,28.229876359303795,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Divisopolis,2019-12-31T00:00:00,1.080402010050251,1.3249255418777466,22.63264317845193,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Esmeraldas,2019-12-31T00:00:00,2.1500000000000004,3.646084308624268,69.58531668019846,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Espirito_Santo_do_Dourado,2019-12-31T00:00:00,1.2,3.124526262283325,160.37718852361044,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Eugenopolis,2019-12-31T00:00:00,0.7199999999999999,1.480507254600525,105.62600758340628,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Felicio_dos_Santos,2019-12-31T00:00:00,1.8000000000000005,1.7584490776062012,-2.3083845774332827,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Formiga,2019-12-31T00:00:00,1.2400000000000002,4.279924392700195,245.15519295969312,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Guaraciaba,2019-12-31T00:00:00,1.197368421052632,1.296574354171753,8.285330678080419,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Guiricema,2019-12-31T00:00:00,1.5,1.7573611736297607,17.157411575317383,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Iapu,2019-12-31T00:00:00,1.5625,2.1812710762023926,39.601348876953125,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Ijaci,2019-12-31T00:00:00,1.416666666666667,4.101637840270996,189.5273769603056,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Imbe_de_Minas,2019-12-31T00:00:00,0.9601626016260164,1.52971351146698,59.31817265913505,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Inhapim,2019-12-31T00:00:00,1.319886363636364,1.6342980861663818,23.82112060494323,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Irai_de_Minas,2019-12-31T00:00:00,1.67972027972028,2.2550902366638184,34.253915005381344,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Itamarati_de_Minas,2019-12-31T00:00:00,0.9,0.893599271774292,-0.71119202507867,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Jequeri,2019-12-31T00:00:00,1.32,1.4105665683746338,6.861103664744979,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Lamim,2019-12-31T00:00:00,1.5200000000000002,1.3899085521697998,-8.558647883565817,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Mar_de_Espanha,2019-12-31T00:00:00,1.8000000000000005,2.0243594646453857,12.464414702521411,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Mata_Verde,2019-12-31T00:00:00,1.020366598778004,1.4112389087677002,38.30704674749319,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Monte_Alegre_de_Minas,2019-12-31T00:00:00,1.8000000000000005,6.880733013153076,282.2629451751708,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Nova_Era,2019-12-31T00:00:00,1.5,3.3124892711639404,120.83261807759602,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Nova_Ponte,2019-12-31T00:00:00,1.679452054794521,2.5395519733428955,51.21312728713811,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Paula_Candido,2019-12-31T00:00:00,1.32,1.452248215675354,10.018804217829844,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Pecanha,2019-12-31T00:00:00,1.44,2.8481640815734863,97.78917233149213,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Pedra_Bonita,2019-12-31T00:00:00,1.2,1.1986039876937866,-0.1163343588511112,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Pedra_Dourada,2019-12-31T00:00:00,0.96,1.26190185546875,31.44810994466148,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Pedra_do_Anta,2019-12-31T00:00:00,1.318181818181818,1.2148478031158447,-7.839132177418656,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Piedade_de_Caratinga,2019-12-31T00:00:00,1.44,2.006957530975342,39.37205076217652,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Pocrane,2019-12-31T00:00:00,1.07741935483871,1.4783756732940674,37.21450859914992,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Presidente_Bernardes,2019-12-31T00:00:00,1.2571428571428571,1.400360345840454,11.392300237308852,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sabinopolis,2019-12-31T00:00:00,1.2,1.7739310264587402,47.82758553822836,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Santa_Barbara,2019-12-31T00:00:00,1.071428571428571,1.7785580158233645,65.99874814351408,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Santo_Antonio_do_Grama,2019-12-31T00:00:00,1.2,2.5113744735717773,109.28120613098145,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Domingos_do_Prata,2019-12-31T00:00:00,0.7211538461538461,1.7858926057815552,147.64377466837564,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Geraldo,2019-12-31T00:00:00,2.0,0.9610801339149476,-51.94599330425261,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Jose_da_Barra,2019-12-31T00:00:00,1.702112676056338,3.264837741851806,91.81090581007716,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Jose_do_Alegre,2019-12-31T00:00:00,1.5,2.136620044708252,42.44133631388347,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Miguel_do_Anta,2019-12-31T00:00:00,1.303164556962025,1.271883845329285,-2.400365438549278,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Sebastiao_da_Vargem_Alegre,2019-12-31T00:00:00,1.02,1.098893404006958,7.734647451662548,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Sebastiao_do_Anta,2019-12-31T00:00:00,1.5,1.9222993850708008,28.153292338053387,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Senhora_dos_Remedios,2019-12-31T00:00:00,1.8000000000000005,1.5935107469558716,-11.471625169118258,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Teixeiras,2019-12-31T00:00:00,0.96,1.2378493547439575,28.94264111916226,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Visconde_do_Rio_Branco,2019-12-31T00:00:00,0.5,1.028517484664917,105.7034969329834,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Abre_Campo,2020-12-31T00:00:00,1.5,1.2934907674789429,-13.767282168070476,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Aimores,2020-12-31T00:00:00,2.063157894736842,1.309045433998108,-36.55136927049986,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Alvarenga,2020-12-31T00:00:00,0.9,0.6914265751838684,-23.17482497957018,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Andrelandia,2020-12-31T00:00:00,1.8000000000000005,2.657214403152466,47.62302239735919,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Antonio_Dias,2020-12-31T00:00:00,1.333333333333333,1.0441155433654783,-21.691334247589094,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Antonio_Prado_de_Minas,2020-12-31T00:00:00,1.5,0.9957669377326964,-33.61553748448689,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Bocaiuva,2020-12-31T00:00:00,1.622950819672131,1.7407445907592771,7.258000036682759,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Bom_Jesus_do_Amparo,2020-12-31T00:00:00,1.5,4.671821594238281,211.45477294921875,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Campo_Belo,2020-12-31T00:00:00,1.8000000000000005,3.1858484745025635,76.99158191680905,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Capela_Nova,2020-12-31T00:00:00,1.8000000000000005,2.2742724418640137,26.348468992445184,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Capitao_Eneas,2020-12-31T00:00:00,3.0,1.7970223426818848,-40.09925524393718,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Casa_Grande,2020-12-31T00:00:00,1.553846153846154,2.119284152984619,36.389574201980416,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Cataguases,2020-12-31T00:00:00,1.25,0.7799899578094482,-37.60080337524414,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Caxambu,2020-12-31T00:00:00,1.3265306122448983,1.745147705078125,31.557288536658618,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Coimbra,2020-12-31T00:00:00,1.8000000000000005,1.514507532119751,-15.860692660013848,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Conselheiro_Pena,2020-12-31T00:00:00,1.55981308411215,1.5115768909454346,-3.092434193432326,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Corrego_Novo,2020-12-31T00:00:00,1.2545454545454553,0.8808083534240723,-29.790638495182687,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Cruzilia,2020-12-31T00:00:00,1.2,1.645519733428955,37.126644452412926,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Divisopolis,2020-12-31T00:00:00,1.34029484029484,2.500765562057495,86.58324175204413,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Esmeraldas,2020-12-31T00:00:00,2.096153846153846,4.147229194641113,97.84946616636508,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Espirito_Santo_do_Dourado,2020-12-31T00:00:00,1.619148936170213,2.5738229751586914,58.96147152754071,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Eugenopolis,2020-12-31T00:00:00,1.8000000000000005,1.2128185033798218,-32.621194256676574,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Felicio_dos_Santos,2020-12-31T00:00:00,3.548821548821549,2.128462076187134,-40.02341208466995,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Formiga,2020-12-31T00:00:00,1.441791044776119,4.193431377410889,190.848760130983,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Guaraciaba,2020-12-31T00:00:00,1.2,1.3920286893844604,16.002390782038376,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Guiricema,2020-12-31T00:00:00,2.4,1.6244333982467651,-32.31527507305145,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Iapu,2020-12-31T00:00:00,1.0,1.7117230892181396,71.17230892181396,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Ijaci,2020-12-31T00:00:00,2.458064516129032,3.798830986022949,54.54561754161604,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Imbe_de_Minas,2020-12-31T00:00:00,1.439877300613497,1.064762830734253,-26.051835786244904,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Inhapim,2020-12-31T00:00:00,1.8000000000000005,1.3271729946136477,-26.268166965908485,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Irai_de_Minas,2020-12-31T00:00:00,3.3595092024539883,2.711183547973633,-19.29822528858618,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Itamarati_de_Minas,2020-12-31T00:00:00,1.2,0.8642855286598206,-27.97620594501496,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Jequeri,2020-12-31T00:00:00,2.1,1.3268165588378906,-36.81825910295759,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Lamim,2020-12-31T00:00:00,2.387096774193548,1.4325149059295654,-39.98924042727495,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Mar_de_Espanha,2020-12-31T00:00:00,1.8000000000000005,1.985149621963501,10.286090109083371,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Mata_Verde,2020-12-31T00:00:00,1.319688109161793,2.2692017555236816,71.94985237572365,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Monte_Alegre_de_Minas,2020-12-31T00:00:00,3.0,5.492535591125488,83.08451970418295,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Nova_Era,2020-12-31T00:00:00,1.565217391304348,2.341349124908448,49.58619409137302,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Nova_Ponte,2020-12-31T00:00:00,1.8591549295774648,2.974227905273437,59.97741005637429,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Paula_Candido,2020-12-31T00:00:00,1.62,1.3483304977416992,-16.76972236162351,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Pecanha,2020-12-31T00:00:00,2.0,2.3271853923797607,16.359269618988062,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Pedra_Bonita,2020-12-31T00:00:00,1.7400000000000002,1.278857946395874,-26.50241687380036,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Pedra_Dourada,2020-12-31T00:00:00,1.44,1.1324880123138428,-21.35499914487203,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Pedra_do_Anta,2020-12-31T00:00:00,1.5,1.21563982963562,-18.957344690958656,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Piedade_de_Caratinga,2020-12-31T00:00:00,1.8000000000000005,1.4492950439453125,-19.483608669704875,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Pocrane,2020-12-31T00:00:00,1.258064516129032,1.2236186265945437,-2.738006604023451,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Presidente_Bernardes,2020-12-31T00:00:00,1.5,1.397857666015625,-6.809488932291667,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sabinopolis,2020-12-31T00:00:00,1.0,1.2415145635604858,24.151456356048584,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Santa_Barbara,2020-12-31T00:00:00,1.142857142857143,1.5768578052520752,37.975057959556565,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Santo_Antonio_do_Grama,2020-12-31T00:00:00,1.695652173913043,1.886615514755249,11.261940613771127,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Domingos_do_Prata,2020-12-31T00:00:00,0.8846153846153846,1.4983876943588257,69.38295675360638,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Geraldo,2020-12-31T00:00:00,1.8000000000000005,1.1164052486419678,-37.97748618655736,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Jose_da_Barra,2020-12-31T00:00:00,2.537024221453287,3.375559568405152,33.0519251594502,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Jose_do_Alegre,2020-12-31T00:00:00,1.359090909090909,2.2984859943389893,69.11937082092899,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Miguel_do_Anta,2020-12-31T00:00:00,1.5,1.1930384635925293,-20.46410242716471,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Sebastiao_da_Vargem_Alegre,2020-12-31T00:00:00,1.8000000000000005,1.0785762071609497,-40.07909960216947,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Sao_Sebastiao_do_Anta,2020-12-31T00:00:00,1.8000000000000005,1.4275751113891602,-20.690271589491115,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Senhora_dos_Remedios,2020-12-31T00:00:00,1.8000000000000005,1.960702896118164,8.92793867323132,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Teixeiras,2020-12-31T00:00:00,1.5,1.0300226211547852,-31.331825256347656,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_2_2020,Visconde_do_Rio_Branco,2020-12-31T00:00:00,1.0,0.790953516960144,-20.9046483039856,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:53:34
V43_cluster_3_2020,Aiuruoca,2019-12-31T00:00:00,1.538461538461539,1.7354446649551392,12.803903222084006,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Albertina,2019-12-31T00:00:00,1.56,1.9280182123184204,23.590911046052582,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Baependi,2019-12-31T00:00:00,1.439956331877729,1.9334536790847776,34.27168840346147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Bandeira_do_Sul,2019-12-31T00:00:00,1.5,1.896607518196106,26.44050121307373,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Borda_da_Mata,2019-12-31T00:00:00,1.5606557377049175,1.960394024848938,25.613482684648364,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Brazopolis,2019-12-31T00:00:00,1.559426229508197,1.48039710521698,-5.067833463089874,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Bueno_Brandao,2019-12-31T00:00:00,1.56,2.0024099349975586,28.359611217792214,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Cachoeira_de_Minas,2019-12-31T00:00:00,1.68,2.000740766525269,19.09171229317075,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Caldas,2019-12-31T00:00:00,1.44,1.776524782180786,23.36977654033237,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Cambuquira,2019-12-31T00:00:00,1.679869186046512,2.2064108848571777,31.344208417195578,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Campanha,2019-12-31T00:00:00,1.506616257088847,2.293265581130981,52.21298524696224,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Careacu,2019-12-31T00:00:00,1.2,1.554934024810791,29.577835400899254,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Carmo_da_Cachoeira,2019-12-31T00:00:00,1.6199809705042818,2.071760416030884,27.88794768286495,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Carmo_de_Minas,2019-12-31T00:00:00,1.5,1.8451228141784668,23.00818761189779,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Carrancas,2019-12-31T00:00:00,1.875,1.9646040201187127,4.778881072998059,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Carvalhopolis,2019-12-31T00:00:00,1.560199625701809,1.704617619514465,9.256379211582896,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Conceicao_das_Pedras,2019-12-31T00:00:00,1.679708222811671,1.73746919631958,3.43875041649928,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Conceicao_do_Rio_Verde,2019-12-31T00:00:00,1.8000000000000005,2.4172420501708984,34.29122500949433,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Conceicao_dos_Ouros,2019-12-31T00:00:00,1.5028571428571431,1.5169260501861572,0.9361440237937146,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Congonhal,2019-12-31T00:00:00,1.501818181818182,2.0768749713897705,38.29070632740601,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Cordislandia,2019-12-31T00:00:00,1.5,2.3780102729797363,58.534018198649086,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Cristina,2019-12-31T00:00:00,1.500597371565114,1.7584013938903809,17.180092889032508,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Datas,2019-12-31T00:00:00,2.0,2.668208360671997,33.41041803359988,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Dom_Vicoso,2019-12-31T00:00:00,1.65,1.5919907093048096,-3.515714587587294,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Fama,2019-12-31T00:00:00,1.619932432432432,1.7425466775894165,7.569096259951495,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Fortaleza_de_Minas,2019-12-31T00:00:00,1.4403669724770642,1.657627820968628,15.083714958968434,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Heliodora,2019-12-31T00:00:00,1.5599383667180282,1.8382105827331543,17.838667344312206,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Ibitiura_de_Minas,2019-12-31T00:00:00,1.32,2.1008410453796387,59.15462464997262,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Inconfidentes,2019-12-31T00:00:00,1.5,2.8529577255249023,90.19718170166016,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Ingai,2019-12-31T00:00:00,1.5,2.0910415649414062,39.40277099609375,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Itajuba,2019-12-31T00:00:00,1.8235294117647065,2.5227766036987305,38.34581375122067,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Itutinga,2019-12-31T00:00:00,1.521739130434783,1.6159268617630005,6.189479487282867,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Jesuania,2019-12-31T00:00:00,1.5,1.9200278520584104,28.001856803894043,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Lambari,2019-12-31T00:00:00,1.559769167353669,1.754131555557251,12.46097129444738,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Luminarias,2019-12-31T00:00:00,1.720238095238095,2.6072351932525635,51.5624610610487,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Maria_da_Fe,2019-12-31T00:00:00,1.5,1.9886201620101929,32.57467746734619,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Monsenhor_Paulo,2019-12-31T00:00:00,1.5,2.198331832885742,46.55545552571614,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Monte_Siao,2019-12-31T00:00:00,1.5601626016260162,1.8383777141571045,17.8324433774486,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Natercia,2019-12-31T00:00:00,1.4399193548387097,1.8986358642578125,31.857097265734385,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Olimpio_Noronha,2019-12-31T00:00:00,1.5,1.79508376121521,19.672250747680664,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Ouro_Fino,2019-12-31T00:00:00,1.439922480620155,1.753187894821167,21.755713826072977,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Paraisopolis,2019-12-31T00:00:00,1.2,1.893233060836792,57.76942173639934,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Pedralva,2019-12-31T00:00:00,1.5,2.1822359561920166,45.48239707946777,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Pirangucu,2019-12-31T00:00:00,1.166666666666667,1.3826181888580322,18.510130473545587,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Piranguinho,2019-12-31T00:00:00,1.5,1.5927293300628662,6.181955337524414,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Poco_Fundo,2019-12-31T00:00:00,1.199923204914885,1.687330722808838,40.61989266459153,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Pocos_de_Caldas,2019-12-31T00:00:00,1.08,1.959694981575012,81.45323903472334,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Pouso_Alegre,2019-12-31T00:00:00,1.5,1.4920567274093628,-0.5295515060424805,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Pouso_Alto,2019-12-31T00:00:00,1.65,1.7238686084747314,4.476885362104942,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Santa_Rita_de_Caldas,2019-12-31T00:00:00,1.9210526315789471,2.1118650436401367,9.93270090181535,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Santa_Rita_do_Sapucai,2019-12-31T00:00:00,1.5,1.692865252494812,12.857683499654136,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Bento_Abade,2019-12-31T00:00:00,1.44,2.742644786834717,90.46144353018867,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Goncalo_do_Sapucai,2019-12-31T00:00:00,1.5,2.400556325912476,60.03708839416504,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Joao_da_Mata,2019-12-31T00:00:00,1.3799999999999997,1.51132071018219,9.515993491463066,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Joao_del_Rei,2019-12-31T00:00:00,1.982758620689655,2.043062686920166,3.0414224707562063,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Lourenco,2019-12-31T00:00:00,1.6000000000000003,1.7962888479232788,12.268052995204904,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Sebastiao_da_Bela_Vista,2019-12-31T00:00:00,1.44,1.4644222259521484,1.6959879133436453,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Tome_das_Letras,2019-12-31T00:00:00,1.440140845070423,1.6121225357055664,11.942004924298466,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Senador_Jose_Bento,2019-12-31T00:00:00,1.2,1.4862325191497805,23.85270992914836,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Serrania,2019-12-31T00:00:00,1.68,1.878470540046692,11.813722621826903,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Silvianopolis,2019-12-31T00:00:00,1.2,1.3368335962295532,11.402799685796106,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Soledade_de_Minas,2019-12-31T00:00:00,1.8000000000000005,1.9132663011550903,6.292572286393891,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Tocos_do_Moji,2019-12-31T00:00:00,1.2,1.751159906387329,45.9299921989441,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Tres_Coracoes,2019-12-31T00:00:00,1.56,2.791533231735229,78.94443793174547,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Turvolandia,2019-12-31T00:00:00,2.1,2.2218434810638428,5.802070526849652,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Virginia,2019-12-31T00:00:00,1.36,1.861019730567932,36.83968607117149,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Aiuruoca,2020-12-31T00:00:00,1.8000000000000005,1.9852638244628904,10.292434692382797,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Albertina,2020-12-31T00:00:00,1.68,2.127347230911255,26.627811363765176,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Baependi,2020-12-31T00:00:00,1.67948717948718,2.2043845653533936,31.25343213554553,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Bandeira_do_Sul,2020-12-31T00:00:00,1.5,1.8602616786956787,24.01744524637858,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Borda_da_Mata,2020-12-31T00:00:00,1.62,2.305201292037964,42.29637605172616,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Brazopolis,2020-12-31T00:00:00,1.680327868852459,1.7012786865234375,1.2468291491996966,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Bueno_Brandao,2020-12-31T00:00:00,1.8000000000000005,2.1333324909210205,18.51847171783445,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Cachoeira_de_Minas,2020-12-31T00:00:00,1.8596638655462183,2.315104961395264,24.49050628379411,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Caldas,2020-12-31T00:00:00,1.68,1.7707923650741575,5.404307444890344,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Cambuquira,2020-12-31T00:00:00,1.800145348837209,2.3206701278686523,28.915708354754383,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Campanha,2020-12-31T00:00:00,1.6833930704898452,2.361158609390259,40.26187055072008,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Careacu,2020-12-31T00:00:00,1.320454545454546,1.590753197669983,20.470121682408298,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Carmo_da_Cachoeira,2020-12-31T00:00:00,1.8000000000000005,2.244464874267578,24.69249301486544,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Carmo_de_Minas,2020-12-31T00:00:00,1.7400000000000002,1.9607166051864624,12.684862367038056,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Carrancas,2020-12-31T00:00:00,1.785714285714286,2.5275115966796875,41.54064941406247,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Carvalhopolis,2020-12-31T00:00:00,1.679765395894428,1.6532411575317385,-1.579044218169906,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Conceicao_das_Pedras,2020-12-31T00:00:00,1.739921976592978,1.85886025428772,6.835839726999724,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Conceicao_do_Rio_Verde,2020-12-31T00:00:00,1.8000000000000005,2.7291159629821777,51.61755349900985,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Conceicao_dos_Ouros,2020-12-31T00:00:00,1.5028571428571431,1.5921231508255005,5.939753381924919,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Congonhal,2020-12-31T00:00:00,1.619354838709677,2.163903951644897,33.627534862533544,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Cordislandia,2020-12-31T00:00:00,1.62,2.1905298233032227,35.21789032735941,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Cristina,2020-12-31T00:00:00,2.100263852242744,1.847629427909851,-12.028699349518392,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Datas,2020-12-31T00:00:00,2.0,2.4278292655944824,21.39146327972415,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Dom_Vicoso,2020-12-31T00:00:00,1.4285714285714288,1.7671669721603394,23.701688051223734,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Fama,2020-12-31T00:00:00,1.8000000000000005,1.9955780506134035,10.865447256300168,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Fortaleza_de_Minas,2020-12-31T00:00:00,1.68,1.8516188859939573,10.215409880592713,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Heliodora,2020-12-31T00:00:00,1.8000000000000005,2.108797550201416,17.155419455634206,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Ibitiura_de_Minas,2020-12-31T00:00:00,1.68,1.994058609008789,18.69396482195173,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Inconfidentes,2020-12-31T00:00:00,2.46,3.229987859725952,31.300319501054968,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Ingai,2020-12-31T00:00:00,1.6791666666666667,2.204458951950073,31.28291525260981,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Itajuba,2020-12-31T00:00:00,1.5882352941176472,2.5340912342071533,59.55389252415409,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Itutinga,2020-12-31T00:00:00,1.8000000000000005,1.7160320281982422,-4.664887322319893,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Jesuania,2020-12-31T00:00:00,1.5,2.061105251312256,37.40701675415039,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Lambari,2020-12-31T00:00:00,1.8000970402717127,1.907342791557312,5.95777610241564,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Luminarias,2020-12-31T00:00:00,1.860103626943005,2.931270837783813,57.58642665523013,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Maria_da_Fe,2020-12-31T00:00:00,1.7333333333333332,1.8012824058532717,3.9201387992272094,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Monsenhor_Paulo,2020-12-31T00:00:00,2.1,2.2076568603515625,5.12651715959821,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Monte_Siao,2020-12-31T00:00:00,1.8000000000000005,2.186972618103028,21.4984787835015,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Natercia,2020-12-31T00:00:00,1.4399193548387097,2.0093636512756348,39.546957579489614,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Olimpio_Noronha,2020-12-31T00:00:00,1.5595854922279788,1.9813276529312127,27.041939207881825,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Ouro_Fino,2020-12-31T00:00:00,2.099920063948841,1.841354489326477,-12.31311510668356,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Paraisopolis,2020-12-31T00:00:00,2.4,1.896649956703186,-20.97291847070058,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Pedralva,2020-12-31T00:00:00,1.68,2.3331124782562256,38.87574275334676,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Pirangucu,2020-12-31T00:00:00,1.333333333333333,1.4050767421722412,5.380755662918115,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Piranguinho,2020-12-31T00:00:00,1.458181818181818,1.608264446258545,10.292449556384016,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Poco_Fundo,2020-12-31T00:00:00,1.740033329060377,1.592519760131836,-8.477628931866432,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Pocos_de_Caldas,2020-12-31T00:00:00,1.8000000000000005,1.8164515495300293,0.9139749738905016,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Pouso_Alegre,2020-12-31T00:00:00,1.6375,1.917114019393921,17.075665306498987,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Pouso_Alto,2020-12-31T00:00:00,1.45,1.8977758884429927,30.881095754689188,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Santa_Rita_de_Caldas,2020-12-31T00:00:00,1.8000000000000005,2.2117133140563965,22.87296189202201,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Santa_Rita_do_Sapucai,2020-12-31T00:00:00,1.68,1.7884929180145264,6.457911786578954,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Bento_Abade,2020-12-31T00:00:00,1.8000000000000005,2.928433895111084,62.69077195061576,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Goncalo_do_Sapucai,2020-12-31T00:00:00,2.4,2.4753732681274414,3.140552838643396,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Joao_da_Mata,2020-12-31T00:00:00,1.6399999999999997,1.53575599193573,-6.356341955138397,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Joao_del_Rei,2020-12-31T00:00:00,1.9709821428571432,2.208517551422119,12.05162661801916,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Lourenco,2020-12-31T00:00:00,3.3928571428571423,1.9906508922576904,-41.32818422819438,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Sebastiao_da_Bela_Vista,2020-12-31T00:00:00,1.5,1.6068718433380127,7.124789555867513,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Sao_Tome_das_Letras,2020-12-31T00:00:00,2.133763094278808,1.8922100067138672,-11.320520455743631,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Senador_Jose_Bento,2020-12-31T00:00:00,1.620618556701031,1.4744243621826172,-9.020888593057338,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Serrania,2020-12-31T00:00:00,1.8000000000000005,2.002984046936035,11.276891496446382,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Silvianopolis,2020-12-31T00:00:00,1.50032154340836,1.456154704093933,-2.943824909298499,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Soledade_de_Minas,2020-12-31T00:00:00,3.2000000000000006,2.2422022819519043,-29.931178689003,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Tocos_do_Moji,2020-12-31T00:00:00,1.441340782122905,1.8432252407073968,27.88268142892409,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Tres_Coracoes,2020-12-31T00:00:00,2.1,3.034441947937012,44.49723561604817,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Turvolandia,2020-12-31T00:00:00,1.6202531645569618,2.488245248794556,53.57138644903901,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_3_2020,Virginia,2020-12-31T00:00:00,1.5333333333333332,1.829870581626892,19.33938575827558,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:08
V43_cluster_4_2020,Abadia_dos_Dourados,2019-12-31T00:00:00,2.4,1.7931814193725586,-25.28410752614339,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Acucena,2019-12-31T00:00:00,0.8571428571428571,1.058965802192688,23.54601025581361,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Agua_Boa,2019-12-31T00:00:00,1.092380952380952,1.2413609027862549,13.6380948496572,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Aguas_Vermelhas,2019-12-31T00:00:00,2.7000000000000006,3.4000394344329834,25.92738646048084,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Angelandia,2019-12-31T00:00:00,1.219512195121951,1.3574920892715454,11.314351320266749,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Aricanduva,2019-12-31T00:00:00,0.9608695652173912,1.1013343334197998,14.618505288033475,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Ataleia,2019-12-31T00:00:00,0.9,0.9995573163032532,11.061924033694796,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Bandeira,2019-12-31T00:00:00,0.9,0.9780629277229308,8.67365863588121,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Berilo,2019-12-31T00:00:00,0.7142857142857143,0.8827653527259827,23.58714938163757,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Berizal,2019-12-31T00:00:00,1.2,1.5743919610977173,31.199330091476448,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Bonfinopolis_de_Minas,2019-12-31T00:00:00,2.4,2.621093511581421,9.212229649225876,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Buritis,2019-12-31T00:00:00,3.12,2.69865083694458,-13.504780867160898,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Buritizeiro,2019-12-31T00:00:00,2.880232558139535,2.6433119773864746,-8.225744830344444,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Capelinha,2019-12-31T00:00:00,1.140074211502783,1.3456312417984009,18.030144724058253,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Carai,2019-12-31T00:00:00,1.2,0.9044532775878906,-24.62889353434245,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Caranaiba,2019-12-31T00:00:00,1.444444444444444,1.808886170387268,25.230581026810903,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Catuji,2019-12-31T00:00:00,1.25974025974026,1.025432825088501,-18.59966233833551,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Congonhas_do_Norte,2019-12-31T00:00:00,0.9,1.2225550413131714,35.839449034796814,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Coroaci,2019-12-31T00:00:00,1.456,2.0073790550231934,37.869440592252296,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Cuparaque,2019-12-31T00:00:00,1.5,0.9972007870674132,-33.51994752883911,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Diamantina,2019-12-31T00:00:00,1.7228915662650603,2.0534820556640625,19.188119314767256,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Formoso,2019-12-31T00:00:00,3.0,2.763814687728882,-7.872843742370605,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Franciscopolis,2019-12-31T00:00:00,3.0,1.5523346662521362,-48.25551112492879,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Frei_Gaspar,2019-12-31T00:00:00,1.2,0.9731600880622864,-18.903325994809467,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Grao_Mogol,2019-12-31T00:00:00,0.7250000000000001,2.4251108169555664,234.4980437180092,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Indaiabira,2019-12-31T00:00:00,2.4,3.232923984527588,34.70516602198283,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Itabirinha,2019-12-31T00:00:00,1.098484848484848,0.9543135166168212,-13.124562625227265,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Itacambira,2019-12-31T00:00:00,0.6000000000000001,3.060652017593384,410.1086695988972,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Itaipe,2019-12-31T00:00:00,0.9610983981693364,0.9616634845733644,0.0587958948952911,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Itamarandiba,2019-12-31T00:00:00,1.214953271028037,1.9725525379180908,62.35624735171983,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Itambacuri,2019-12-31T00:00:00,0.9,1.2128987312316897,34.766525692409935,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Jequitinhonha,2019-12-31T00:00:00,2.0375,2.0320749282836914,-0.2662611885304657,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Joao_Pinheiro,2019-12-31T00:00:00,2.4,2.860229730606079,19.176238775253303,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Jose_Goncalves_de_Minas,2019-12-31T00:00:00,0.958823529411765,1.144142508506775,19.327746285982627,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Juiz_de_Fora,2019-12-31T00:00:00,0.9,1.6575610637664795,84.17345152960883,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Ladainha,2019-12-31T00:00:00,1.118556701030928,1.051265835762024,-6.0158653742706925,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Malacacheta,2019-12-31T00:00:00,1.5,1.7107003927230835,14.046692848205566,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Mantena,2019-12-31T00:00:00,0.279,0.8930618166923523,220.09384110837,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Minas_Novas,2019-12-31T00:00:00,0.9,1.0473285913467407,16.369843482971188,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Monte_Formoso,2019-12-31T00:00:00,1.2,1.3204896450042725,10.040803750356044,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Ninheira,2019-12-31T00:00:00,2.7000871839581526,2.905716180801392,7.615642860161287,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Nova_Belem,2019-12-31T00:00:00,0.9,1.1303842067718506,25.598245196872284,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Novo_Cruzeiro,2019-12-31T00:00:00,1.079404466501241,1.1639620065689087,7.833721528108062,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Novorizonte,2019-12-31T00:00:00,1.6000000000000003,0.9972500801086426,-37.67186999320985,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Ouro_Verde_de_Minas,2019-12-31T00:00:00,1.5,1.3114118576049805,-12.572542826334637,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Padre_Paraiso,2019-12-31T00:00:00,0.6000000000000001,0.7551718950271606,25.86198250452676,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Paracatu,2019-12-31T00:00:00,2.4,2.8026235103607178,16.775979598363243,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Pedra_Azul,2019-12-31T00:00:00,1.2,1.3758271932601929,14.652266105016077,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Pirapora,2019-12-31T00:00:00,3.0,3.3109164237976074,10.363880793253582,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Pote,2019-12-31T00:00:00,0.7250000000000001,0.9201412796974182,26.916038578954225,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Rio_Pardo_de_Minas,2019-12-31T00:00:00,2.75,3.063051462173462,11.383689533580434,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Santa_Barbara_do_Monte_Verde,2019-12-31T00:00:00,0.6666666666666667,1.452930212020874,117.93953180313108,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Santa_Maria_do_Suacui,2019-12-31T00:00:00,0.8,0.8786141276359558,9.826765954494473,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Santo_Antonio_do_Retiro,2019-12-31T00:00:00,2.1,1.1127803325653076,-47.01046035403297,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Sao_Goncalo_do_Rio_Preto,2019-12-31T00:00:00,1.6000000000000003,4.102841377258301,156.42758607864374,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Sao_Joao_do_Manteninha,2019-12-31T00:00:00,0.9,0.8531259298324585,-5.208230018615724,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Sao_Joao_do_Paraiso,2019-12-31T00:00:00,1.5857142857142863,2.41871976852417,52.53187729431696,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Sao_Sebastiao_do_Maranhao,2019-12-31T00:00:00,0.925925925925926,1.0591528415679932,14.388506889343262,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Senador_Modestino_Goncalves,2019-12-31T00:00:00,1.833333333333333,1.923507809638977,4.918607798489674,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Setubinha,2019-12-31T00:00:00,0.9,1.2026060819625854,33.62289799584283,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Taiobeiras,2019-12-31T00:00:00,2.579831932773109,2.5258119106292725,-2.0939357117643467,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Teofilo_Otoni,2019-12-31T00:00:00,0.90625,1.0001858472824097,10.365334872541755,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Turmalina,2019-12-31T00:00:00,1.199233716475096,1.5056569576263428,25.55158656245221,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Urucuia,2019-12-31T00:00:00,2.400355871886121,2.639252185821533,9.95253731888078,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Vargem_Grande_do_Rio_Pardo,2019-12-31T00:00:00,2.1,2.1652255058288574,3.1059764680408253,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Varzea_da_Palma,2019-12-31T00:00:00,3.6004056795131847,3.403266429901123,-5.475473242746276,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Abadia_dos_Dourados,2020-12-31T00:00:00,2.584210526315789,1.777942776679993,-31.19977035250536,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Acucena,2020-12-31T00:00:00,1.166666666666667,0.8990654349327087,-22.93724843433927,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Agua_Boa,2020-12-31T00:00:00,1.33,1.157353401184082,-12.980947279392332,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Aguas_Vermelhas,2020-12-31T00:00:00,3.6000000000000005,2.6436469554901123,-26.56536234749689,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Angelandia,2020-12-31T00:00:00,1.8400349650349648,1.2179806232452393,-33.80665876519935,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Aricanduva,2020-12-31T00:00:00,1.3196428571428571,0.9924668669700624,-24.792767861537907,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Ataleia,2020-12-31T00:00:00,1.204819277108434,0.8699946403503418,-27.79044485092165,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Bandeira,2020-12-31T00:00:00,1.083333333333333,0.9567781686782836,-11.682015198927637,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Berilo,2020-12-31T00:00:00,0.8428571428571429,0.7838466167449951,-7.001248860763291,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Berizal,2020-12-31T00:00:00,3.340236686390532,1.2441120147705078,-62.75377670571907,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Bonfinopolis_de_Minas,2020-12-31T00:00:00,3.3,2.427903175354004,-26.42717650442412,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Buritis,2020-12-31T00:00:00,3.3,2.6244089603424072,-20.472455747199778,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Buritizeiro,2020-12-31T00:00:00,3.0,2.4411988258361816,-18.62670580546061,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Capelinha,2020-12-31T00:00:00,1.434123222748815,1.1298182010650637,-21.218889482905347,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Carai,2020-12-31T00:00:00,1.5225,0.871798574924469,-42.73900985717773,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Caranaiba,2020-12-31T00:00:00,1.645161290322581,1.3187150955200195,-19.84280791937137,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Catuji,2020-12-31T00:00:00,1.197183098591549,0.9112823605537416,-23.881120471393345,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Congonhas_do_Norte,2020-12-31T00:00:00,1.2,1.0199683904647827,-15.002634127934773,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Coroaci,2020-12-31T00:00:00,1.8000000000000005,1.6124351024627686,-10.42027208540176,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Cuparaque,2020-12-31T00:00:00,1.018518518518519,1.0889357328414917,6.91369013352822,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Diamantina,2020-12-31T00:00:00,2.3453815261044184,1.7351971864700315,-26.01642133030176,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Formoso,2020-12-31T00:00:00,3.0,2.721269130706787,-9.29102897644043,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Franciscopolis,2020-12-31T00:00:00,1.8000000000000005,1.6483383178710938,-8.425649007161471,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Frei_Gaspar,2020-12-31T00:00:00,1.08,0.8430641889572144,-21.93850102248016,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Grao_Mogol,2020-12-31T00:00:00,0.7749999999999999,1.2031313180923462,55.24275072159307,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Indaiabira,2020-12-31T00:00:00,3.0,2.58981990814209,-13.672669728597006,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Itabirinha,2020-12-31T00:00:00,0.7992424242424243,0.9152239561080932,14.511433370870428,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Itacambira,2020-12-31T00:00:00,0.75,1.9311766624450684,157.49022165934247,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Itaipe,2020-12-31T00:00:00,0.9594594594594597,0.8776833415031433,-8.52314468840479,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Itamarandiba,2020-12-31T00:00:00,1.7196261682242993,1.5475449562072754,-10.006896568381276,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Itambacuri,2020-12-31T00:00:00,1.091304347826087,1.0047084093093872,-7.935085999538235,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Jequitinhonha,2020-12-31T00:00:00,2.4,1.9240131378173828,-19.832785924275715,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Joao_Pinheiro,2020-12-31T00:00:00,3.0,2.585048198699951,-13.831726710001629,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Jose_Goncalves_de_Minas,2020-12-31T00:00:00,1.5,0.90544855594635,-39.63676293690999,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Juiz_de_Fora,2020-12-31T00:00:00,1.222222222222222,1.3744175434112549,12.452344460920866,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Ladainha,2020-12-31T00:00:00,1.242268041237113,0.9223653078079224,-25.75150634243278,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Malacacheta,2020-12-31T00:00:00,1.8000000000000005,1.5513291358947754,-13.815048005845822,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Mantena,2020-12-31T00:00:00,0.7,0.6250731348991394,-10.703837871551508,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Minas_Novas,2020-12-31T00:00:00,1.0,0.9395476579666138,-6.045234203338623,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Monte_Formoso,2020-12-31T00:00:00,0.6000000000000001,1.0670762062072754,77.8460343678792,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Ninheira,2020-12-31T00:00:00,3.0,2.794819593429565,-6.839346885681152,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Nova_Belem,2020-12-31T00:00:00,1.1,0.926689624786377,-15.75548865578392,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Novo_Cruzeiro,2020-12-31T00:00:00,1.19727047146402,1.0799046754837036,-9.802780472552856,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Novorizonte,2020-12-31T00:00:00,1.235294117647059,1.1201328039169312,-9.322582540057974,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Ouro_Verde_de_Minas,2020-12-31T00:00:00,1.2,1.298478603363037,8.206550280253097,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Padre_Paraiso,2020-12-31T00:00:00,0.7219512195121951,0.6800644397735596,-5.801885031365056,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Paracatu,2020-12-31T00:00:00,2.7000000000000006,2.555315494537353,-5.358685387505447,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Pedra_Azul,2020-12-31T00:00:00,1.0,1.2382246255874634,23.82246255874633,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Pirapora,2020-12-31T00:00:00,3.6000000000000005,2.8950295448303223,-19.58251264360217,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Pote,2020-12-31T00:00:00,0.6571428571428573,0.7367804050445557,12.118757289388888,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Rio_Pardo_de_Minas,2020-12-31T00:00:00,3.4487179487179493,2.526257038116455,-26.747937184727338,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Santa_Barbara_do_Monte_Verde,2020-12-31T00:00:00,1.6000000000000003,1.195325493812561,-25.29215663671496,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Santa_Maria_do_Suacui,2020-12-31T00:00:00,0.8,0.77480548620224,-3.1493142247200065,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Santo_Antonio_do_Retiro,2020-12-31T00:00:00,0.975,1.2986538410186768,33.195265745505324,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Sao_Goncalo_do_Rio_Preto,2020-12-31T00:00:00,3.6000000000000005,2.2865183353424072,-36.48560179604425,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Sao_Joao_do_Manteninha,2020-12-31T00:00:00,0.9166666666666664,0.7564105987548828,-17.48248013583095,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Sao_Joao_do_Paraiso,2020-12-31T00:00:00,3.146938775510204,1.6309759616851809,-48.17261859755263,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Sao_Sebastiao_do_Maranhao,2020-12-31T00:00:00,0.8148148148148149,0.9288821220397948,13.999169523065731,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Senador_Modestino_Goncalves,2020-12-31T00:00:00,3.6000000000000005,1.6094512939453125,-55.29301961263021,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Setubinha,2020-12-31T00:00:00,1.0,0.8812935948371887,-11.870640516281128,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Taiobeiras,2020-12-31T00:00:00,3.240083507306889,2.213726043701172,-31.676883058449658,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Teofilo_Otoni,2020-12-31T00:00:00,1.09375,0.868622362613678,-20.58309827532087,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Turmalina,2020-12-31T00:00:00,1.320338983050847,1.1438132524490356,-13.36972799166479,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Urucuia,2020-12-31T00:00:00,2.4,2.332895040512085,-2.796039978663123,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Vargem_Grande_do_Rio_Pardo,2020-12-31T00:00:00,1.8000000000000005,1.88719642162323,4.844245645734984,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_4_2020,Varzea_da_Palma,2020-12-31T00:00:00,3.0,3.419013500213623,13.967116673787435,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2020_(2020)
    Modelo LSTM treinado com dados de 2012 a 2018, validado com os dados de 2019 e testado com os dados de 2020.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:54:42
V43_cluster_0_2021,Aguanil,2020-12-31T00:00:00,2.1644859813084114,1.7553586959838867,-18.90182190402597,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Alfenas,2020-12-31T00:00:00,2.364130434782609,2.052685022354126,-13.173782962492147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Alto_Caparao,2020-12-31T00:00:00,1.92,1.4134409427642822,-26.38328423102697,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Alto_Jequitiba,2020-12-31T00:00:00,1.8000000000000005,1.4553327560424805,-19.14818021986221,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Amparo_do_Serra,2020-12-31T00:00:00,1.4392156862745098,1.3623692989349363,-5.339462880542557,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Araponga,2020-12-31T00:00:00,1.8000000000000005,1.185238003730774,-34.15344423717924,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Astolfo_Dutra,2020-12-31T00:00:00,1.75,1.4392120838165283,-17.75930949619838,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Bambui,2020-12-31T00:00:00,1.7998829724985372,1.50750994682312,-16.244001979170605,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Boa_Esperanca,2020-12-31T00:00:00,2.063248407643312,1.9671390056610107,-4.65815951323475,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Bom_Jesus_do_Galho,2020-12-31T00:00:00,1.44,1.2340333461761477,-14.303239848878649,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Bom_Sucesso,2020-12-31T00:00:00,2.1,1.352888107299805,-35.5767567952474,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Caete,2020-12-31T00:00:00,1.2,1.3029241561889648,8.577013015747074,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Caiana,2020-12-31T00:00:00,1.5,1.245358943939209,-16.976070404052734,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Cajuri,2020-12-31T00:00:00,1.8000000000000005,1.3541462421417236,-24.769653214348697,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Camacho,2020-12-31T00:00:00,2.1,1.5710139274597168,-25.189812978108726,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Campo_do_Meio,2020-12-31T00:00:00,2.4,1.861578702926636,-22.43422071139017,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Campos_Altos,2020-12-31T00:00:00,2.1000529941706416,1.65590238571167,-21.149495259969704,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Campos_Gerais,2020-12-31T00:00:00,2.690649114843395,1.907047867774964,-29.123130279067983,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Cana_Verde,2020-12-31T00:00:00,1.5,1.2803547382354736,-14.643017450968424,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Canaa,2020-12-31T00:00:00,1.8000000000000005,1.4487473964691162,-19.51403352949356,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Candeias,2020-12-31T00:00:00,1.859937013094646,1.5698952674865725,-15.594170316847952,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Caparao,2020-12-31T00:00:00,1.9199600798403191,1.4574520587921145,-24.08946029162602,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Capitolio,2020-12-31T00:00:00,2.1,1.594802975654602,-24.057001159304665,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Caputira,2020-12-31T00:00:00,1.8000000000000005,1.127407789230347,-37.366233931647415,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Carangola,2020-12-31T00:00:00,1.5,1.3829807043075562,-7.801286379496257,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Caratinga,2020-12-31T00:00:00,2.040022111663903,1.4239344596862793,-30.200047757086523,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Carmo_da_Mata,2020-12-31T00:00:00,1.68,1.2237507104873655,-27.157695804323467,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Carmo_do_Rio_Claro,2020-12-31T00:00:00,2.7847803881511743,2.050069808959961,-26.383070719590577,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Carmopolis_de_Minas,2020-12-31T00:00:00,1.981818181818182,1.5753414630889893,-20.510293146885868,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Cassia,2020-12-31T00:00:00,2.1679245283018864,1.7724814414978027,-18.24062976554956,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Catas_Altas_da_Noruega,2020-12-31T00:00:00,1.0,0.8377729654312134,-16.222703456878662,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Chale,2020-12-31T00:00:00,1.71015625,1.2924221754074097,-24.42666128270972,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Claudio,2020-12-31T00:00:00,2.76,1.3729190826416016,-50.25655497675356,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Conceicao_da_Barra_de_Minas,2020-12-31T00:00:00,1.911042944785276,1.8027946949005127,-5.66435464886562,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Conceicao_de_Ipanema,2020-12-31T00:00:00,1.500533617929563,1.482920527458191,-1.1737884617123475,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Coqueiral,2020-12-31T00:00:00,2.160028248587571,1.605520725250244,-25.671308868294474,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Corrego_Danta,2020-12-31T00:00:00,1.8000000000000005,1.572763204574585,-12.624266412523072,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Cristais,2020-12-31T00:00:00,1.92,1.902531385421753,-0.9098236759503646,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Desterro_de_Entre_Rios,2020-12-31T00:00:00,2.4,1.9904184341430664,-17.06589857737223,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Divinesia,2020-12-31T00:00:00,2.1,2.57405686378479,22.57413637070428,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Divino,2020-12-31T00:00:00,1.8000483851457605,1.1933354139328003,-33.70537015669336,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Doresopolis,2020-12-31T00:00:00,1.8000000000000005,1.6003365516662598,-11.092413796318915,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Durande,2020-12-31T00:00:00,2.4,1.6326706409454346,-31.97205662727356,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Eloi_Mendes,2020-12-31T00:00:00,2.109128416709644,1.7629802227020264,-16.41190698798832,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Entre_Folhas,2020-12-31T00:00:00,1.26046511627907,0.9929978847503662,-21.219725010579825,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Entre_Rios_de_Minas,2020-12-31T00:00:00,1.8000000000000005,2.01269793510437,11.816551950242768,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ervalia,2020-12-31T00:00:00,1.7999614197530858,1.4072149991989136,-21.81971325852352,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Espera_Feliz,2020-12-31T00:00:00,2.04,1.349875569343567,-33.82962895374672,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Faria_Lemos,2020-12-31T00:00:00,1.44031007751938,1.15181565284729,-20.03002194978449,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ferros,2020-12-31T00:00:00,1.2,0.9117820858955384,-24.018159508705136,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Fervedouro,2020-12-31T00:00:00,1.5,1.1616641283035278,-22.55572477976481,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Guape,2020-12-31T00:00:00,1.847986942328618,1.820296049118042,-1.4984355449872986,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ibituruna,2020-12-31T00:00:00,1.8000000000000005,1.4778460264205933,-17.89744297663372,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ilicinea,2020-12-31T00:00:00,2.09995817649519,2.0499796867370605,-2.379975483204293,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Itapecerica,2020-12-31T00:00:00,1.8000000000000005,1.347317099571228,-25.149050023820674,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ituiutaba,2020-12-31T00:00:00,0.75,1.2400846481323242,65.34461975097656,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Itumirim,2020-12-31T00:00:00,2.050724637681159,1.4088153839111328,-31.301581985958887,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Lajinha,2020-12-31T00:00:00,1.9200446677833607,1.337654948234558,-30.332092233101832,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Lavras,2020-12-31T00:00:00,1.8000000000000005,1.414764404296875,-21.40197753906251,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Luisburgo,2020-12-31T00:00:00,2.1,1.553852081298828,-26.007043747674853,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Machado,2020-12-31T00:00:00,2.211839166046165,1.592883586883545,-27.98375165175556,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Manhuacu,2020-12-31T00:00:00,1.6800182481751822,1.1997504234313965,-28.58706000755929,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Manhumirim,2020-12-31T00:00:00,1.68,1.4025471210479736,-16.515052318572994,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Martins_Soares,2020-12-31T00:00:00,1.8000000000000005,1.6042602062225342,-10.874432987637004,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Matipo,2020-12-31T00:00:00,1.56,1.2092396020889282,-22.48464089173537,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Medeiros,2020-12-31T00:00:00,1.980113636363636,1.6461305618286133,-16.866864022428686,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Miradouro,2020-12-31T00:00:00,1.5,1.3373525142669678,-10.84316571553548,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Mirai,2020-12-31T00:00:00,1.5011494252873558,1.1862201690673828,-20.979207726751657,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Moeda,2020-12-31T00:00:00,1.2,1.0691388845443726,-10.905092954635617,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Muriae,2020-12-31T00:00:00,1.56,1.254213809967041,-19.601678848266605,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Mutum,2020-12-31T00:00:00,1.65,1.5245723724365234,-7.601674397786454,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Nazareno,2020-12-31T00:00:00,2.1,1.6347819566726685,-22.15324015844436,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Nepomuceno,2020-12-31T00:00:00,1.920040743570155,1.5366266965866089,-19.96905785814836,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Oliveira,2020-12-31T00:00:00,1.947151898734177,1.5568392276763916,-20.045311889202043,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Orizania,2020-12-31T00:00:00,1.679901960784314,1.4040076732635498,-16.423237424638426,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Paraguacu,2020-12-31T00:00:00,2.3413259668508286,1.740753412246704,-25.6509586066701,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Passa_Tempo,2020-12-31T00:00:00,1.511111111111111,1.5482892990112305,2.4603212580961364,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Perdoes,2020-12-31T00:00:00,1.92,1.5971975326538086,-16.812628507614132,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Pimenta,2020-12-31T00:00:00,1.8000000000000005,1.7667732238769531,-1.845932006835952,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Piranga,2020-12-31T00:00:00,2.4,2.011116743087769,-16.20346903800964,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Piumhi,2020-12-31T00:00:00,1.7399966931216928,1.4316486120224,-17.721187765368214,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ponte_Nova,2020-12-31T00:00:00,1.333333333333333,1.2567957639694214,-5.740317702293376,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Porto_Firme,2020-12-31T00:00:00,1.56,1.1613000631332395,-25.55768826068977,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Raul_Soares,2020-12-31T00:00:00,1.320083682008368,1.148437261581421,-13.0026923873345,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Reduto,2020-12-31T00:00:00,1.8000000000000005,1.3650068044662476,-24.16628864076404,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ribeirao_Vermelho,2020-12-31T00:00:00,1.92,1.4605867862701416,-23.927771548430123,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ritapolis,2020-12-31T00:00:00,2.101769911504425,1.7495720386505127,-16.757204055786133,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Rosario_da_Limeira,2020-12-31T00:00:00,1.5,1.169918656349182,-22.005422910054527,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santa_Barbara_do_Leste,2020-12-31T00:00:00,1.4400953029271608,1.2773157358169556,-11.303388517366656,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santa_Margarida,2020-12-31T00:00:00,1.8000000000000005,1.3034143447875977,-27.588091956244583,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santa_Rita_de_Minas,2020-12-31T00:00:00,1.5,1.386063814163208,-7.5957457224528,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santa_Rita_do_Itueto,2020-12-31T00:00:00,1.77,1.5409345626831057,-12.941550130897998,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santana_da_Vargem,2020-12-31T00:00:00,2.22,1.83228600025177,-17.464594583253593,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santana_do_Jacare,2020-12-31T00:00:00,1.8000000000000005,1.2928245067596436,-28.176416291130923,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santana_do_Manhuacu,2020-12-31T00:00:00,1.8000000000000005,1.4484087228775024,-19.532848729027656,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Domingos_das_Dores,2020-12-31T00:00:00,1.56,1.6343019008636477,4.762942363054321,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Francisco_de_Paula,2020-12-31T00:00:00,1.62,1.518992900848389,-6.235006120469841,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Francisco_do_Gloria,2020-12-31T00:00:00,1.679693486590038,1.1279017925262451,-32.850737260640955,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Joao_do_Manhuacu,2020-12-31T00:00:00,1.8000000000000005,1.3779733180999756,-23.44592677222359,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Jose_do_Mantimento,2020-12-31T00:00:00,1.8000000000000005,1.458147048950195,-18.99183061387805,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Roque_de_Minas,2020-12-31T00:00:00,1.8000000000000005,1.5191926956176758,-15.600405799018024,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Tiago,2020-12-31T00:00:00,2.69971671388102,1.8288908004760744,-32.256195952984875,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Tomas_de_Aquino,2020-12-31T00:00:00,2.099966151415999,1.9232603311538696,-8.41469850087714,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Senador_Firmino,2020-12-31T00:00:00,1.376237623762376,1.672377347946167,21.518066289613586,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Senhora_de_Oliveira,2020-12-31T00:00:00,1.8000000000000005,1.7274751663208008,-4.029157426622193,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sericita,2020-12-31T00:00:00,2.5200000000000005,1.202663540840149,-52.27525631586711,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Simonesia,2020-12-31T00:00:00,1.8000000000000005,1.2518327236175537,-30.45373757680258,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Tapirai,2020-12-31T00:00:00,1.799716914366596,1.7163317203521729,-4.633239447203303,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Tombos,2020-12-31T00:00:00,1.5,1.1225255727767944,-25.16496181488037,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Tres_Pontas,2020-12-31T00:00:00,2.26,2.0305285453796387,-10.153604186741644,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ubaporanga,2020-12-31T00:00:00,1.6200873362445412,1.3448786735534668,-16.9872732496647,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Vargem_Bonita,2020-12-31T00:00:00,1.8031222896790973,1.9846585988998413,10.06788670185269,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Vermelho_Novo,2020-12-31T00:00:00,1.320080321285141,1.1474517583847046,-13.077125695834704,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Vicosa,2020-12-31T00:00:00,1.8000000000000005,1.2129346132278442,-32.61474370956422,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Vieiras,2020-12-31T00:00:00,1.8000000000000005,1.2497293949127195,-30.570589171515586,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Aguanil,2021-12-31T00:00:00,1.7382352941176469,1.790393590927124,3.000646516958076,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Alfenas,2021-12-31T00:00:00,1.6209774981853378,2.040879726409912,25.90426015750677,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Alto_Caparao,2021-12-31T00:00:00,1.08,1.5478827953338623,43.32248104943169,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Alto_Jequitiba,2021-12-31T00:00:00,0.9,1.5613356828689575,73.48174254099527,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Amparo_do_Serra,2021-12-31T00:00:00,1.2,1.3505570888519287,12.546424070994064,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Araponga,2021-12-31T00:00:00,1.2,1.307286500930786,8.940541744232181,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Astolfo_Dutra,2021-12-31T00:00:00,1.75,1.4502966403961182,-17.125906263078964,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Bambui,2021-12-31T00:00:00,1.439910025706941,1.5599359273910522,8.335652890893863,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Boa_Esperanca,2021-12-31T00:00:00,1.570339108544351,1.929295301437378,22.858514504282244,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Bom_Jesus_do_Galho,2021-12-31T00:00:00,1.079802955665025,1.2340129613876345,14.281309836537254,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Bom_Sucesso,2021-12-31T00:00:00,1.37989417989418,1.577011227607727,14.284939424026229,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Caete,2021-12-31T00:00:00,1.222222222222222,1.2759907245635986,4.399241100658081,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Caiana,2021-12-31T00:00:00,0.9,1.2878100872039795,43.09000968933105,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Cajuri,2021-12-31T00:00:00,1.2602564102564102,1.4211872816085815,12.769692742084803,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Camacho,2021-12-31T00:00:00,1.5,1.5595109462738037,3.9673964182535806,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Campo_do_Meio,2021-12-31T00:00:00,1.255813953488372,1.8618905544281008,48.26165526001542,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Campos_Altos,2021-12-31T00:00:00,1.2,1.7390282154083252,44.91901795069377,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Campos_Gerais,2021-12-31T00:00:00,1.589070422535211,2.140666961669922,34.71190019726696,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Cana_Verde,2021-12-31T00:00:00,1.32,1.3498941659927368,2.2647095449043,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Canaa,2021-12-31T00:00:00,1.2,1.438427209854126,19.868934154510505,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Candeias,2021-12-31T00:00:00,1.199963309484498,1.6469125747680664,37.24691094726697,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Caparao,2021-12-31T00:00:00,0.9,1.631934642791748,81.32607142130533,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Capitolio,2021-12-31T00:00:00,1.2,1.6476218700408936,37.3018225034078,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Caputira,2021-12-31T00:00:00,1.38008658008658,1.3070456981658936,-5.292485484215362,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Carangola,2021-12-31T00:00:00,1.02,1.3407011032104492,31.44128462847541,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Caratinga,2021-12-31T00:00:00,1.26,1.5040225982666016,19.36687287830171,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Carmo_da_Mata,2021-12-31T00:00:00,1.32,1.3352396488189695,1.154518849921944,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Carmo_do_Rio_Claro,2021-12-31T00:00:00,1.643702081051479,2.18434739112854,32.891928306813924,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Carmopolis_de_Minas,2021-12-31T00:00:00,1.98,1.678664207458496,-15.218979421288063,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Cassia,2021-12-31T00:00:00,1.314977578475336,1.7525718212127686,33.27769612960289,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Catas_Altas_da_Noruega,2021-12-31T00:00:00,1.0,0.8778223395347595,-12.217766046524048,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Chale,2021-12-31T00:00:00,1.26016713091922,1.391429424285889,10.416260680511511,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Claudio,2021-12-31T00:00:00,1.800653594771242,1.8156659603118896,0.8337175781194466,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Conceicao_da_Barra_de_Minas,2021-12-31T00:00:00,1.462068965517241,1.8310630321502688,25.23780172725897,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Conceicao_de_Ipanema,2021-12-31T00:00:00,1.29,1.4015300273895264,8.645738557327624,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Coqueiral,2021-12-31T00:00:00,1.5,1.7463257312774658,16.42171541849772,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Corrego_Danta,2021-12-31T00:00:00,1.08029197080292,1.5634942054748535,44.72885550679384,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Cristais,2021-12-31T00:00:00,1.318776371308017,1.819633841514588,37.978953907841046,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Desterro_de_Entre_Rios,2021-12-31T00:00:00,1.5,1.996970295906067,33.131353060404464,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Divinesia,2021-12-31T00:00:00,2.1,2.082646369934082,-0.8263633364722885,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Divino,2021-12-31T00:00:00,1.08,1.332764983177185,23.40416510899861,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Doresopolis,2021-12-31T00:00:00,1.2,1.6192771196365356,34.93975996971131,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Durande,2021-12-31T00:00:00,1.32,1.8275842666625977,38.45335353504528,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Eloi_Mendes,2021-12-31T00:00:00,1.037885462555066,1.743879318237305,68.02232820028362,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Entre_Folhas,2021-12-31T00:00:00,0.8400000000000001,1.0431702136993408,24.186930202302467,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Entre_Rios_de_Minas,2021-12-31T00:00:00,1.8000000000000005,1.954508066177368,8.583781454298215,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ervalia,2021-12-31T00:00:00,1.08,1.4740794897079468,36.488841639624695,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Espera_Feliz,2021-12-31T00:00:00,0.78,1.5178734064102173,94.59915466797656,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Faria_Lemos,2021-12-31T00:00:00,0.7199999999999999,1.2248413562774658,70.11685503853695,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ferros,2021-12-31T00:00:00,1.205128205128205,0.9643092751502992,-19.98284738114539,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Fervedouro,2021-12-31T00:00:00,1.15006090133983,1.2473183870315552,8.456724820261211,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Guape,2021-12-31T00:00:00,1.376842105263158,1.8389323949813845,33.56160361103324,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ibituruna,2021-12-31T00:00:00,1.6000000000000003,1.5811989307403564,-1.1750668287277417,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ilicinea,2021-12-31T00:00:00,1.560035211267606,1.990244507789612,27.57689656071542,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Itapecerica,2021-12-31T00:00:00,1.222784810126582,1.534455418586731,25.48859013286932,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ituiutaba,2021-12-31T00:00:00,2.25,1.219967246055603,-45.77923350863987,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Itumirim,2021-12-31T00:00:00,1.2595155709342565,1.540851354598999,22.336824582173254,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Lajinha,2021-12-31T00:00:00,1.260014255167498,1.4867374897003174,17.993703928586132,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Lavras,2021-12-31T00:00:00,1.259900454447089,1.5581178665161133,23.66991860479148,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Luisburgo,2021-12-31T00:00:00,1.3799999999999997,1.6919946670532229,22.60830920675529,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Machado,2021-12-31T00:00:00,1.444286871961102,1.6911113262176514,17.089711126530062,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Manhuacu,2021-12-31T00:00:00,0.9,1.3739069700241089,52.65633000267877,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Manhumirim,2021-12-31T00:00:00,1.2,1.5097825527191162,25.815212726593025,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Martins_Soares,2021-12-31T00:00:00,1.2,1.6698167324066162,39.151394367218025,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Matipo,2021-12-31T00:00:00,1.07995337995338,1.3272887468338013,22.90241148104915,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Medeiros,2021-12-31T00:00:00,1.500161864681127,1.646385669708252,9.747201849995443,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Miradouro,2021-12-31T00:00:00,1.2,1.3730709552764893,14.422579606374107,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Mirai,2021-12-31T00:00:00,1.019512195121951,1.2842977046966553,25.971784431968604,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Moeda,2021-12-31T00:00:00,1.8000000000000005,1.1530780792236328,-35.94010670979819,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Muriae,2021-12-31T00:00:00,0.9,1.292879581451416,43.65328682793511,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Mutum,2021-12-31T00:00:00,1.319934249850568,1.5213724374771118,15.261228932376673,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Nazareno,2021-12-31T00:00:00,1.5,1.838164567947388,22.544304529825844,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Nepomuceno,2021-12-31T00:00:00,1.379962721342032,1.689303636550903,22.41661390012284,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Oliveira,2021-12-31T00:00:00,1.537805840568272,1.6429893970489502,6.839846338586495,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Orizania,2021-12-31T00:00:00,1.08,1.4957022666931152,38.490950619732885,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Paraguacu,2021-12-31T00:00:00,0.9712280701754386,1.8011932373046875,85.45522855196386,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Passa_Tempo,2021-12-31T00:00:00,1.511627906976744,1.4977059364318848,-0.9209918975829946,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Perdoes,2021-12-31T00:00:00,1.44017094017094,1.639445424079895,13.836863274390351,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Pimenta,2021-12-31T00:00:00,1.3502325581395351,1.7524943351745603,29.79203653549102,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Piranga,2021-12-31T00:00:00,2.1,2.0240602493286133,-3.616178603399372,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Piumhi,2021-12-31T00:00:00,1.5,1.531468152999878,2.0978768666585283,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ponte_Nova,2021-12-31T00:00:00,1.2,1.3023486137390137,8.52905114491781,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Porto_Firme,2021-12-31T00:00:00,1.319607843137255,1.2596842050552368,-4.541018636230211,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Raul_Soares,2021-12-31T00:00:00,1.320079522862823,1.2119213342666626,-8.193308563835648,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Reduto,2021-12-31T00:00:00,1.2,1.5003079175949097,25.025659799575813,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ribeirao_Vermelho,2021-12-31T00:00:00,1.258899676375405,1.551555633544922,23.246964207038733,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ritapolis,2021-12-31T00:00:00,1.5,1.7720117568969729,18.134117126464844,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Rosario_da_Limeira,2021-12-31T00:00:00,0.9,1.171898603439331,30.21095593770345,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santa_Barbara_do_Leste,2021-12-31T00:00:00,1.319917440660475,1.26454496383667,-4.195146993140509,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santa_Margarida,2021-12-31T00:00:00,0.9,1.4804291725158691,64.49213027954102,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santa_Rita_de_Minas,2021-12-31T00:00:00,1.2,1.352378010749817,12.698167562484748,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santa_Rita_do_Itueto,2021-12-31T00:00:00,1.3799999999999997,1.5765104293823242,14.23988618712497,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santana_da_Vargem,2021-12-31T00:00:00,1.44,1.9535943269729608,35.66627270645566,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santana_do_Jacare,2021-12-31T00:00:00,1.2,1.462910771369934,21.90923094749452,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Santana_do_Manhuacu,2021-12-31T00:00:00,1.32,1.5697760581970217,18.9224286512895,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Domingos_das_Dores,2021-12-31T00:00:00,1.2,1.5762832164764404,31.356934706370044,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Francisco_de_Paula,2021-12-31T00:00:00,1.3200867052023115,1.464511513710022,10.940554733151124,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Francisco_do_Gloria,2021-12-31T00:00:00,0.78,1.2296946048736572,57.65315447098169,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Joao_do_Manhuacu,2021-12-31T00:00:00,0.9,1.5357537269592283,70.63930299546983,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Jose_do_Mantimento,2021-12-31T00:00:00,1.500917431192661,1.5590827465057373,3.875317462790537,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Roque_de_Minas,2021-12-31T00:00:00,1.2,1.5719246864318848,30.993723869323738,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Tiago,2021-12-31T00:00:00,1.5,1.9619896411895752,30.799309412638348,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sao_Tomas_de_Aquino,2021-12-31T00:00:00,1.2,1.7728760242462158,47.739668687184654,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Senador_Firmino,2021-12-31T00:00:00,1.563636363636364,1.4883146286010742,-4.817087705745272,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Senhora_de_Oliveira,2021-12-31T00:00:00,1.62037037037037,1.613738179206848,-0.4093009403773499,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Sericita,2021-12-31T00:00:00,0.9,1.474661111831665,63.85123464796278,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Simonesia,2021-12-31T00:00:00,1.08,1.4025225639343262,29.86320036428945,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Tapirai,2021-12-31T00:00:00,1.396563119629874,1.6946842670440674,21.34677217404992,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Tombos,2021-12-31T00:00:00,0.8497959183673469,1.1771806478500366,38.52510025132516,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Tres_Pontas,2021-12-31T00:00:00,1.3500296384113808,2.0181455612182617,49.488981856211126,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Ubaporanga,2021-12-31T00:00:00,1.319867549668874,1.4137548208236694,7.113385822566029,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Vargem_Bonita,2021-12-31T00:00:00,1.519565217391304,1.8609167337417605,22.46376216326323,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Vermelho_Novo,2021-12-31T00:00:00,0.96,1.2034050226211548,25.35468985637031,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Vicosa,2021-12-31T00:00:00,0.9006711409395973,1.3088445663452148,45.31880803683831,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_0_2021,Vieiras,2021-12-31T00:00:00,0.78,1.2936859130859375,65.85716834435095,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:16
V43_cluster_1_2021,Almenara,2020-12-31T00:00:00,0.78,1.2556370496749878,60.97910893269074,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Alpinopolis,2020-12-31T00:00:00,2.765998457979954,2.402599334716797,-13.138081195047103,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Alterosa,2020-12-31T00:00:00,1.980023501762632,1.891491174697876,-4.471276577573127,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Andradas,2020-12-31T00:00:00,2.568,1.440100908279419,-43.92130419472668,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Araguari,2020-12-31T00:00:00,1.979964695498676,2.084799528121948,5.294782925251535,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Arapua,2020-12-31T00:00:00,1.5,1.4854180812835691,-0.9721279144287108,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Araxa,2020-12-31T00:00:00,1.786008230452675,1.6484167575836182,-7.703854356493273,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Arceburgo,2020-12-31T00:00:00,1.8387096774193543,1.7113145589828491,-6.928506441283629,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Areado,2020-12-31T00:00:00,2.078746484531941,1.845781326293945,-11.207001910598592,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Bom_Jesus_da_Penha,2020-12-31T00:00:00,1.986087924318308,2.0602807998657227,3.735628953732263,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Botelhos,2020-12-31T00:00:00,1.716062736614386,2.148633003234864,25.2071359275532,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Botumirim,2020-12-31T00:00:00,0.9200000000000002,0.770592987537384,-16.23989265898001,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Cabo_Verde,2020-12-31T00:00:00,2.249052581714827,1.7113823890686035,-23.90651943923285,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Campestre,2020-12-31T00:00:00,2.138000770416025,1.5116314888000488,-29.2969623904342,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Capetinga,2020-12-31T00:00:00,2.213808463251671,2.325866937637329,5.061796277581536,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Carmo_do_Paranaiba,2020-12-31T00:00:00,1.947480785653288,1.91767156124115,-1.5306556363347312,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Cascalho_Rico,2020-12-31T00:00:00,2.478504672897196,1.923353672027588,-22.398626354844662,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Claraval,2020-12-31T00:00:00,2.796008294453085,1.823328256607056,-34.78816710864912,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Conceicao_da_Aparecida,2020-12-31T00:00:00,2.243948871362524,1.9762142896652224,-11.931402943897451,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Coromandel,2020-12-31T00:00:00,1.818934240362812,1.896867156028748,4.284537282138978,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Corrego_Fundo,2020-12-31T00:00:00,1.5,2.026997327804565,35.133155186971024,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Cruzeiro_da_Fortaleza,2020-12-31T00:00:00,2.1,1.809550642967224,-13.830921763465524,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Delfinopolis,2020-12-31T00:00:00,1.8000000000000005,1.5484734773635864,-13.97369570202299,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Divisa_Nova,2020-12-31T00:00:00,1.8000000000000005,1.9349899291992188,7.499440511067693,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Dom_Cavati,2020-12-31T00:00:00,0.7894736842105263,1.2998958826065063,64.6534784634908,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Dores_do_Turvo,2020-12-31T00:00:00,1.625,1.0129114389419556,-37.666988372802734,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Estrela_do_Indaia,2020-12-31T00:00:00,1.8000000000000005,1.487628936767578,-17.353947957356784,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Estrela_do_Sul,2020-12-31T00:00:00,2.0627027027027025,1.856789231300354,-9.982702360962913,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Guaranesia,2020-12-31T00:00:00,1.564686285397002,1.513518452644348,-3.270165606370819,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Guarani,2020-12-31T00:00:00,1.127272727272727,1.877136707305908,66.52019177713706,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Guarda-Mor,2020-12-31T00:00:00,1.7994350282485878,1.9145866632461548,6.39932163094799,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Guaxupe,2020-12-31T00:00:00,1.7400000000000002,1.5010254383087158,-13.73417021214278,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Guimarania,2020-12-31T00:00:00,2.149930843706777,1.6811914443969729,-21.80253382018711,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Ibia,2020-12-31T00:00:00,1.746,1.6131634712219238,-7.608048612719139,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Ibiraci,2020-12-31T00:00:00,2.6315194346289745,1.725736379623413,-34.42053450512595,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Indianopolis,2020-12-31T00:00:00,1.8000000000000005,2.320250988006592,28.902832667032857,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Itamogi,2020-12-31T00:00:00,2.400049176297025,2.0280098915100098,-15.501319242175915,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Itanhomi,2020-12-31T00:00:00,1.26,1.4308245182037354,13.5575014447409,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Jacui,2020-12-31T00:00:00,1.68,1.8298436403274536,8.919264305205576,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Jacutinga,2020-12-31T00:00:00,1.8000000000000005,1.7400673627853394,-3.3295909563700503,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Juruaia,2020-12-31T00:00:00,1.92,1.6907916069030762,-11.93793714046478,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Lagoa_Dourada,2020-12-31T00:00:00,2.1,1.894952893257141,-9.764147940136144,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Lagoa_Formosa,2020-12-31T00:00:00,2.5494505494505484,2.0096585750579834,-21.17287485763941,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Lagoa_Grande,2020-12-31T00:00:00,2.4,2.1098082065582275,-12.091324726740517,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Matutina,2020-12-31T00:00:00,1.82995951417004,1.8247300386428835,-0.2857700122141057,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Monte_Belo,2020-12-31T00:00:00,1.8000000000000005,1.6113892793655396,-10.478373368581147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Monte_Carmelo,2020-12-31T00:00:00,1.98,1.8808164596557613,-5.009269714355457,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Monte_Santo_de_Minas,2020-12-31T00:00:00,2.123987903619159,1.6668694019317627,-21.52170927661553,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Muzambinho,2020-12-31T00:00:00,1.764006791171477,1.8077423572540283,2.4793309357673485,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Nova_Resende,2020-12-31T00:00:00,2.353040067245727,1.8554848432540887,-21.14520831657721,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Passos,2020-12-31T00:00:00,1.62,2.2955474853515625,41.70046205873842,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Patis,2020-12-31T00:00:00,3.6000000000000005,3.985459327697754,10.707203547159814,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Patos_de_Minas,2020-12-31T00:00:00,1.941759465478842,1.689143419265747,-13.009646699510188,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Patrocinio,2020-12-31T00:00:00,1.7479986236953782,1.571121096611023,-10.118859631046224,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Pedrinopolis,2020-12-31T00:00:00,2.158490566037736,1.5985589027404783,-25.940889995414896,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Perdizes,2020-12-31T00:00:00,2.050845253576073,2.052910804748535,0.1007170662369871,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Piracema,2020-12-31T00:00:00,1.333333333333333,1.3049039840698242,-2.132201194763162,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Ponto_dos_Volantes,2020-12-31T00:00:00,0.631578947368421,0.6274459958076477,-0.6543839971224412,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Pratapolis,2020-12-31T00:00:00,2.402298850574712,1.781409740447998,-25.84562324450914,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Pratinha,2020-12-31T00:00:00,2.1,1.62929368019104,-22.41458665756952,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Presidente_Kubitschek,2020-12-31T00:00:00,1.789473684210526,1.1297073364257812,-36.8692959056181,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Presidente_Olegario,2020-12-31T00:00:00,1.9814229249011863,2.042588949203491,3.086974695488345,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Quartel_Geral,2020-12-31T00:00:00,3.6000000000000005,3.574228048324585,-0.7158875465393213,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Rio_Paranaiba,2020-12-31T00:00:00,1.818897637795276,1.5075219869613647,-17.11892106316308,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Rio_Vermelho,2020-12-31T00:00:00,0.9333333333333332,1.0900219678878784,16.788067987987,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Romaria,2020-12-31T00:00:00,2.330769230769231,2.0742087364196777,-11.00754596219205,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sacramento,2020-12-31T00:00:00,1.8321428571428573,1.462303876876831,-20.186143172414685,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Santa_Rosa_da_Serra,2020-12-31T00:00:00,2.1,1.568225622177124,-25.32258942013696,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Santo_Antonio_do_Amparo,2020-12-31T00:00:00,2.1,1.6584826707839966,-21.024634724571595,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sao_Goncalo_do_Abaete,2020-12-31T00:00:00,2.44,2.2460286617279053,-7.949645011151421,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sao_Gotardo,2020-12-31T00:00:00,1.38027397260274,1.5781952142715454,14.33927217330567,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sao_Joao_Batista_do_Gloria,2020-12-31T00:00:00,1.5,1.7443801164627075,16.292007764180504,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sao_Pedro_da_Uniao,2020-12-31T00:00:00,2.1,1.8156088590621948,-13.542435282752631,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sao_Sebastiao_do_Paraiso,2020-12-31T00:00:00,1.929071661237785,1.7171618938446045,-10.985064559872752,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Serra_do_Salitre,2020-12-31T00:00:00,1.8000000000000005,1.677334904670715,-6.814727518293607,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Tapira,2020-12-31T00:00:00,2.1013698630137,1.6731362342834473,-20.37878415730665,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Tiros,2020-12-31T00:00:00,1.740235294117647,1.7707078456878662,1.7510592776288567,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Tupaciguara,2020-12-31T00:00:00,2.1,2.301931381225586,9.61578005836123,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Uberaba,2020-12-31T00:00:00,2.5325581395348844,2.408802032470703,-4.886604778475476,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Uberlandia,2020-12-31T00:00:00,1.920754716981132,2.380094289779663,23.914535715444163,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Unai,2020-12-31T00:00:00,2.3398907103825146,2.745762348175049,17.34575191873744,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Varginha,2020-12-31T00:00:00,1.899977968715576,1.813315987586975,-4.561209790615928,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Varjao_de_Minas,2020-12-31T00:00:00,2.519786096256685,2.4888811111450195,-1.2264924057473403,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Virginopolis,2020-12-31T00:00:00,1.626666666666667,1.3561041355133057,-16.632942488936138,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Almenara,2021-12-31T00:00:00,0.78,1.1840318441390991,51.79895437680757,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Alpinopolis,2021-12-31T00:00:00,1.67993145468393,2.0535850524902344,22.24219308261033,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Alterosa,2021-12-31T00:00:00,1.08,1.5142593383789062,40.20919799804686,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Andradas,2021-12-31T00:00:00,1.26,1.5737439393997192,24.900312650771365,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Araguari,2021-12-31T00:00:00,1.8600340136054423,1.9545927047729488,5.083707635228497,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Arapua,2021-12-31T00:00:00,1.32,1.429435968399048,8.290603666594528,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Araxa,2021-12-31T00:00:00,1.250440917107584,1.6087021827697754,28.650795152392444,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Arceburgo,2021-12-31T00:00:00,1.354903268845897,1.31353497505188,-3.053228576919339,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Areado,2021-12-31T00:00:00,1.5228426395939092,1.6943485736846924,11.262223005294755,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Bom_Jesus_da_Penha,2021-12-31T00:00:00,1.519900497512438,1.8921078443527224,24.48892854824783,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Botelhos,2021-12-31T00:00:00,1.26,1.4224119186401367,12.889834812709264,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Botumirim,2021-12-31T00:00:00,0.7241379310344828,0.9549596905708312,31.875385840733845,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Cabo_Verde,2021-12-31T00:00:00,1.32,1.7631655931472778,33.57315099600589,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Campestre,2021-12-31T00:00:00,1.2899602385685882,1.7235078811645508,33.60938032299749,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Capetinga,2021-12-31T00:00:00,1.6399999999999997,1.7844831943511963,8.809950875072966,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Carmo_do_Paranaiba,2021-12-31T00:00:00,1.541078066914498,1.91106915473938,24.00858825832669,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Cascalho_Rico,2021-12-31T00:00:00,1.9411764705882348,1.8786661624908447,-3.220227992895855,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Claraval,2021-12-31T00:00:00,1.050113378684807,1.6599406003952026,58.07251236758467,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Conceicao_da_Aparecida,2021-12-31T00:00:00,1.62,1.9889098405838013,22.77221238171612,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Coromandel,2021-12-31T00:00:00,1.249939246658566,1.850919365882873,48.080746390746114,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Corrego_Fundo,2021-12-31T00:00:00,1.1984126984126982,1.5006128549575806,25.21670180440741,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Cruzeiro_da_Fortaleza,2021-12-31T00:00:00,1.800184162062615,1.8630053997039795,3.489711717571469,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Delfinopolis,2021-12-31T00:00:00,0.9,1.4591176509857178,62.12418344285753,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Divisa_Nova,2021-12-31T00:00:00,1.2601319509896318,1.4973411560058594,18.82415606000131,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Dom_Cavati,2021-12-31T00:00:00,0.6000000000000001,1.0912426710128784,81.87377850214638,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Dores_do_Turvo,2021-12-31T00:00:00,1.5,1.0109180212020874,-32.60546525319417,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Estrela_do_Indaia,2021-12-31T00:00:00,1.8000000000000005,1.4989079236984253,-16.727337572309718,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Estrela_do_Sul,2021-12-31T00:00:00,1.8000000000000005,1.7079797983169556,-5.112233426835816,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Guaranesia,2021-12-31T00:00:00,1.031014249790444,1.4568791389465332,41.30543193196867,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Guarani,2021-12-31T00:00:00,0.953846153846154,1.4880999326705933,56.01047681223957,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Guarda-Mor,2021-12-31T00:00:00,1.7994350282485878,1.794718623161316,-0.2621047725108711,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Guaxupe,2021-12-31T00:00:00,1.02,1.5034606456756592,47.39810251722149,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Guimarania,2021-12-31T00:00:00,1.541380188439012,1.721057653427124,11.656920618012824,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Ibia,2021-12-31T00:00:00,1.2,1.5074520111083984,25.62100092569988,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Ibiraci,2021-12-31T00:00:00,1.327034071867436,1.6800382137298584,26.60098556216164,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Indianopolis,2021-12-31T00:00:00,1.919956379498364,1.82818341255188,-4.779950624214802,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Itamogi,2021-12-31T00:00:00,1.260064724919094,1.6945273876190186,34.47939253500018,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Itanhomi,2021-12-31T00:00:00,0.9606060606060604,1.3580961227416992,41.37909164188039,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Jacui,2021-12-31T00:00:00,0.96,1.6223459243774414,68.99436712265017,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Jacutinga,2021-12-31T00:00:00,1.32014652014652,1.4467092752456665,9.587023346855448,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Juruaia,2021-12-31T00:00:00,1.5,1.6454880237579346,9.699201583862305,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Lagoa_Dourada,2021-12-31T00:00:00,1.2,2.0871052742004395,73.92543951670329,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Lagoa_Formosa,2021-12-31T00:00:00,1.4830188679245278,1.9793803691864007,33.4696686601518,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Lagoa_Grande,2021-12-31T00:00:00,0.6000000000000001,1.7667217254638672,194.45362091064447,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Matutina,2021-12-31T00:00:00,1.502024291497976,1.6399859189987185,9.185046359213835,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Monte_Belo,2021-12-31T00:00:00,1.56,1.5496087074279783,-0.6661084982065089,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Monte_Carmelo,2021-12-31T00:00:00,1.8000000000000005,1.6996769905090332,-5.573500527275948,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Monte_Santo_de_Minas,2021-12-31T00:00:00,1.200018932222643,1.4323487281799316,19.36051088185529,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Muzambinho,2021-12-31T00:00:00,1.199937762564182,1.5332859754562378,27.7804585614269,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Nova_Resende,2021-12-31T00:00:00,1.3800031392246113,1.8768712282180784,36.0048520811804,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Passos,2021-12-31T00:00:00,0.99,1.3798469305038452,39.37847782867124,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Patis,2021-12-31T00:00:00,2.111111111111112,3.745493888854981,77.41813157734114,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Patos_de_Minas,2021-12-31T00:00:00,1.7224109589041097,1.6759798526763916,-2.6957042967991813,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Patrocinio,2021-12-31T00:00:00,1.4369951534733445,1.5333741903305054,6.706984127552862,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Pedrinopolis,2021-12-31T00:00:00,1.514285714285714,1.149975299835205,-24.058234916543046,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Perdizes,2021-12-31T00:00:00,1.261308677098151,1.5956673622131348,26.50887060289089,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Piracema,2021-12-31T00:00:00,1.2,1.2630610466003418,5.255087216695154,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Ponto_dos_Volantes,2021-12-31T00:00:00,0.5375,0.644518256187439,19.910373244174696,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Pratapolis,2021-12-31T00:00:00,0.9602272727272728,1.8335602283477783,90.95065099953192,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Pratinha,2021-12-31T00:00:00,1.35,1.6457736492156982,21.909159201162822,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Presidente_Kubitschek,2021-12-31T00:00:00,0.7368421052631579,1.1634551286697388,57.89748174803599,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Presidente_Olegario,2021-12-31T00:00:00,1.637164750957854,1.9312193393707275,17.961209355431787,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Quartel_Geral,2021-12-31T00:00:00,2.4571428571428573,2.748771905899048,11.868624077286825,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Rio_Paranaiba,2021-12-31T00:00:00,1.080031384856807,1.5203440189361572,40.7685036058214,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Rio_Vermelho,2021-12-31T00:00:00,0.7777777777777777,1.010989546775818,29.98437029974803,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Romaria,2021-12-31T00:00:00,2.052631578947369,1.7683868408203125,-13.8478205754207,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sacramento,2021-12-31T00:00:00,1.25645342312009,1.448796033859253,15.308375718498816,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Santa_Rosa_da_Serra,2021-12-31T00:00:00,1.5,1.5773942470550537,5.159616470336914,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Santo_Antonio_do_Amparo,2021-12-31T00:00:00,1.3799999999999997,1.5760364532470703,14.20554009036744,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sao_Goncalo_do_Abaete,2021-12-31T00:00:00,1.67887323943662,2.047993421554565,21.9861853442736,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sao_Gotardo,2021-12-31T00:00:00,1.26027397260274,1.5204532146453855,20.64465724903601,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sao_Joao_Batista_do_Gloria,2021-12-31T00:00:00,1.110749185667752,1.3597264289855957,22.41525328404048,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sao_Pedro_da_Uniao,2021-12-31T00:00:00,1.479945054945055,1.6435916423797607,11.057612367966009,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Sao_Sebastiao_do_Paraiso,2021-12-31T00:00:00,1.14450771643146,1.542894959449768,34.80861136178856,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Serra_do_Salitre,2021-12-31T00:00:00,1.4676384839650147,1.547168254852295,5.418893804993465,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Tapira,2021-12-31T00:00:00,0.6000000000000001,1.7285513877868652,188.09189796447748,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Tiros,2021-12-31T00:00:00,1.2,1.795512318611145,49.62602655092876,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Tupaciguara,2021-12-31T00:00:00,1.887700534759358,2.1163930892944336,12.114874701999751,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Uberaba,2021-12-31T00:00:00,2.0302325581395344,1.872890949249268,-7.749930334801232,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Uberlandia,2021-12-31T00:00:00,1.77962962962963,1.809236764907837,1.6636683715121527,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Unai,2021-12-31T00:00:00,2.639892904953146,2.554624319076538,-3.23000170638063,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Varginha,2021-12-31T00:00:00,1.2,1.5306930541992188,27.55775451660157,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Varjao_de_Minas,2021-12-31T00:00:00,2.390254805543138,2.40664291381836,0.6856218105792043,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_1_2021,Virginopolis,2021-12-31T00:00:00,1.202380952380952,1.334429383277893,10.982245737963408,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:55:51
V43_cluster_2_2021,Abre_Campo,2020-12-31T00:00:00,1.5,1.0960792303085327,-26.928051312764484,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Aimores,2020-12-31T00:00:00,2.063157894736842,1.2352503538131714,-40.1281716264024,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Alvarenga,2020-12-31T00:00:00,0.9,0.7051830291748047,-21.64633009168837,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Andrelandia,2020-12-31T00:00:00,1.8000000000000005,1.3956845998764038,-22.461966673533134,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Antonio_Dias,2020-12-31T00:00:00,1.333333333333333,0.9406795501708984,-29.4490337371826,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Antonio_Prado_de_Minas,2020-12-31T00:00:00,1.5,0.821966290473938,-45.20224730173747,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Bocaiuva,2020-12-31T00:00:00,1.622950819672131,1.7644565105438232,8.7190375183568,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Bom_Jesus_do_Amparo,2020-12-31T00:00:00,1.5,1.7480528354644775,16.536855697631836,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Campo_Belo,2020-12-31T00:00:00,1.8000000000000005,1.5109498500823977,-16.058341662089042,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Capela_Nova,2020-12-31T00:00:00,1.8000000000000005,1.940300703048706,7.794483502705876,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Capitao_Eneas,2020-12-31T00:00:00,3.0,1.3368901014328003,-55.436996618906655,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Casa_Grande,2020-12-31T00:00:00,1.553846153846154,1.3645364046096802,-12.183300693436438,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Cataguases,2020-12-31T00:00:00,1.25,0.637782096862793,-48.97743225097656,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Caxambu,2020-12-31T00:00:00,1.3265306122448983,1.15338933467865,-13.05218861653257,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Coimbra,2020-12-31T00:00:00,1.8000000000000005,1.4500455856323242,-19.441911909315333,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Conselheiro_Pena,2020-12-31T00:00:00,1.55981308411215,1.225386142730713,-21.44019336597589,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Corrego_Novo,2020-12-31T00:00:00,1.2545454545454553,0.8641390800476074,-31.11934869185741,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Cruzilia,2020-12-31T00:00:00,1.2,1.320155382156372,10.01294851303101,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Divisopolis,2020-12-31T00:00:00,1.34029484029484,1.5454590320587158,15.30739249274014,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Esmeraldas,2020-12-31T00:00:00,2.096153846153846,2.2513904571533203,7.405783277039152,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Espirito_Santo_do_Dourado,2020-12-31T00:00:00,1.619148936170213,1.1687490940093994,-27.817073037527244,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Eugenopolis,2020-12-31T00:00:00,1.8000000000000005,1.130372166633606,-37.20154629813301,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Felicio_dos_Santos,2020-12-31T00:00:00,3.548821548821549,1.6784658432006836,-52.70357159102438,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Formiga,2020-12-31T00:00:00,1.441791044776119,2.01348876953125,39.65191258653601,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Guaraciaba,2020-12-31T00:00:00,1.2,1.2034348249435425,0.2862354119618771,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Guiricema,2020-12-31T00:00:00,2.4,1.6176918745040894,-32.59617189566294,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Iapu,2020-12-31T00:00:00,1.0,1.332725167274475,33.27251672744751,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Ijaci,2020-12-31T00:00:00,2.458064516129032,1.3070335388183594,-46.82671954938433,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Imbe_de_Minas,2020-12-31T00:00:00,1.439877300613497,1.0742708444595337,-25.391500789559444,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Inhapim,2020-12-31T00:00:00,1.8000000000000005,1.279420256614685,-28.92109685473973,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Irai_de_Minas,2020-12-31T00:00:00,3.3595092024539883,1.3989052772521973,-58.35983195907448,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Itamarati_de_Minas,2020-12-31T00:00:00,1.2,0.8522133827209473,-28.982218106587727,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Jequeri,2020-12-31T00:00:00,2.1,1.2750102281570437,-39.28522723061698,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Lamim,2020-12-31T00:00:00,2.387096774193548,1.4239656925201416,-40.34738315118325,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Mar_de_Espanha,2020-12-31T00:00:00,1.8000000000000005,1.738722562789917,-3.404302067226848,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Mata_Verde,2020-12-31T00:00:00,1.319688109161793,1.412134289741516,7.0051537130573145,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Monte_Alegre_de_Minas,2020-12-31T00:00:00,3.0,2.341906309127808,-21.93645636240641,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Nova_Era,2020-12-31T00:00:00,1.565217391304348,1.5484204292297363,-1.0731392436557388,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Nova_Ponte,2020-12-31T00:00:00,1.8591549295774648,1.4663424491882324,-21.12855008154204,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Paula_Candido,2020-12-31T00:00:00,1.62,1.3056429624557495,-19.404755403966085,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Pecanha,2020-12-31T00:00:00,2.0,1.2652385234832764,-36.73807382583617,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Pedra_Bonita,2020-12-31T00:00:00,1.7400000000000002,0.9509324431419371,-45.34871016425648,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Pedra_Dourada,2020-12-31T00:00:00,1.44,1.0383892059326172,-27.88963847690158,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Pedra_do_Anta,2020-12-31T00:00:00,1.5,1.1922574043273926,-20.51617304484049,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Piedade_de_Caratinga,2020-12-31T00:00:00,1.8000000000000005,1.4099549055099487,-21.66917191611397,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Pocrane,2020-12-31T00:00:00,1.258064516129032,1.120596170425415,-10.926971068749044,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Presidente_Bernardes,2020-12-31T00:00:00,1.5,1.303599834442139,-13.093344370524088,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sabinopolis,2020-12-31T00:00:00,1.0,1.0788934230804443,7.889342308044434,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Santa_Barbara,2020-12-31T00:00:00,1.142857142857143,1.1478075981140137,0.4331648349761823,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Santo_Antonio_do_Grama,2020-12-31T00:00:00,1.695652173913043,1.183916449546814,-30.17928630877762,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Domingos_do_Prata,2020-12-31T00:00:00,0.8846153846153846,0.8523547053337097,-3.646859397058898,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Geraldo,2020-12-31T00:00:00,1.8000000000000005,0.9200390577316284,-48.88671901490954,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Jose_da_Barra,2020-12-31T00:00:00,2.537024221453287,2.172269821166992,-14.377253366440154,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Jose_do_Alegre,2020-12-31T00:00:00,1.359090909090909,1.8816933631896973,38.4523544821851,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Miguel_do_Anta,2020-12-31T00:00:00,1.5,1.184044361114502,-21.063709259033203,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Sebastiao_da_Vargem_Alegre,2020-12-31T00:00:00,1.8000000000000005,1.049379825592041,-41.701120800442176,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Sebastiao_do_Anta,2020-12-31T00:00:00,1.8000000000000005,1.3485790491104126,-25.0789417160882,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Senhora_dos_Remedios,2020-12-31T00:00:00,1.8000000000000005,1.434828281402588,-20.28731769985624,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Teixeiras,2020-12-31T00:00:00,1.5,1.0487059354782104,-30.086270968119305,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Visconde_do_Rio_Branco,2020-12-31T00:00:00,1.0,0.8414899110794067,-15.851008892059326,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Abre_Campo,2021-12-31T00:00:00,1.2,1.7078372240066528,42.31976866722108,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Aimores,2021-12-31T00:00:00,1.634328358208955,1.6828773021697998,2.970574653311969,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Alvarenga,2021-12-31T00:00:00,0.6304878048780488,0.8251785039901733,30.87937587465032,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Andrelandia,2021-12-31T00:00:00,1.4,1.813090324401856,29.50645174298969,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Antonio_Dias,2021-12-31T00:00:00,1.5,1.230663537979126,-17.955764134724937,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Antonio_Prado_de_Minas,2021-12-31T00:00:00,0.9,1.3910413980484009,54.560155338711205,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Bocaiuva,2021-12-31T00:00:00,1.7407407407407405,1.7214233875274658,-1.1097202909753527,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Bom_Jesus_do_Amparo,2021-12-31T00:00:00,1.2,2.224207878112793,85.35065650939943,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Campo_Belo,2021-12-31T00:00:00,1.5,2.099960803985596,39.99738693237305,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Capela_Nova,2021-12-31T00:00:00,1.8000000000000005,2.25315809249878,25.175449583265497,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Capitao_Eneas,2021-12-31T00:00:00,2.0,3.368565559387207,68.42827796936038,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Casa_Grande,2021-12-31T00:00:00,1.3230769230769233,2.13053035736084,61.02845724238903,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Cataguases,2021-12-31T00:00:00,1.25,1.180619716644287,-5.550422668457031,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Caxambu,2021-12-31T00:00:00,1.4387755102040822,1.9225115776062007,33.62137206057279,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Coimbra,2021-12-31T00:00:00,1.501182033096927,2.193173885345459,46.09646511828803,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Conselheiro_Pena,2021-12-31T00:00:00,1.2898734177215188,1.5668082237243652,21.46992117195768,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Corrego_Novo,2021-12-31T00:00:00,1.8000000000000005,1.5724502801895142,-12.64165110058256,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Cruzilia,2021-12-31T00:00:00,1.5027322404371577,1.6092309951782229,7.087008042769054,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Divisopolis,2021-12-31T00:00:00,0.9595505617977528,1.829344749450684,90.64599847905252,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Esmeraldas,2021-12-31T00:00:00,1.7115384615384608,2.12716007232666,24.28350984380492,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Espirito_Santo_do_Dourado,2021-12-31T00:00:00,1.200854700854701,1.8007268905639648,49.95376953450808,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Eugenopolis,2021-12-31T00:00:00,1.5,1.7314510345458984,15.430068969726562,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Felicio_dos_Santos,2021-12-31T00:00:00,3.542087542087541,4.338405609130859,22.48160322356136,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Formiga,2021-12-31T00:00:00,1.347576301615799,2.385071039199829,76.98968409729612,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Guaraciaba,2021-12-31T00:00:00,2.4,1.243579387664795,-48.184192180633545,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Guiricema,2021-12-31T00:00:00,2.1,2.3576736450195312,12.270173572358626,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Iapu,2021-12-31T00:00:00,1.5578947368421048,1.4371646642684937,-7.749565469252068,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Ijaci,2021-12-31T00:00:00,1.2375,2.130125999450684,72.13139389500472,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Imbe_de_Minas,2021-12-31T00:00:00,1.2,1.2627413272857666,5.228443940480554,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Inhapim,2021-12-31T00:00:00,1.2,1.7723733186721802,47.69777655601502,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Irai_de_Minas,2021-12-31T00:00:00,2.472300469483568,4.393679618835449,77.71624740067425,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Itamarati_de_Minas,2021-12-31T00:00:00,1.2,1.161378264427185,-3.2184779644012416,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Jequeri,2021-12-31T00:00:00,1.5,2.175102949142456,45.00686327616374,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Lamim,2021-12-31T00:00:00,1.2800000000000002,2.790977716445923,118.04513409733768,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Mar_de_Espanha,2021-12-31T00:00:00,1.4199999999999997,2.641477584838867,86.01954822808928,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Mata_Verde,2021-12-31T00:00:00,1.319277108433735,1.8149772882461548,37.573620935553286,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Monte_Alegre_de_Minas,2021-12-31T00:00:00,2.765957446808511,5.350717544555664,93.44901891855092,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Nova_Era,2021-12-31T00:00:00,1.5,1.8271253108978271,21.80835405985514,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Nova_Ponte,2021-12-31T00:00:00,2.5482352941176467,2.2511839866638184,-11.657138104143772,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Paula_Candido,2021-12-31T00:00:00,1.5,1.721078872680664,14.738591512044271,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Pecanha,2021-12-31T00:00:00,1.807692307692308,2.2039270401000977,21.91936817575005,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Pedra_Bonita,2021-12-31T00:00:00,1.08,2.2273969650268555,106.24045972470884,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Pedra_Dourada,2021-12-31T00:00:00,0.96,1.5069862604141235,56.97773545980456,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Pedra_do_Anta,2021-12-31T00:00:00,0.9,1.5711913108825684,74.57681232028537,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Piedade_de_Caratinga,2021-12-31T00:00:00,1.2,1.6594257354736328,38.28547795613607,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Pocrane,2021-12-31T00:00:00,1.3228346456692908,1.2492854595184326,-5.559968238785112,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Presidente_Bernardes,2021-12-31T00:00:00,1.56,1.6995385885238647,8.944781315632353,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sabinopolis,2021-12-31T00:00:00,1.2,1.613717555999756,34.47646299997966,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Santa_Barbara,2021-12-31T00:00:00,0.9333333333333332,1.3150161504745483,40.8945875508445,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Santo_Antonio_do_Grama,2021-12-31T00:00:00,1.9130434782608696,2.568570375442505,34.26617871631274,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Domingos_do_Prata,2021-12-31T00:00:00,0.903846153846154,1.125765323638916,24.55275921111411,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Geraldo,2021-12-31T00:00:00,1.5,2.8505282402038574,90.03521601359049,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Jose_da_Barra,2021-12-31T00:00:00,1.682068965517241,3.268682718276977,94.32513085287488,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Jose_do_Alegre,2021-12-31T00:00:00,1.7823529411764714,1.711874008178711,-3.954263567531111,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Miguel_do_Anta,2021-12-31T00:00:00,1.2603053435114495,1.711827516555786,35.82641106529867,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Sebastiao_da_Vargem_Alegre,2021-12-31T00:00:00,1.020238095238095,1.8350327014923096,79.86318194323692,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Sao_Sebastiao_do_Anta,2021-12-31T00:00:00,1.5,1.7903074026107788,19.35382684071859,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Senhora_dos_Remedios,2021-12-31T00:00:00,1.5,2.246645927429199,49.77639516194661,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Teixeiras,2021-12-31T00:00:00,1.32,1.7571429014205933,33.116886471257054,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_2_2021,Visconde_do_Rio_Branco,2021-12-31T00:00:00,1.25,1.2459118366241455,-0.3270530700683594,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:56:26
V43_cluster_3_2021,Aiuruoca,2020-12-31T00:00:00,1.8000000000000005,1.6550322771072388,-8.053762382931193,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Albertina,2020-12-31T00:00:00,1.68,1.7525957822799685,4.321177516664782,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Baependi,2020-12-31T00:00:00,1.67948717948718,1.7952677011489868,6.893802053145749,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Bandeira_do_Sul,2020-12-31T00:00:00,1.5,1.6793015003204346,11.953433354695637,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Borda_da_Mata,2020-12-31T00:00:00,1.62,1.844622611999512,13.865593333303186,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Brazopolis,2020-12-31T00:00:00,1.680327868852459,1.5289552211761477,-9.008518544639028,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Bueno_Brandao,2020-12-31T00:00:00,1.8000000000000005,1.7864621877670288,-0.7521006796095253,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Cachoeira_de_Minas,2020-12-31T00:00:00,1.8596638655462183,1.9842939376831048,6.701752636371236,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Caldas,2020-12-31T00:00:00,1.68,1.6235851049423218,-3.3580294677189384,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Cambuquira,2020-12-31T00:00:00,1.800145348837209,1.949655532836914,8.305450673540339,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Campanha,2020-12-31T00:00:00,1.6833930704898452,1.938844919204712,15.174818834233028,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Careacu,2020-12-31T00:00:00,1.320454545454546,1.4921818971633911,13.005169492580348,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Carmo_da_Cachoeira,2020-12-31T00:00:00,1.8000000000000005,1.910329341888428,6.129407882690414,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Carmo_de_Minas,2020-12-31T00:00:00,1.7400000000000002,1.6859910488128662,-3.1039627119042525,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Carrancas,2020-12-31T00:00:00,1.785714285714286,1.9269942045211792,7.911675453186016,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Carvalhopolis,2020-12-31T00:00:00,1.679765395894428,1.6033577919006348,-4.548706871837207,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Conceicao_das_Pedras,2020-12-31T00:00:00,1.739921976592978,1.66603684425354,-4.246462389314488,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Conceicao_do_Rio_Verde,2020-12-31T00:00:00,1.8000000000000005,2.242953062057495,24.6085034476386,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Conceicao_dos_Ouros,2020-12-31T00:00:00,1.5028571428571431,1.512263536453247,0.6259007145696548,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Congonhal,2020-12-31T00:00:00,1.619354838709677,1.9033517837524407,17.537659952840038,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Cordislandia,2020-12-31T00:00:00,1.62,1.872929692268372,15.612943967183424,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Cristina,2020-12-31T00:00:00,2.100263852242744,1.6194288730621338,-22.89402727505669,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Datas,2020-12-31T00:00:00,2.0,2.0057291984558105,0.2864599227905496,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Dom_Vicoso,2020-12-31T00:00:00,1.4285714285714288,1.6067225933074951,12.47058153152464,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Fama,2020-12-31T00:00:00,1.8000000000000005,1.711763858795166,-4.9020078447130135,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Fortaleza_de_Minas,2020-12-31T00:00:00,1.68,1.5704267024993896,-6.522220089322041,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Heliodora,2020-12-31T00:00:00,1.8000000000000005,1.789112567901611,-0.6048573387993854,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Ibitiura_de_Minas,2020-12-31T00:00:00,1.68,1.856624722480774,10.513376338141308,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Inconfidentes,2020-12-31T00:00:00,2.46,2.3077337741851807,-6.189683976212167,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Ingai,2020-12-31T00:00:00,1.6791666666666667,1.9582576751708984,16.620804476678813,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Itajuba,2020-12-31T00:00:00,1.5882352941176472,2.1741788387298584,36.89274169780589,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Itutinga,2020-12-31T00:00:00,1.8000000000000005,1.6196813583374023,-10.017702314588773,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Jesuania,2020-12-31T00:00:00,1.5,1.7558183670043943,17.05455780029297,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Lambari,2020-12-31T00:00:00,1.8000970402717127,1.639212131500244,-8.937568651698024,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Luminarias,2020-12-31T00:00:00,1.860103626943005,2.370138645172119,27.41970989365435,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Maria_da_Fe,2020-12-31T00:00:00,1.7333333333333332,1.7343130111694336,0.0565198751596398,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Monsenhor_Paulo,2020-12-31T00:00:00,2.1,1.8555073738098145,-11.642506009056458,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Monte_Siao,2020-12-31T00:00:00,1.8000000000000005,1.7166262865066528,-4.631872971852634,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Natercia,2020-12-31T00:00:00,1.4399193548387097,1.7875316143035889,24.141092228308604,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Olimpio_Noronha,2020-12-31T00:00:00,1.5595854922279788,1.643477201461792,5.379102950872407,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Ouro_Fino,2020-12-31T00:00:00,2.099920063948841,1.6113438606262207,-23.26641912282444,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Paraisopolis,2020-12-31T00:00:00,2.4,1.7126104831695557,-28.64122986793518,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Pedralva,2020-12-31T00:00:00,1.68,1.96707820892334,17.08798862638928,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Pirangucu,2020-12-31T00:00:00,1.333333333333333,1.362834930419922,2.212619781494164,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Piranguinho,2020-12-31T00:00:00,1.458181818181818,1.537597894668579,5.446239659316533,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Poco_Fundo,2020-12-31T00:00:00,1.740033329060377,1.459810495376587,-16.10445208168003,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Pocos_de_Caldas,2020-12-31T00:00:00,1.8000000000000005,1.6617251634597778,-7.681935363345689,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Pouso_Alegre,2020-12-31T00:00:00,1.6375,1.5735783576965332,-3.903611743723161,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Pouso_Alto,2020-12-31T00:00:00,1.45,1.717785120010376,18.467939311060416,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Santa_Rita_de_Caldas,2020-12-31T00:00:00,1.8000000000000005,2.00927472114563,11.62637339697942,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Santa_Rita_do_Sapucai,2020-12-31T00:00:00,1.68,1.660688400268555,-1.1494999840145983,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Bento_Abade,2020-12-31T00:00:00,1.8000000000000005,2.385540723800659,32.530040211147714,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Goncalo_do_Sapucai,2020-12-31T00:00:00,2.4,2.035907030105591,-15.170540412267048,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Joao_da_Mata,2020-12-31T00:00:00,1.6399999999999997,1.4316856861114502,-12.70209231027741,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Joao_del_Rei,2020-12-31T00:00:00,1.9709821428571432,1.9245203733444207,-2.357290231223033,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Lourenco,2020-12-31T00:00:00,3.3928571428571423,1.783280849456787,-47.44014338443153,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Sebastiao_da_Bela_Vista,2020-12-31T00:00:00,1.5,1.4823503494262695,-1.1766433715820312,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Tome_das_Letras,2020-12-31T00:00:00,2.133763094278808,1.630486011505127,-23.586361771984063,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Senador_Jose_Bento,2020-12-31T00:00:00,1.620618556701031,1.3844547271728516,-14.57245004086094,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Serrania,2020-12-31T00:00:00,1.8000000000000005,1.7064752578735352,-5.195819007025839,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Silvianopolis,2020-12-31T00:00:00,1.50032154340836,1.300508975982666,-13.317982955291654,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Soledade_de_Minas,2020-12-31T00:00:00,3.2000000000000006,1.93660855293274,-39.48098272085191,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Tocos_do_Moji,2020-12-31T00:00:00,1.441340782122905,1.5994758605957031,10.971387227376308,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Tres_Coracoes,2020-12-31T00:00:00,2.1,2.2650399208068848,7.859043847946889,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Turvolandia,2020-12-31T00:00:00,1.6202531645569618,2.0309367179870605,25.34687556326391,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Virginia,2020-12-31T00:00:00,1.5333333333333332,1.672558307647705,9.079889629198163,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Aiuruoca,2021-12-31T00:00:00,1.2,1.7051661014556885,42.09717512130738,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Albertina,2021-12-31T00:00:00,1.56,1.81658947467804,16.448043248592274,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Baependi,2021-12-31T00:00:00,1.079646017699115,1.760556936264038,63.06797852281666,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Bandeira_do_Sul,2021-12-31T00:00:00,1.8011695906432754,1.6892621517181396,-6.213042875389029,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Borda_da_Mata,2021-12-31T00:00:00,1.2,1.7894327640533447,49.1193970044454,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Brazopolis,2021-12-31T00:00:00,1.200934579439252,1.5014506578445437,25.02351781273633,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Bueno_Brandao,2021-12-31T00:00:00,1.2,1.8672337532043457,55.60281276702882,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Cachoeira_de_Minas,2021-12-31T00:00:00,1.5602040816326532,2.060741424560547,32.08153015495982,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Caldas,2021-12-31T00:00:00,1.2,1.7190693616867063,43.25578014055888,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Cambuquira,2021-12-31T00:00:00,1.2,1.8100932836532595,50.84110697110494,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Campanha,2021-12-31T00:00:00,1.325757575757576,1.7363487482070925,30.970305579049228,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Careacu,2021-12-31T00:00:00,1.2,1.450663924217224,20.888660351435348,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Carmo_da_Cachoeira,2021-12-31T00:00:00,1.439980158730159,1.779224872589111,23.55898529588865,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Carmo_de_Minas,2021-12-31T00:00:00,1.3799999999999997,1.6497397422790527,19.54635813616327,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Carrancas,2021-12-31T00:00:00,1.214285714285714,1.7337844371795654,42.78224776772896,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Carvalhopolis,2021-12-31T00:00:00,1.14,1.6425358057022097,44.08208821949207,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Conceicao_das_Pedras,2021-12-31T00:00:00,1.5,1.6294304132461548,8.62869421641032,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Conceicao_do_Rio_Verde,2021-12-31T00:00:00,1.500115340253749,1.93581223487854,29.04422632936288,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Conceicao_dos_Ouros,2021-12-31T00:00:00,1.26,1.5201797485351562,20.649186391679063,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Congonhal,2021-12-31T00:00:00,1.6215384615384625,1.837766408920288,13.334740588063257,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Cordislandia,2021-12-31T00:00:00,1.319791666666667,1.7891185283660889,35.560677760966456,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Cristina,2021-12-31T00:00:00,1.68,1.7124121189117432,1.9292927923656684,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Datas,2021-12-31T00:00:00,1.0,2.0759146213531494,107.59146213531494,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Dom_Vicoso,2021-12-31T00:00:00,1.2,1.5565223693847656,29.71019744873048,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Fama,2021-12-31T00:00:00,1.5,1.6402029991149902,9.346866607666016,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Fortaleza_de_Minas,2021-12-31T00:00:00,1.26,1.534743070602417,21.805005603366425,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Heliodora,2021-12-31T00:00:00,1.2,1.7068414688110352,42.236789067586265,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Ibitiura_de_Minas,2021-12-31T00:00:00,1.9198795180722887,1.813485026359558,-5.541727525670963,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Inconfidentes,2021-12-31T00:00:00,1.5,2.610107898712158,74.0071932474772,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Ingai,2021-12-31T00:00:00,1.320075757575758,1.8032200336456297,36.5997385602428,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Itajuba,2021-12-31T00:00:00,1.181818181818182,1.908705830574036,61.505877971649134,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Itutinga,2021-12-31T00:00:00,1.2,1.6332170963287354,36.101424694061286,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Jesuania,2021-12-31T00:00:00,1.2,1.630371332168579,35.86427768071493,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Lambari,2021-12-31T00:00:00,1.199954863461973,1.649760603904724,37.48522166450685,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Luminarias,2021-12-31T00:00:00,1.380229885057471,2.04551649093628,48.2011448296605,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Maria_da_Fe,2021-12-31T00:00:00,1.444444444444444,1.6768290996551514,16.088168437664365,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Monsenhor_Paulo,2021-12-31T00:00:00,1.41,1.8161567449569704,28.805442904749647,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Monte_Siao,2021-12-31T00:00:00,1.5,1.785094976425171,19.006331761678062,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Natercia,2021-12-31T00:00:00,1.4399193548387097,1.6212992668151855,12.59653267156707,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Olimpio_Noronha,2021-12-31T00:00:00,1.20026525198939,1.5279996395111084,27.30516333606361,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Ouro_Fino,2021-12-31T00:00:00,1.2,1.8702346086502075,55.85288405418397,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Paraisopolis,2021-12-31T00:00:00,1.2,1.891520857810974,57.62673815091451,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Pedralva,2021-12-31T00:00:00,1.5,1.7903718948364258,19.358126322428383,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Pirangucu,2021-12-31T00:00:00,1.333333333333333,1.3326380252838137,-0.052148103713967,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Piranguinho,2021-12-31T00:00:00,1.380549682875264,1.4884002208709717,7.812144635829981,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Poco_Fundo,2021-12-31T00:00:00,0.9601760412194076,1.5437994003295898,60.78295375595816,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Pocos_de_Caldas,2021-12-31T00:00:00,1.4199999999999997,1.769938349723816,24.64354575519833,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Pouso_Alegre,2021-12-31T00:00:00,1.2,1.627917766571045,35.65981388092042,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Pouso_Alto,2021-12-31T00:00:00,1.5047619047619047,1.6293736696243286,8.281161588958549,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Santa_Rita_de_Caldas,2021-12-31T00:00:00,1.682051282051282,2.0444085597991943,21.542582061232583,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Santa_Rita_do_Sapucai,2021-12-31T00:00:00,1.5,1.7677892446517944,17.85261631011963,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Bento_Abade,2021-12-31T00:00:00,1.32,2.122334718704224,60.78293323516844,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Goncalo_do_Sapucai,2021-12-31T00:00:00,1.62,2.0534725189208984,26.75756289635175,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Joao_da_Mata,2021-12-31T00:00:00,0.8995327102803738,1.5004209280014038,66.80004082716904,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Joao_del_Rei,2021-12-31T00:00:00,1.296875,1.838022232055664,41.72701548381024,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Lourenco,2021-12-31T00:00:00,1.5087719298245608,2.569841384887696,70.32669644023105,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Sebastiao_da_Bela_Vista,2021-12-31T00:00:00,1.2,1.5531632900238037,29.43027416865032,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Sao_Tome_das_Letras,2021-12-31T00:00:00,1.2,1.812327146530152,51.02726221084596,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Senador_Jose_Bento,2021-12-31T00:00:00,1.32,1.4993979930877686,13.590757052103672,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Serrania,2021-12-31T00:00:00,1.08,1.7678463459014893,63.689476472360106,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Silvianopolis,2021-12-31T00:00:00,0.9601265822784812,1.347313642501831,40.32666810500282,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Soledade_de_Minas,2021-12-31T00:00:00,1.7204819277108432,2.421860933303833,40.76642679567098,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Tocos_do_Moji,2021-12-31T00:00:00,1.259776536312849,1.6108613014221191,27.868812840159364,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Tres_Coracoes,2021-12-31T00:00:00,1.5,2.172272205352783,44.81814702351888,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Turvolandia,2021-12-31T00:00:00,1.3797385620915028,1.95189905166626,41.46876120556032,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_3_2021,Virginia,2021-12-31T00:00:00,1.433333333333333,1.6312906742095947,13.810977270436876,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:00
V43_cluster_4_2021,Abadia_dos_Dourados,2020-12-31T00:00:00,2.584210526315789,1.7488694190979004,-32.324808629612804,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Acucena,2020-12-31T00:00:00,1.166666666666667,0.9094489812850952,-22.04723017556329,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Agua_Boa,2020-12-31T00:00:00,1.33,1.0964831113815308,-17.55766079838115,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Aguas_Vermelhas,2020-12-31T00:00:00,3.6000000000000005,2.3899874687194824,-33.61145920223661,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Angelandia,2020-12-31T00:00:00,1.8400349650349648,1.1375343799591064,-38.17865412478776,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Aricanduva,2020-12-31T00:00:00,1.3196428571428571,0.9915543794631958,-24.861914411449305,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Ataleia,2020-12-31T00:00:00,1.204819277108434,0.8210697770118713,-31.8512085080147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Bandeira,2020-12-31T00:00:00,1.083333333333333,0.9496676325798036,-12.338372377248886,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Berilo,2020-12-31T00:00:00,0.8428571428571429,0.7863558530807495,-6.703542854826329,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Berizal,2020-12-31T00:00:00,3.340236686390532,1.1905392408370972,-64.35763831683447,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Bonfinopolis_de_Minas,2020-12-31T00:00:00,3.3,2.394976854324341,-27.4249438083533,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Buritis,2020-12-31T00:00:00,3.3,2.535109281539917,-23.178506620002512,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Buritizeiro,2020-12-31T00:00:00,3.0,2.388730525970459,-20.37564913431803,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Capelinha,2020-12-31T00:00:00,1.434123222748815,1.124867558479309,-21.56409291502504,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Carai,2020-12-31T00:00:00,1.5225,0.8269821405410767,-45.68261802685868,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Caranaiba,2020-12-31T00:00:00,1.645161290322581,1.202948808670044,-26.879582218095383,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Catuji,2020-12-31T00:00:00,1.197183098591549,0.8840053677558899,-26.15955163450801,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Congonhas_do_Norte,2020-12-31T00:00:00,1.2,1.03182053565979,-14.014955361684162,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Coroaci,2020-12-31T00:00:00,1.8000000000000005,1.471864938735962,-18.229725625779903,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Cuparaque,2020-12-31T00:00:00,1.018518518518519,1.0219968557357788,0.3415094722400493,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Diamantina,2020-12-31T00:00:00,2.3453815261044184,1.7099614143371582,-27.092398601035573,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Formoso,2020-12-31T00:00:00,3.0,2.629400491714477,-12.35331694285075,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Franciscopolis,2020-12-31T00:00:00,1.8000000000000005,1.35861337184906,-24.52147934171889,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Frei_Gaspar,2020-12-31T00:00:00,1.08,0.8425971269607544,-21.98174750363386,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Grao_Mogol,2020-12-31T00:00:00,0.7749999999999999,1.1410728693008425,47.23520894204418,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Indaiabira,2020-12-31T00:00:00,3.0,2.4591164588928223,-18.02945137023925,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Itabirinha,2020-12-31T00:00:00,0.7992424242424243,0.8379384875297546,4.841592752538013,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Itacambira,2020-12-31T00:00:00,0.75,1.90425705909729,153.900941212972,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Itaipe,2020-12-31T00:00:00,0.9594594594594597,0.8118050694465637,-15.389330790076464,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Itamarandiba,2020-12-31T00:00:00,1.7196261682242993,1.372769832611084,-20.170449951420668,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Itambacuri,2020-12-31T00:00:00,1.091304347826087,1.002183437347412,-8.166457932308862,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Jequitinhonha,2020-12-31T00:00:00,2.4,1.5246766805648804,-36.47180497646332,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Joao_Pinheiro,2020-12-31T00:00:00,3.0,2.56084942817688,-14.638352394104004,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Jose_Goncalves_de_Minas,2020-12-31T00:00:00,1.5,0.8887072801589966,-40.75284798940022,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Juiz_de_Fora,2020-12-31T00:00:00,1.222222222222222,1.2775591611862185,4.527567733417868,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Ladainha,2020-12-31T00:00:00,1.242268041237113,0.9358707070350648,-24.66434972414829,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Malacacheta,2020-12-31T00:00:00,1.8000000000000005,1.4794409275054932,-17.80883736080595,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Mantena,2020-12-31T00:00:00,0.7,0.6306505799293518,-9.907060010092591,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Minas_Novas,2020-12-31T00:00:00,1.0,0.9421571493148804,-5.784285068511963,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Monte_Formoso,2020-12-31T00:00:00,0.6000000000000001,0.8423131704330444,40.38552840550739,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Ninheira,2020-12-31T00:00:00,3.0,2.7750403881073,-7.498653729756673,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Nova_Belem,2020-12-31T00:00:00,1.1,0.9007651209831238,-18.11226172880693,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Novo_Cruzeiro,2020-12-31T00:00:00,1.19727047146402,1.0040639638900757,-16.13724819736779,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Novorizonte,2020-12-31T00:00:00,1.235294117647059,1.0434308052062988,-15.531791959490112,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Ouro_Verde_de_Minas,2020-12-31T00:00:00,1.2,1.1315430402755735,-5.704746643702185,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Padre_Paraiso,2020-12-31T00:00:00,0.7219512195121951,0.6809782981872559,-5.675303291630097,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Paracatu,2020-12-31T00:00:00,2.7000000000000006,2.4694881439208984,-8.537476151077856,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Pedra_Azul,2020-12-31T00:00:00,1.0,1.1252678632736206,12.52678632736206,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Pirapora,2020-12-31T00:00:00,3.6000000000000005,2.8846631050109863,-19.870469305250392,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Pote,2020-12-31T00:00:00,0.6571428571428573,0.7344417572021484,11.762876095979092,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Rio_Pardo_de_Minas,2020-12-31T00:00:00,3.4487179487179493,2.4938714504241943,-27.6869988352836,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Santa_Barbara_do_Monte_Verde,2020-12-31T00:00:00,1.6000000000000003,1.1508328914642334,-28.07294428348543,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Santa_Maria_do_Suacui,2020-12-31T00:00:00,0.8,0.7691786289215088,-3.852671384811407,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Santo_Antonio_do_Retiro,2020-12-31T00:00:00,0.975,1.2230360507965088,25.439594953488097,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Sao_Goncalo_do_Rio_Preto,2020-12-31T00:00:00,3.6000000000000005,1.934437870979309,-46.2656146950192,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Sao_Joao_do_Manteninha,2020-12-31T00:00:00,0.9166666666666664,0.7562127709388733,-17.504061352122903,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Sao_Joao_do_Paraiso,2020-12-31T00:00:00,3.146938775510204,1.5200443267822266,-51.69768351989033,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Sao_Sebastiao_do_Maranhao,2020-12-31T00:00:00,0.8148148148148149,0.8733958005905151,7.189484617926849,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Senador_Modestino_Goncalves,2020-12-31T00:00:00,3.6000000000000005,1.5897634029388428,-55.83990547392104,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Setubinha,2020-12-31T00:00:00,1.0,0.8887499570846558,-11.125004291534424,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Taiobeiras,2020-12-31T00:00:00,3.240083507306889,2.1499476432800293,-33.645301473509406,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Teofilo_Otoni,2020-12-31T00:00:00,1.09375,0.826559841632843,-24.428814479282924,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Turmalina,2020-12-31T00:00:00,1.320338983050847,1.0854352712631226,-17.7911668748084,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Urucuia,2020-12-31T00:00:00,2.4,2.096491813659668,-12.646174430847164,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Vargem_Grande_do_Rio_Pardo,2020-12-31T00:00:00,1.8000000000000005,1.6348785161972046,-9.17341576682198,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Varzea_da_Palma,2020-12-31T00:00:00,3.0,3.103785991668701,3.4595330556233725,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Abadia_dos_Dourados,2021-12-31T00:00:00,1.8000000000000005,1.988521099090576,10.473394393920882,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Acucena,2021-12-31T00:00:00,0.9,0.9767221808433532,8.524686760372584,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Agua_Boa,2021-12-31T00:00:00,0.6171428571428572,1.2026915550231934,94.88057604542485,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Aguas_Vermelhas,2021-12-31T00:00:00,3.0,2.830991268157959,-5.633624394734701,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Angelandia,2021-12-31T00:00:00,1.5133433283358322,1.4596824645996094,-3.5458486340460285,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Aricanduva,2021-12-31T00:00:00,0.8394736842105264,1.0743186473846436,27.975262070897973,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Ataleia,2021-12-31T00:00:00,0.6266666666666667,0.9228745698928832,47.26721859992818,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Bandeira,2021-12-31T00:00:00,0.96,0.949038028717041,-1.141872008641546,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Berilo,2021-12-31T00:00:00,1.8017241379310345,0.8051601648330688,-55.31168463127464,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Berizal,2021-12-31T00:00:00,3.541935483870968,1.654406189918518,-53.29089992033328,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Bonfinopolis_de_Minas,2021-12-31T00:00:00,3.0,2.6948883533477783,-10.170388221740724,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Buritis,2021-12-31T00:00:00,3.1195039458850062,2.6578707695007324,-14.79828794553129,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Buritizeiro,2021-12-31T00:00:00,3.0,2.5667848587036133,-14.440504709879557,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Capelinha,2021-12-31T00:00:00,1.4350318471337582,1.2558434009552002,-12.48672261430697,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Carai,2021-12-31T00:00:00,1.218,1.1025261878967283,-9.480608547066623,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Caranaiba,2021-12-31T00:00:00,2.28,1.5259840488433838,-33.07087505072877,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Catuji,2021-12-31T00:00:00,1.384615384615385,1.0387216806411743,-24.981211953692988,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Congonhas_do_Norte,2021-12-31T00:00:00,0.7333333333333333,1.0703778266906738,45.96061273054645,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Coroaci,2021-12-31T00:00:00,1.5,1.650158166885376,10.010544459025066,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Cuparaque,2021-12-31T00:00:00,1.32,1.068262815475464,-19.07099882761638,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Diamantina,2021-12-31T00:00:00,2.9196787148594376,1.964694142341613,-32.70855000783193,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Formoso,2021-12-31T00:00:00,3.0,2.981345891952514,-0.621803601582845,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Franciscopolis,2021-12-31T00:00:00,1.2,1.8699098825454712,55.82582354545595,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Frei_Gaspar,2021-12-31T00:00:00,1.2,0.9247209429740906,-22.939921418825783,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Grao_Mogol,2021-12-31T00:00:00,1.155555555555555,1.118715763092041,-3.188058963188712,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Indaiabira,2021-12-31T00:00:00,1.984444444444444,2.77698016166687,39.93741016238432,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Itabirinha,2021-12-31T00:00:00,0.9659090909090908,0.8717020750045776,-9.753196940702544,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Itacambira,2021-12-31T00:00:00,0.5,1.5114400386810305,202.28800773620603,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Itaipe,2021-12-31T00:00:00,0.7792792792792793,0.911300003528595,16.94138773603935,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Itamarandiba,2021-12-31T00:00:00,1.632,1.5227701663970947,-6.693004509981935,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Itambacuri,2021-12-31T00:00:00,0.8987341772151899,1.042082905769348,15.95006979687113,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Jequitinhonha,2021-12-31T00:00:00,1.8000000000000005,2.14052152633667,18.917862574259424,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Joao_Pinheiro,2021-12-31T00:00:00,2.4,2.6781599521636963,11.589998006820682,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Jose_Goncalves_de_Minas,2021-12-31T00:00:00,1.502673796791444,1.146291971206665,-23.716512948168567,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Juiz_de_Fora,2021-12-31T00:00:00,1.142857142857143,1.4599978923797607,27.749815583229047,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Ladainha,2021-12-31T00:00:00,0.7199999999999999,1.0528860092163086,46.23416794670956,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Malacacheta,2021-12-31T00:00:00,1.8000000000000005,1.6516612768173218,-8.24104017681547,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Mantena,2021-12-31T00:00:00,0.7289999999999999,0.6639465689659119,-8.92365309109575,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Minas_Novas,2021-12-31T00:00:00,1.7848101265822778,0.9810935854911804,-45.03092677035228,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Monte_Formoso,2021-12-31T00:00:00,0.55,0.9690873622894288,76.19770223444156,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Ninheira,2021-12-31T00:00:00,2.100246002460024,2.8083152770996094,33.713635155606646,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Nova_Belem,2021-12-31T00:00:00,1.0,0.961435616016388,-3.856438398361206,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Novo_Cruzeiro,2021-12-31T00:00:00,1.226392251815981,1.1202186346054075,-8.657394651128685,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Novorizonte,2021-12-31T00:00:00,1.307692307692308,1.149425387382507,-12.102764494278867,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Ouro_Verde_de_Minas,2021-12-31T00:00:00,1.942857142857143,1.2009550333023071,-38.18613799179303,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Padre_Paraiso,2021-12-31T00:00:00,0.4787878787878789,0.6957401037216187,45.31280647350261,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Paracatu,2021-12-31T00:00:00,2.4,2.5014195442199707,4.225814342498784,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Pedra_Azul,2021-12-31T00:00:00,1.2,1.1386224031448364,-5.114799737930294,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Pirapora,2021-12-31T00:00:00,3.0,2.885939121246338,-3.802029291788737,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Pote,2021-12-31T00:00:00,0.6000000000000001,0.7461469173431396,24.357819557189924,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Rio_Pardo_de_Minas,2021-12-31T00:00:00,2.764006791171477,2.8757448196411133,4.042610489472715,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Santa_Barbara_do_Monte_Verde,2021-12-31T00:00:00,1.4,1.322326421737671,-5.548112733023501,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Santa_Maria_do_Suacui,2021-12-31T00:00:00,0.8,0.8011263608932495,0.1407951116561834,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Santo_Antonio_do_Retiro,2021-12-31T00:00:00,1.2,1.250118613243103,4.176551103591923,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Sao_Goncalo_do_Rio_Preto,2021-12-31T00:00:00,3.36,2.5083916187286377,-25.345487537838164,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Sao_Joao_do_Manteninha,2021-12-31T00:00:00,0.7,0.7775180339813232,11.074004854474756,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Sao_Joao_do_Paraiso,2021-12-31T00:00:00,3.0614754098360666,1.9916884899139404,-34.943508495448285,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Sao_Sebastiao_do_Maranhao,2021-12-31T00:00:00,0.9655172413793104,0.886711835861206,-8.161988428660806,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Senador_Modestino_Goncalves,2021-12-31T00:00:00,2.7000000000000006,2.118736743927002,-21.52826874344439,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Setubinha,2021-12-31T00:00:00,0.9329787234042556,0.9931007623672484,6.444095396261513,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Taiobeiras,2021-12-31T00:00:00,3.49869451697128,2.2892465591430664,-34.56854983941834,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Teofilo_Otoni,2021-12-31T00:00:00,0.6800000000000002,0.9188857078552246,35.13025115518006,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Turmalina,2021-12-31T00:00:00,1.2797783933518008,1.2145549058914185,-5.09646731021602,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Urucuia,2021-12-31T00:00:00,1.799276672694394,2.269139528274536,26.11398584279584,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Vargem_Grande_do_Rio_Pardo,2021-12-31T00:00:00,1.644444444444444,1.868095874786377,13.600424818090524,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_4_2021,Varzea_da_Palma,2021-12-31T00:00:00,1.68,3.2168662548065186,91.48013421467373,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2021_(2021)
    Modelo LSTM treinado com dados de 2012 a 2019, validado com os dados de 2020 e testado com os dados de 2021.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:57:35
V43_cluster_0_2022,Aguanil,2021-12-31T00:00:00,1.7382352941176469,2.0589418411254883,18.450122839706616,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Alfenas,2021-12-31T00:00:00,1.6209774981853378,2.2961833477020264,41.65423951119447,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Alto_Caparao,2021-12-31T00:00:00,1.08,1.6340157985687256,51.29775912673384,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Alto_Jequitiba,2021-12-31T00:00:00,0.9,1.6571884155273438,84.13204616970485,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Amparo_do_Serra,2021-12-31T00:00:00,1.2,1.4802476167678833,23.35396806399028,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Araponga,2021-12-31T00:00:00,1.2,1.4460283517837524,20.50236264864604,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Astolfo_Dutra,2021-12-31T00:00:00,1.75,1.7659077644348145,0.909015110560826,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Bambui,2021-12-31T00:00:00,1.439910025706941,1.719064474105835,19.38693692071765,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Boa_Esperanca,2021-12-31T00:00:00,1.570339108544351,2.1736435890197754,38.418738805700784,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Bom_Jesus_do_Galho,2021-12-31T00:00:00,1.079802955665025,1.488553524017334,37.854181284451954,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Bom_Sucesso,2021-12-31T00:00:00,1.37989417989418,1.7719550132751465,28.41238401418814,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Caete,2021-12-31T00:00:00,1.222222222222222,1.361832618713379,11.42266880382192,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Caiana,2021-12-31T00:00:00,0.9,1.4181307554244995,57.5700839360555,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Cajuri,2021-12-31T00:00:00,1.2602564102564102,1.6716630458831787,32.64467708940788,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Camacho,2021-12-31T00:00:00,1.5,1.8002040386199951,20.013602574666344,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Campo_do_Meio,2021-12-31T00:00:00,1.255813953488372,2.231511116027832,77.69440368369773,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Campos_Altos,2021-12-31T00:00:00,1.2,1.8985203504562376,58.210029204686485,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Campos_Gerais,2021-12-31T00:00:00,1.589070422535211,2.509064197540283,57.89509149237762,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Cana_Verde,2021-12-31T00:00:00,1.32,1.4465419054031372,9.586507985086149,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Canaa,2021-12-31T00:00:00,1.2,1.6459699869155884,37.16416557629904,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Candeias,2021-12-31T00:00:00,1.199963309484498,1.9460570812225344,62.176382047760846,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Caparao,2021-12-31T00:00:00,0.9,1.7399464845657349,93.32738717397054,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Capitolio,2021-12-31T00:00:00,1.2,1.821570634841919,51.79755290349325,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Caputira,2021-12-31T00:00:00,1.38008658008658,1.4478609561920166,4.910878569747757,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Carangola,2021-12-31T00:00:00,1.02,1.4775294065475464,44.85582417132808,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Caratinga,2021-12-31T00:00:00,1.26,1.7905166149139404,42.10449324713813,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Carmo_da_Mata,2021-12-31T00:00:00,1.32,1.4736576080322266,11.64072788122928,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Carmo_do_Rio_Claro,2021-12-31T00:00:00,1.643702081051479,2.432325839996338,47.97850949001506,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Carmopolis_de_Minas,2021-12-31T00:00:00,1.98,1.875361919403076,-5.284751545299172,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Cassia,2021-12-31T00:00:00,1.314977578475336,2.057385206222534,56.45781646010956,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Catas_Altas_da_Noruega,2021-12-31T00:00:00,1.0,0.9028604030609132,-9.713959693908691,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Chale,2021-12-31T00:00:00,1.26016713091922,1.580372333526611,25.40974087888009,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Claudio,2021-12-31T00:00:00,1.800653594771242,2.1115663051605225,17.266658689495422,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Conceicao_da_Barra_de_Minas,2021-12-31T00:00:00,1.462068965517241,1.9854367971420288,35.79638471018597,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Conceicao_de_Ipanema,2021-12-31T00:00:00,1.29,1.558421611785889,20.807876882627024,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Coqueiral,2021-12-31T00:00:00,1.5,1.9096938371658323,27.312922477722168,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Corrego_Danta,2021-12-31T00:00:00,1.08029197080292,1.699098825454712,57.2814453292537,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Cristais,2021-12-31T00:00:00,1.318776371308017,2.079136848449707,57.65651354425869,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Desterro_de_Entre_Rios,2021-12-31T00:00:00,1.5,2.1156468391418457,41.043122609456375,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Divinesia,2021-12-31T00:00:00,2.1,2.6693289279937744,27.110901333036875,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Divino,2021-12-31T00:00:00,1.08,1.4727332592010498,36.36419066676386,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Doresopolis,2021-12-31T00:00:00,1.2,1.7892568111419678,49.10473426183065,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Durande,2021-12-31T00:00:00,1.32,2.1362075805664062,61.833907618667126,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Eloi_Mendes,2021-12-31T00:00:00,1.037885462555066,1.8574435710906985,78.96421504142128,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Entre_Folhas,2021-12-31T00:00:00,0.8400000000000001,1.1991760730743408,42.75905631837389,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Entre_Rios_de_Minas,2021-12-31T00:00:00,1.8000000000000005,2.110858678817749,17.26992660098604,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ervalia,2021-12-31T00:00:00,1.08,1.656376838684082,53.36822580408166,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Espera_Feliz,2021-12-31T00:00:00,0.78,1.7471370697021484,123.99193201309596,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Faria_Lemos,2021-12-31T00:00:00,0.7199999999999999,1.3099417686462402,81.93635675642228,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ferros,2021-12-31T00:00:00,1.205128205128205,1.0288937091827393,-14.623713493347164,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Fervedouro,2021-12-31T00:00:00,1.15006090133983,1.3592920303344729,18.193047755200336,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Guape,2021-12-31T00:00:00,1.376842105263158,1.943102240562439,41.12745630996306,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ibituruna,2021-12-31T00:00:00,1.6000000000000003,1.7456843852996826,9.105274081230142,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ilicinea,2021-12-31T00:00:00,1.560035211267606,2.251675844192505,44.334937309710256,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Itapecerica,2021-12-31T00:00:00,1.222784810126582,1.707131028175354,39.61009443670081,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ituiutaba,2021-12-31T00:00:00,2.25,1.3512879610061646,-39.942757288614914,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Itumirim,2021-12-31T00:00:00,1.2595155709342565,1.7944657802581787,42.47269519082791,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Lajinha,2021-12-31T00:00:00,1.260014255167498,1.764252781867981,40.01847793646214,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Lavras,2021-12-31T00:00:00,1.259900454447089,2.003435611724853,59.01538924391186,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Luisburgo,2021-12-31T00:00:00,1.3799999999999997,1.8650668859481807,35.149774344071126,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Machado,2021-12-31T00:00:00,1.444286871961102,1.903560161590576,31.79931207197482,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Manhuacu,2021-12-31T00:00:00,0.9,1.4546499252319336,61.62776947021485,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Manhumirim,2021-12-31T00:00:00,1.2,1.5900413990020752,32.50344991683961,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Martins_Soares,2021-12-31T00:00:00,1.2,1.7318307161331177,44.31922634442648,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Matipo,2021-12-31T00:00:00,1.07995337995338,1.4394581317901611,33.28891399481525,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Medeiros,2021-12-31T00:00:00,1.500161864681127,1.8973610401153564,26.477087892022755,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Miradouro,2021-12-31T00:00:00,1.2,1.469443678855896,22.453639904658004,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Mirai,2021-12-31T00:00:00,1.019512195121951,1.3823394775390625,35.58832195957314,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Moeda,2021-12-31T00:00:00,1.8000000000000005,1.3134946823120115,-27.028073204888248,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Muriae,2021-12-31T00:00:00,0.9,1.3999338150024414,55.548201666937935,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Mutum,2021-12-31T00:00:00,1.319934249850568,1.617292404174805,22.528255051939222,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Nazareno,2021-12-31T00:00:00,1.5,1.8906874656677248,26.045831044514973,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Nepomuceno,2021-12-31T00:00:00,1.379962721342032,1.8087897300720213,31.075260374638923,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Oliveira,2021-12-31T00:00:00,1.537805840568272,1.840396761894226,19.67679620816997,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Orizania,2021-12-31T00:00:00,1.08,1.6140141487121582,49.44575451038501,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Paraguacu,2021-12-31T00:00:00,0.9712280701754386,2.048647880554199,110.93375937787096,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Passa_Tempo,2021-12-31T00:00:00,1.511627906976744,1.6042859554290771,6.129686282231272,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Perdoes,2021-12-31T00:00:00,1.44017094017094,1.8880566358566284,31.099481540193214,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Pimenta,2021-12-31T00:00:00,1.3502325581395351,2.04098916053772,51.15834292649316,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Piranga,2021-12-31T00:00:00,2.1,2.284840106964112,8.801909855433868,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Piumhi,2021-12-31T00:00:00,1.5,1.6956238746643066,13.04159164428711,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ponte_Nova,2021-12-31T00:00:00,1.2,1.4049351215362549,17.07792679468791,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Porto_Firme,2021-12-31T00:00:00,1.319607843137255,1.3621320724487305,3.2224898883881776,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Raul_Soares,2021-12-31T00:00:00,1.320079522862823,1.3053979873657229,-1.1121705353978153,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Reduto,2021-12-31T00:00:00,1.2,1.6686358451843262,39.052987098693855,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ribeirao_Vermelho,2021-12-31T00:00:00,1.258899676375405,1.8037563562393188,43.280389223123215,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ritapolis,2021-12-31T00:00:00,1.5,1.8092482089996336,20.61654726664225,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Rosario_da_Limeira,2021-12-31T00:00:00,0.9,1.3021907806396484,44.68786451551649,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santa_Barbara_do_Leste,2021-12-31T00:00:00,1.319917440660475,1.496574878692627,13.38397634504732,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santa_Margarida,2021-12-31T00:00:00,0.9,1.5574638843536377,73.05154270595973,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santa_Rita_de_Minas,2021-12-31T00:00:00,1.2,1.4694349765777588,22.45291471481324,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santa_Rita_do_Itueto,2021-12-31T00:00:00,1.3799999999999997,1.7251057624816897,25.00766394794854,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santana_da_Vargem,2021-12-31T00:00:00,1.44,2.156691312789917,49.77023005485536,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santana_do_Jacare,2021-12-31T00:00:00,1.2,1.6114168167114258,34.28473472595216,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santana_do_Manhuacu,2021-12-31T00:00:00,1.32,1.6591899394989014,25.69620753779555,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Domingos_das_Dores,2021-12-31T00:00:00,1.2,1.7146451473236084,42.88709561030071,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Francisco_de_Paula,2021-12-31T00:00:00,1.3200867052023115,1.7265201807022097,30.788392451661668,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Francisco_do_Gloria,2021-12-31T00:00:00,0.78,1.4228777885437012,82.4202293004745,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Joao_do_Manhuacu,2021-12-31T00:00:00,0.9,1.649578332901001,83.28648143344455,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Jose_do_Mantimento,2021-12-31T00:00:00,1.500917431192661,1.6882622241973877,12.482018604838146,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Roque_de_Minas,2021-12-31T00:00:00,1.2,1.6899805068969729,40.83170890808106,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Tiago,2021-12-31T00:00:00,1.5,2.094043254852295,39.60288365681966,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Tomas_de_Aquino,2021-12-31T00:00:00,1.2,2.017524719238281,68.12705993652345,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Senador_Firmino,2021-12-31T00:00:00,1.563636363636364,1.740434169769287,11.306836438733455,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Senhora_de_Oliveira,2021-12-31T00:00:00,1.62037037037037,1.737810134887695,7.247711181640648,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sericita,2021-12-31T00:00:00,0.9,1.872397541999817,108.044171333313,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Simonesia,2021-12-31T00:00:00,1.08,1.545333981513977,43.08647976981269,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Tapirai,2021-12-31T00:00:00,1.396563119629874,1.783639907836914,27.716383367593554,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Tombos,2021-12-31T00:00:00,0.8497959183673469,1.2941361665725708,52.28787743048985,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Tres_Pontas,2021-12-31T00:00:00,1.3500296384113808,2.184793710708618,61.83301822021689,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ubaporanga,2021-12-31T00:00:00,1.319867549668874,1.5550111532211304,17.815697007722378,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Vargem_Bonita,2021-12-31T00:00:00,1.519565217391304,2.1541531085968018,41.76114877747197,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Vermelho_Novo,2021-12-31T00:00:00,0.96,1.2786697149276731,33.19476197163266,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Vicosa,2021-12-31T00:00:00,0.9006711409395973,1.553451418876648,72.47709494234019,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Vieiras,2021-12-31T00:00:00,0.78,1.4150110483169556,81.41167286114815,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Aguanil,2022-12-31T00:00:00,1.56,2.116868019104004,35.696667891282296,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Alfenas,2022-12-31T00:00:00,0.9243951612903224,2.339022636413574,153.03276502969092,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Alto_Caparao,2022-12-31T00:00:00,1.5,2.01165771484375,34.11051432291667,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Alto_Jequitiba,2022-12-31T00:00:00,0.9,1.847097873687744,105.23309707641602,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Amparo_do_Serra,2022-12-31T00:00:00,1.8000000000000005,1.4890756607055664,-17.273574405246322,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Araponga,2022-12-31T00:00:00,1.260041407867495,1.728244662284851,37.15776731573823,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Astolfo_Dutra,2022-12-31T00:00:00,0.625,2.4273428916931152,288.37486267089844,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Bambui,2022-12-31T00:00:00,1.5,1.8132901191711424,20.88600794474284,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Boa_Esperanca,2022-12-31T00:00:00,0.9726256983240223,2.2364346981048584,129.93785810497968,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Bom_Jesus_do_Galho,2022-12-31T00:00:00,0.7801587301587303,1.524977684020996,95.47018126820495,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Bom_Sucesso,2022-12-31T00:00:00,1.440136054421769,1.952031373977661,35.544927715973614,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Caete,2022-12-31T00:00:00,1.5333333333333332,1.4537900686264038,-5.187604220017136,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Caiana,2022-12-31T00:00:00,0.9,1.5136011838912964,68.17790932125514,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Cajuri,2022-12-31T00:00:00,1.050602409638554,1.798335075378418,71.17180189955128,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Camacho,2022-12-31T00:00:00,1.380176211453745,2.000279664993286,44.92929586769096,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Campo_do_Meio,2022-12-31T00:00:00,1.580968858131488,2.1963822841644287,38.92634714894284,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Campos_Altos,2022-12-31T00:00:00,1.680042238648363,2.0999014377593994,24.99099066990265,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Campos_Gerais,2022-12-31T00:00:00,1.535771358328211,2.511070966720581,63.50552138529581,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Cana_Verde,2022-12-31T00:00:00,1.02,1.5262267589569092,49.630074407540114,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Canaa,2022-12-31T00:00:00,1.320338983050847,1.728865623474121,30.94104208597328,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Candeias,2022-12-31T00:00:00,1.020017406440383,2.1729092597961426,113.02668425817129,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Caparao,2022-12-31T00:00:00,1.32,2.1636555194854736,63.91329693071769,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Capitolio,2022-12-31T00:00:00,1.08,2.0044150352478027,85.5939847451669,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Caputira,2022-12-31T00:00:00,1.440044247787611,1.7466397285461426,21.29069861773794,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Carangola,2022-12-31T00:00:00,1.02,1.558234453201294,52.76808364718568,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Caratinga,2022-12-31T00:00:00,1.620022123893805,1.900081276893616,17.287365948230036,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Carmo_da_Mata,2022-12-31T00:00:00,1.56,1.6491270065307615,5.713269649407799,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Carmo_do_Rio_Claro,2022-12-31T00:00:00,1.619555143651529,2.489917755126953,53.74084450826797,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Carmopolis_de_Minas,2022-12-31T00:00:00,1.8000000000000005,2.1305594444274902,18.364413579305,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Cassia,2022-12-31T00:00:00,1.413626373626374,2.103839874267578,48.825737374338885,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Catas_Altas_da_Noruega,2022-12-31T00:00:00,1.0,1.1704583168029783,17.04583168029785,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Chale,2022-12-31T00:00:00,1.44,1.6426477432250977,14.07275994618734,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Claudio,2022-12-31T00:00:00,1.140522875816993,2.563239336013794,124.74247473358776,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Conceicao_da_Barra_de_Minas,2022-12-31T00:00:00,1.370833333333333,2.245924949645996,63.83647049089338,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Conceicao_de_Ipanema,2022-12-31T00:00:00,1.5,1.5212236642837524,1.4149109522501626,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Coqueiral,2022-12-31T00:00:00,1.2,2.00195837020874,66.82986418406169,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Corrego_Danta,2022-12-31T00:00:00,1.5,1.7826852798461914,18.84568532307943,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Cristais,2022-12-31T00:00:00,1.059063136456212,2.152194023132324,103.21678179960982,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Desterro_de_Entre_Rios,2022-12-31T00:00:00,1.8000000000000005,2.433400154113769,35.188897450764955,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Divinesia,2022-12-31T00:00:00,2.2230769230769227,3.139704942703247,41.23240226692809,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Divino,2022-12-31T00:00:00,1.08,1.6454339027404783,52.35499099448874,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Doresopolis,2022-12-31T00:00:00,1.32,1.8552751541137693,40.55114803892193,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Durande,2022-12-31T00:00:00,1.5,2.1704375743865967,44.695838292439774,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Eloi_Mendes,2022-12-31T00:00:00,1.090201870999508,1.9198503494262693,76.10044529332272,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Entre_Folhas,2022-12-31T00:00:00,1.2,1.273326396942139,6.11053307851156,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Entre_Rios_de_Minas,2022-12-31T00:00:00,1.8000000000000005,2.244246482849121,24.680360158284486,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ervalia,2022-12-31T00:00:00,1.2,1.7329479455947876,44.41232879956564,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Espera_Feliz,2022-12-31T00:00:00,1.2,2.1206326484680176,76.71938737233481,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Faria_Lemos,2022-12-31T00:00:00,1.200305810397553,1.4140955209732056,17.8112701549652,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ferros,2022-12-31T00:00:00,1.230769230769231,1.3415725231170654,9.00276750326154,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Fervedouro,2022-12-31T00:00:00,1.4399108138238568,1.411234974861145,-1.9915010490517533,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Guape,2022-12-31T00:00:00,1.262758620689655,1.964064359664917,55.53759265505897,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ibituruna,2022-12-31T00:00:00,1.2,1.7496788501739502,45.80657084782919,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ilicinea,2022-12-31T00:00:00,1.080069324090121,2.310349225997925,113.90749412721487,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Itapecerica,2022-12-31T00:00:00,1.040506329113924,1.8436092138290403,77.1838538838129,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ituiutaba,2022-12-31T00:00:00,1.75,2.479346752166748,41.67695726667132,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Itumirim,2022-12-31T00:00:00,1.249307479224377,1.909819483757019,52.870251360595056,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Lajinha,2022-12-31T00:00:00,1.419975786924939,1.7981982231140137,26.635837010160778,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Lavras,2022-12-31T00:00:00,1.260078277886497,1.9774988889694207,56.93460665683715,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Luisburgo,2022-12-31T00:00:00,1.5,2.019864559173584,34.65763727823894,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Machado,2022-12-31T00:00:00,0.964047619047619,1.9482399225234983,102.0895943343713,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Manhuacu,2022-12-31T00:00:00,1.44,1.587172269821167,10.220296515358823,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Manhumirim,2022-12-31T00:00:00,1.3799999999999997,1.6519103050231934,19.70364529153578,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Martins_Soares,2022-12-31T00:00:00,1.3799999999999997,1.7667081356048584,28.022328667018755,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Matipo,2022-12-31T00:00:00,1.26,1.55572772026062,23.470453988938104,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Medeiros,2022-12-31T00:00:00,1.5,1.960698246955872,30.713216463724773,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Miradouro,2022-12-31T00:00:00,0.96,1.5089399814605713,57.18124806880953,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Mirai,2022-12-31T00:00:00,1.2,1.3788751363754272,14.906261364618942,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Moeda,2022-12-31T00:00:00,1.25,1.8274798393249512,46.198387145996094,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Muriae,2022-12-31T00:00:00,0.9897142857142858,1.4531254768371582,46.82272427627175,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Mutum,2022-12-31T00:00:00,1.379940564635958,1.6224265098571775,17.572202124892968,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Nazareno,2022-12-31T00:00:00,1.319811320754717,1.9996596574783323,51.51102479821533,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Nepomuceno,2022-12-31T00:00:00,0.8699884125144843,1.8333839178085327,110.73659044602609,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Oliveira,2022-12-31T00:00:00,1.535560504825538,2.0523061752319336,33.65192506465939,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Orizania,2022-12-31T00:00:00,1.5,1.7257885932922363,15.052572886149088,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Paraguacu,2022-12-31T00:00:00,1.043954802259887,2.1524479389190674,106.18210043764202,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Passa_Tempo,2022-12-31T00:00:00,1.507692307692308,1.7953627109527588,19.08017980809111,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Perdoes,2022-12-31T00:00:00,1.259859154929577,1.8997279405593872,50.7889142310973,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Pimenta,2022-12-31T00:00:00,1.3502325581395351,2.22407603263855,64.71799759465661,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Piranga,2022-12-31T00:00:00,1.8000000000000005,2.7439682483673096,52.44268046485051,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Piumhi,2022-12-31T00:00:00,1.2,1.8164055347442627,51.36712789535524,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ponte_Nova,2022-12-31T00:00:00,1.25,1.4461982250213623,15.695858001708984,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Porto_Firme,2022-12-31T00:00:00,1.32,1.5122466087341309,14.56413702531294,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Raul_Soares,2022-12-31T00:00:00,0.8399548532731377,1.4116594791412354,68.06373266852117,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Reduto,2022-12-31T00:00:00,1.260059171597633,1.7537424564361572,39.17937315694323,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ribeirao_Vermelho,2022-12-31T00:00:00,1.32,1.8646966218948364,41.26489559809366,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ritapolis,2022-12-31T00:00:00,1.8000000000000005,2.0226218700408936,12.367881668938514,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Rosario_da_Limeira,2022-12-31T00:00:00,1.02,1.3875524997711182,36.034558801090014,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santa_Barbara_do_Leste,2022-12-31T00:00:00,1.05015873015873,1.6494159698486328,57.06349168752097,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santa_Margarida,2022-12-31T00:00:00,1.3799999999999997,1.725663185119629,25.048056892726763,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santa_Rita_de_Minas,2022-12-31T00:00:00,1.019909502262443,1.5104038715362549,48.09195013731699,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santa_Rita_do_Itueto,2022-12-31T00:00:00,1.6399999999999997,1.7107295989990234,4.312780426769742,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santana_da_Vargem,2022-12-31T00:00:00,0.9900921658986176,2.11468505859375,113.58466730967824,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santana_do_Jacare,2022-12-31T00:00:00,1.5,1.7651561498641968,17.67707665761312,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Santana_do_Manhuacu,2022-12-31T00:00:00,1.26,1.7060420513153076,35.40016280280219,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Domingos_das_Dores,2022-12-31T00:00:00,1.2,1.672302007675171,39.35850063959758,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Francisco_de_Paula,2022-12-31T00:00:00,1.62,1.741337537765503,7.489971467006347,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Francisco_do_Gloria,2022-12-31T00:00:00,0.9601476014760146,1.5888376235961914,65.47847655440735,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Joao_do_Manhuacu,2022-12-31T00:00:00,1.2,1.8104935884475708,50.87446570396425,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Jose_do_Mantimento,2022-12-31T00:00:00,1.499236641221374,1.7778364419937134,18.582776935425898,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Roque_de_Minas,2022-12-31T00:00:00,1.32,1.7058403491973877,29.23032948465057,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Tiago,2022-12-31T00:00:00,1.3210526315789468,2.6736724376678467,102.3895470744586,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sao_Tomas_de_Aquino,2022-12-31T00:00:00,1.2,2.0630178451538086,71.9181537628174,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Senador_Firmino,2022-12-31T00:00:00,1.565217391304348,1.957388401031494,25.055370065901013,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Senhora_de_Oliveira,2022-12-31T00:00:00,1.5,2.1836748123168945,45.5783208211263,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Sericita,2022-12-31T00:00:00,1.3799999999999997,2.225261926651001,61.25086425007257,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Simonesia,2022-12-31T00:00:00,1.8000000000000005,1.582311987876892,-12.093778451283786,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Tapirai,2022-12-31T00:00:00,1.324520819563781,1.8349404335021973,38.5361714515381,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Tombos,2022-12-31T00:00:00,1.2,1.3837435245513916,15.311960379282638,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Tres_Pontas,2022-12-31T00:00:00,0.975023651844844,2.199519395828247,125.5862605657342,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Ubaporanga,2022-12-31T00:00:00,1.2,1.700685739517212,41.72381162643433,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Vargem_Bonita,2022-12-31T00:00:00,1.235217391304348,2.255995750427246,82.63957148830218,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Vermelho_Novo,2022-12-31T00:00:00,0.9598214285714286,1.299338698387146,35.37296206452125,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Vicosa,2022-12-31T00:00:00,1.079768786127168,1.6776901483535769,55.37494414623588,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_0_2022,Vieiras,2022-12-31T00:00:00,1.32,1.547616958618164,17.243708986224547,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:09
V43_cluster_1_2022,Almenara,2021-12-31T00:00:00,0.78,1.039179801940918,33.228179736015115,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Alpinopolis,2021-12-31T00:00:00,1.67993145468393,2.21706771850586,31.973701208123902,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Alterosa,2021-12-31T00:00:00,1.08,1.7572927474975586,62.71229143495912,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Andradas,2021-12-31T00:00:00,1.26,2.126220464706421,68.74765592908102,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Araguari,2021-12-31T00:00:00,1.8600340136054423,2.1038191318511963,13.10648711058822,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Arapua,2021-12-31T00:00:00,1.32,1.442103624343872,9.250274571505454,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Araxa,2021-12-31T00:00:00,1.250440917107584,1.691967487335205,35.30967070790706,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Arceburgo,2021-12-31T00:00:00,1.354903268845897,1.6917119026184082,24.858500345888444,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Areado,2021-12-31T00:00:00,1.5228426395939092,1.872693419456482,22.973534544308936,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Bom_Jesus_da_Penha,2021-12-31T00:00:00,1.519900497512438,1.97321355342865,29.8251797836853,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Botelhos,2021-12-31T00:00:00,1.26,1.6916348934173584,34.25673757280622,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Botumirim,2021-12-31T00:00:00,0.7241379310344828,0.9144614338874816,26.28276944160461,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Cabo_Verde,2021-12-31T00:00:00,1.32,1.8849724531173704,42.800943417982616,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Campestre,2021-12-31T00:00:00,1.2899602385685882,1.841785788536072,42.77849296966083,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Capetinga,2021-12-31T00:00:00,1.6399999999999997,2.0423738956451416,24.534993636898903,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Carmo_do_Paranaiba,2021-12-31T00:00:00,1.541078066914498,1.97266948223114,28.005811294217047,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Cascalho_Rico,2021-12-31T00:00:00,1.9411764705882348,2.0305752754211426,4.605392976240703,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Claraval,2021-12-31T00:00:00,1.050113378684807,2.012568950653076,91.65253881192116,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Conceicao_da_Aparecida,2021-12-31T00:00:00,1.62,2.2173566818237305,36.87386924837842,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Coromandel,2021-12-31T00:00:00,1.249939246658566,1.9192465543746948,53.547187153725496,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Corrego_Fundo,2021-12-31T00:00:00,1.1984126984126982,1.675031065940857,39.77080417784637,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Cruzeiro_da_Fortaleza,2021-12-31T00:00:00,1.800184162062615,1.9047861099243164,5.810624827509367,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Delfinopolis,2021-12-31T00:00:00,0.9,1.5583349466323853,73.14832740359836,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Divisa_Nova,2021-12-31T00:00:00,1.2601319509896318,1.6534016132354736,31.208609696547374,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Dom_Cavati,2021-12-31T00:00:00,0.6000000000000001,0.964349925518036,60.724987586339296,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Dores_do_Turvo,2021-12-31T00:00:00,1.5,1.1384333372116089,-24.10444418589274,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Estrela_do_Indaia,2021-12-31T00:00:00,1.8000000000000005,1.623591661453247,-9.800463252597398,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Estrela_do_Sul,2021-12-31T00:00:00,1.8000000000000005,1.8511103391647337,2.839463286929645,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Guaranesia,2021-12-31T00:00:00,1.031014249790444,1.7703946828842163,71.71389078706265,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Guarani,2021-12-31T00:00:00,0.953846153846154,1.597198247909546,67.4482034098717,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Guarda-Mor,2021-12-31T00:00:00,1.7994350282485878,1.8689818382263184,3.864924761713754,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Guaxupe,2021-12-31T00:00:00,1.02,1.610928297042847,57.93414676890654,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Guimarania,2021-12-31T00:00:00,1.541380188439012,1.8856538534164429,22.33541520512756,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Ibia,2021-12-31T00:00:00,1.2,1.5726659297943115,31.055494149525963,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Ibiraci,2021-12-31T00:00:00,1.327034071867436,2.020942211151123,52.29015245307167,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Indianopolis,2021-12-31T00:00:00,1.919956379498364,2.1423027515411377,11.580803314962154,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Itamogi,2021-12-31T00:00:00,1.260064724919094,2.074574708938598,64.64032901736874,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Itanhomi,2021-12-31T00:00:00,0.9606060606060604,1.211936593055725,26.163746280249008,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Jacui,2021-12-31T00:00:00,0.96,1.6764819622039795,74.63353772958122,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Jacutinga,2021-12-31T00:00:00,1.32014652014652,1.6530399322509766,25.21639886362838,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Juruaia,2021-12-31T00:00:00,1.5,1.7541145086288452,16.940967241923012,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Lagoa_Dourada,2021-12-31T00:00:00,1.2,2.225914478302002,85.49287319183351,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Lagoa_Formosa,2021-12-31T00:00:00,1.4830188679245278,2.0958251953125,41.32154624880731,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Lagoa_Grande,2021-12-31T00:00:00,0.6000000000000001,1.8756914138793943,212.6152356465657,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Matutina,2021-12-31T00:00:00,1.502024291497976,1.693775653839111,12.766195821633536,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Monte_Belo,2021-12-31T00:00:00,1.56,1.6848275661468506,8.001767060695547,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Monte_Carmelo,2021-12-31T00:00:00,1.8000000000000005,1.88685941696167,4.825523164537202,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Monte_Santo_de_Minas,2021-12-31T00:00:00,1.200018932222643,1.8540685176849363,54.50327223178723,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Muzambinho,2021-12-31T00:00:00,1.199937762564182,1.751840591430664,45.994287877656646,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Nova_Resende,2021-12-31T00:00:00,1.3800031392246113,2.114441156387329,53.22002510627475,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Passos,2021-12-31T00:00:00,0.99,1.5477396249771118,56.33733585627392,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Patis,2021-12-31T00:00:00,2.111111111111112,3.107210397720337,47.18365041833172,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Patos_de_Minas,2021-12-31T00:00:00,1.7224109589041097,1.7588324546813965,2.1145647958754354,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Patrocinio,2021-12-31T00:00:00,1.4369951534733445,1.739474892616272,21.04946132990132,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Pedrinopolis,2021-12-31T00:00:00,1.514285714285714,1.7474708557128906,15.3990187734928,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Perdizes,2021-12-31T00:00:00,1.261308677098151,1.7741634845733645,40.66053114413836,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Piracema,2021-12-31T00:00:00,1.2,1.2883222103118896,7.360184192657475,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Ponto_dos_Volantes,2021-12-31T00:00:00,0.5375,0.6062880754470825,12.797781478526984,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Pratapolis,2021-12-31T00:00:00,0.9602272727272728,2.1062488555908203,119.34899324496114,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Pratinha,2021-12-31T00:00:00,1.35,1.717201828956604,27.20013547826696,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Presidente_Kubitschek,2021-12-31T00:00:00,0.7368421052631579,1.3970155715942385,89.59497043064664,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Presidente_Olegario,2021-12-31T00:00:00,1.637164750957854,1.9928877353668213,21.72798945254868,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Quartel_Geral,2021-12-31T00:00:00,2.4571428571428573,3.039301633834839,23.692508353743435,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Rio_Paranaiba,2021-12-31T00:00:00,1.080031384856807,1.5908236503601074,47.294205767087256,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Rio_Vermelho,2021-12-31T00:00:00,0.7777777777777777,1.0695576667785645,37.51455715724401,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Romaria,2021-12-31T00:00:00,2.052631578947369,2.112183094024658,2.901227657611523,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sacramento,2021-12-31T00:00:00,1.25645342312009,1.6372621059417725,30.308221205370177,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Santa_Rosa_da_Serra,2021-12-31T00:00:00,1.5,1.6618993282318115,10.793288548787434,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Santo_Antonio_do_Amparo,2021-12-31T00:00:00,1.3799999999999997,1.958511114120484,41.92109522612202,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sao_Goncalo_do_Abaete,2021-12-31T00:00:00,1.67887323943662,2.110746622085572,25.72400181885532,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sao_Gotardo,2021-12-31T00:00:00,1.26027397260274,1.5666344165802002,24.309035228646284,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sao_Joao_Batista_do_Gloria,2021-12-31T00:00:00,1.110749185667752,1.4210093021392822,27.93250901957765,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sao_Pedro_da_Uniao,2021-12-31T00:00:00,1.479945054945055,1.82914137840271,23.595222153069685,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sao_Sebastiao_do_Paraiso,2021-12-31T00:00:00,1.14450771643146,1.7032424211502075,48.81878004814726,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Serra_do_Salitre,2021-12-31T00:00:00,1.4676384839650147,1.80860698223114,23.232458264855183,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Tapira,2021-12-31T00:00:00,0.6000000000000001,1.8328546285629272,205.47577142715448,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Tiros,2021-12-31T00:00:00,1.2,1.8113179206848145,50.943160057067885,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Tupaciguara,2021-12-31T00:00:00,1.887700534759358,2.192509412765503,16.147099203158387,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Uberaba,2021-12-31T00:00:00,2.0302325581395344,2.411567687988281,18.782829992549964,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Uberlandia,2021-12-31T00:00:00,1.77962962962963,1.98469340801239,11.522834581341366,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Unai,2021-12-31T00:00:00,2.639892904953146,2.6578497886657715,0.6802125828261322,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Varginha,2021-12-31T00:00:00,1.2,1.7181415557861328,43.17846298217774,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Varjao_de_Minas,2021-12-31T00:00:00,2.390254805543138,2.429838895797729,1.6560615279506454,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Virginopolis,2021-12-31T00:00:00,1.202380952380952,1.3724188804626465,14.14176827610132,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Almenara,2022-12-31T00:00:00,0.78,0.9933531284332277,27.35296518374712,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Alpinopolis,2022-12-31T00:00:00,1.4420494699646638,2.4411747455596924,69.28509017235805,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Alterosa,2022-12-31T00:00:00,1.080104712041885,2.064505100250244,91.13934762375015,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Andradas,2022-12-31T00:00:00,1.26,2.3166322708129883,83.85970403277685,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Araguari,2022-12-31T00:00:00,1.919968366943456,2.4430668354034424,27.245160777974004,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Arapua,2022-12-31T00:00:00,1.14,1.557830572128296,36.65180457265755,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Araxa,2022-12-31T00:00:00,1.077872465471643,1.805524110794068,67.50813928659241,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Arceburgo,2022-12-31T00:00:00,0.9244897959183672,1.9766101837158203,113.80551656087243,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Areado,2022-12-31T00:00:00,0.9076923076923076,2.086708307266236,129.89159317339883,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Bom_Jesus_da_Penha,2022-12-31T00:00:00,1.6298200514138823,2.039818525314331,25.156057783481785,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Botelhos,2022-12-31T00:00:00,0.9,1.7817864418029783,97.97627131144203,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Botumirim,2022-12-31T00:00:00,0.7241379310344828,0.9155209064483644,26.42907755715506,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Cabo_Verde,2022-12-31T00:00:00,1.35,1.9748305082321167,46.28374135052715,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Campestre,2022-12-31T00:00:00,1.020018115942029,1.865102767944336,82.84996499516446,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Capetinga,2022-12-31T00:00:00,1.407056229327453,2.3496527671813965,66.9906801311336,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Carmo_do_Paranaiba,2022-12-31T00:00:00,1.392969472710453,2.200034618377685,57.93846609551592,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Cascalho_Rico,2022-12-31T00:00:00,2.580434782608696,2.3546037673950195,-8.75166529050473,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Claraval,2022-12-31T00:00:00,1.289915966386555,2.7247791290283203,111.23694876506192,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Conceicao_da_Aparecida,2022-12-31T00:00:00,1.53,2.1724672317504883,41.99132233663322,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Coromandel,2022-12-31T00:00:00,1.260025542784164,2.132889032363892,69.27347580994592,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Corrego_Fundo,2022-12-31T00:00:00,1.079051383399209,2.267729043960572,110.15950480660248,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Cruzeiro_da_Fortaleza,2022-12-31T00:00:00,1.5598526703499078,2.12051773071289,35.943462547473395,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Delfinopolis,2022-12-31T00:00:00,1.3799999999999997,1.7241604328155518,24.93916179822842,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Divisa_Nova,2022-12-31T00:00:00,1.260204081632653,1.9066375494003296,51.29593509411523,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Dom_Cavati,2022-12-31T00:00:00,0.6000000000000001,1.461137056350708,143.52284272511798,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Dores_do_Turvo,2022-12-31T00:00:00,1.2,1.7818537950515747,48.4878162542979,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Estrela_do_Indaia,2022-12-31T00:00:00,1.86,2.083278179168701,12.004203181112974,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Estrela_do_Sul,2022-12-31T00:00:00,1.460045146726862,2.3855342864990234,63.387707006658566,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Guaranesia,2022-12-31T00:00:00,1.086968085106383,1.9166269302368164,76.32780175410888,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Guarani,2022-12-31T00:00:00,1.2,1.797126054763794,49.7605045636495,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Guarda-Mor,2022-12-31T00:00:00,1.858757062146893,2.128024101257324,14.486403015971527,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Guaxupe,2022-12-31T00:00:00,1.14,1.6650598049163818,46.05787762424403,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Guimarania,2022-12-31T00:00:00,1.2220588235294123,2.051356554031372,67.86070478235047,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Ibia,2022-12-31T00:00:00,1.14,1.6945382356643677,48.64370488283928,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Ibiraci,2022-12-31T00:00:00,1.377007874015748,2.8204920291900635,104.82758903656108,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Indianopolis,2022-12-31T00:00:00,1.8000000000000005,2.471039295196533,37.27996084425183,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Itamogi,2022-12-31T00:00:00,1.32,2.3305132389068604,76.55403325051971,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Itanhomi,2022-12-31T00:00:00,1.081818181818182,1.556979417800903,43.92246719168011,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Jacui,2022-12-31T00:00:00,1.08,1.74635910987854,61.69991758134629,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Jacutinga,2022-12-31T00:00:00,1.289920424403183,1.7332226037979126,34.36662998803477,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Juruaia,2022-12-31T00:00:00,1.5,1.843293309211731,22.886220614115395,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Lagoa_Dourada,2022-12-31T00:00:00,1.5,2.4977800846099854,66.51867230733237,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Lagoa_Formosa,2022-12-31T00:00:00,2.088607594936709,2.350733995437622,12.55029432701342,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Lagoa_Grande,2022-12-31T00:00:00,2.4,2.442432641983032,1.7680267492930133,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Matutina,2022-12-31T00:00:00,1.8097165991902835,1.843263506889344,1.85371055965723,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Monte_Belo,2022-12-31T00:00:00,0.96,1.9251813888549805,100.53972800572716,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Monte_Carmelo,2022-12-31T00:00:00,1.7458874458874465,2.275681495666504,30.345257996271336,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Monte_Santo_de_Minas,2022-12-31T00:00:00,1.4699677072120565,2.1921169757843018,49.12687979669126,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Muzambinho,2022-12-31T00:00:00,1.43993993993994,1.9006109237670896,31.99237489352261,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Nova_Resende,2022-12-31T00:00:00,1.5,2.123741626739502,41.5827751159668,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Passos,2022-12-31T00:00:00,1.290038314176245,1.7791202068328855,37.91219898526381,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Patis,2022-12-31T00:00:00,2.044444444444444,4.495101451873779,119.8690927546958,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Patos_de_Minas,2022-12-31T00:00:00,1.91614730878187,1.9000860452651973,-0.8382060942320027,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Patrocinio,2022-12-31T00:00:00,0.9438953724513282,2.29590392112732,143.23712014444772,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Pedrinopolis,2022-12-31T00:00:00,2.02051282051282,2.589383363723755,28.15476038734323,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Perdizes,2022-12-31T00:00:00,1.501272727272727,2.0155699253082275,34.25741297317734,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Piracema,2022-12-31T00:00:00,1.0,1.354100465774536,35.41004657745361,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Ponto_dos_Volantes,2022-12-31T00:00:00,0.6000000000000001,0.6886550784111023,14.775846401850364,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Pratapolis,2022-12-31T00:00:00,1.2,2.003670215606689,66.97251796722414,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Pratinha,2022-12-31T00:00:00,1.720111731843575,1.915272235870361,11.345803904123011,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Presidente_Kubitschek,2022-12-31T00:00:00,0.896551724137931,1.785614252090454,99.16466657931988,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Presidente_Olegario,2022-12-31T00:00:00,1.8899598393574304,2.282222509384156,20.755079650797818,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Quartel_Geral,2022-12-31T00:00:00,3.0,3.7463512420654297,24.87837473551432,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Rio_Paranaiba,2022-12-31T00:00:00,1.230031446540881,1.9201316833496087,56.10427593127331,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Rio_Vermelho,2022-12-31T00:00:00,0.9090909090909092,1.1902697086334229,30.92966794967652,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Romaria,2022-12-31T00:00:00,1.910526315789474,2.62051773071289,37.16208507863612,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sacramento,2022-12-31T00:00:00,1.5575892857142857,1.9296395778656008,23.886289894495427,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Santa_Rosa_da_Serra,2022-12-31T00:00:00,2.22,1.8276578187942505,-17.6730712254842,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Santo_Antonio_do_Amparo,2022-12-31T00:00:00,1.26,2.222951412200928,76.42471525404189,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sao_Goncalo_do_Abaete,2022-12-31T00:00:00,1.5,2.3854007720947266,59.02671813964844,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sao_Gotardo,2022-12-31T00:00:00,1.50025974025974,1.750458836555481,16.67705195184562,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sao_Joao_Batista_do_Gloria,2022-12-31T00:00:00,1.232209737827715,1.5837626457214355,28.53028158286425,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sao_Pedro_da_Uniao,2022-12-31T00:00:00,1.4700000000000002,1.956852912902832,33.119245775702844,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Sao_Sebastiao_do_Paraiso,2022-12-31T00:00:00,1.3172147001934242,1.8707228899002075,42.02110632575724,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Serra_do_Salitre,2022-12-31T00:00:00,1.5168750000000002,2.668215274810791,75.90211947660754,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Tapira,2022-12-31T00:00:00,1.8000000000000005,2.086907386779785,15.9392992655436,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Tiros,2022-12-31T00:00:00,1.6801801801801797,2.0289175510406494,20.755950758987748,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Tupaciguara,2022-12-31T00:00:00,2.4,2.314458131790161,-3.5642445087432826,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Uberaba,2022-12-31T00:00:00,2.102941176470588,2.863719940185547,36.176892260571485,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Uberlandia,2022-12-31T00:00:00,1.681818181818182,2.49426794052124,48.30782349045212,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Unai,2022-12-31T00:00:00,2.52010582010582,2.8206050395965576,11.924071485145785,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Varginha,2022-12-31T00:00:00,1.020039292730845,1.945786714553833,90.75605502848629,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Varjao_de_Minas,2022-12-31T00:00:00,2.383928571428572,2.517011880874634,5.582520845677494,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_1_2022,Virginopolis,2022-12-31T00:00:00,1.314606741573034,1.6852777004241943,28.196337895515605,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:58:43
V43_cluster_2_2022,Abre_Campo,2021-12-31T00:00:00,1.2,1.8712961673736568,55.94134728113811,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Aimores,2021-12-31T00:00:00,1.634328358208955,2.4939868450164795,52.60010832520927,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Alvarenga,2021-12-31T00:00:00,0.6304878048780488,1.0281610488891602,63.07389943696544,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Andrelandia,2021-12-31T00:00:00,1.4,1.9783586263656616,41.31133045469013,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Antonio_Dias,2021-12-31T00:00:00,1.5,1.4316670894622805,-4.5555273691813145,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Antonio_Prado_de_Minas,2021-12-31T00:00:00,0.9,2.1149888038635254,134.99875598483618,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Bocaiuva,2021-12-31T00:00:00,1.7407407407407405,2.0307538509368896,16.660327607012825,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Bom_Jesus_do_Amparo,2021-12-31T00:00:00,1.2,1.3256381750106812,10.469847917556766,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Campo_Belo,2021-12-31T00:00:00,1.5,2.240126132965088,49.34174219767253,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Capela_Nova,2021-12-31T00:00:00,1.8000000000000005,2.130455017089844,18.358612060546857,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Capitao_Eneas,2021-12-31T00:00:00,2.0,8.702866554260254,335.1433277130128,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Casa_Grande,2021-12-31T00:00:00,1.3230769230769233,2.5592312812805176,93.43027125957396,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Cataguases,2021-12-31T00:00:00,1.25,3.3214447498321533,165.7155799865723,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Caxambu,2021-12-31T00:00:00,1.4387755102040822,2.3958070278167725,66.5170842028678,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Coimbra,2021-12-31T00:00:00,1.501182033096927,2.276463031768799,51.6447027461735,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Conselheiro_Pena,2021-12-31T00:00:00,1.2898734177215188,1.4130762815475464,9.551546852066911,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Corrego_Novo,2021-12-31T00:00:00,1.8000000000000005,1.861315369606018,3.406409422556544,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Cruzilia,2021-12-31T00:00:00,1.5027322404371577,1.792783260345459,19.301576961170603,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Divisopolis,2021-12-31T00:00:00,0.9595505617977528,1.3262523412704468,38.215993411088725,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Esmeraldas,2021-12-31T00:00:00,1.7115384615384608,1.8773475885391235,9.68772427419603,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Espirito_Santo_do_Dourado,2021-12-31T00:00:00,1.200854700854701,1.651851773262024,37.55633983747813,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Eugenopolis,2021-12-31T00:00:00,1.5,2.667620182037353,77.84134546915689,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Felicio_dos_Santos,2021-12-31T00:00:00,3.542087542087541,3.962339639663696,11.864531652102473,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Formiga,2021-12-31T00:00:00,1.347576301615799,2.048993825912476,52.050301230115736,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Guaraciaba,2021-12-31T00:00:00,2.4,1.2404011487960815,-48.31661880016327,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Guiricema,2021-12-31T00:00:00,2.1,2.723768711090088,29.703271956670847,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Iapu,2021-12-31T00:00:00,1.5578947368421048,1.434032320976257,-7.9506280454429135,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Ijaci,2021-12-31T00:00:00,1.2375,3.438772678375244,177.8806204747672,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Imbe_de_Minas,2021-12-31T00:00:00,1.2,1.3544690608978271,12.8724217414856,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Inhapim,2021-12-31T00:00:00,1.2,2.05229926109314,71.02493842442831,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Irai_de_Minas,2021-12-31T00:00:00,2.472300469483568,4.891221046447754,97.84088167363684,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Itamarati_de_Minas,2021-12-31T00:00:00,1.2,1.5058352947235107,25.486274560292564,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Jequeri,2021-12-31T00:00:00,1.5,2.362656831741333,57.5104554494222,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Lamim,2021-12-31T00:00:00,1.2800000000000002,3.472689390182495,171.30385860800737,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Mar_de_Espanha,2021-12-31T00:00:00,1.4199999999999997,1.939918637275696,36.61398854054199,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Mata_Verde,2021-12-31T00:00:00,1.319277108433735,1.6576610803604126,25.64919604558379,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Monte_Alegre_de_Minas,2021-12-31T00:00:00,2.765957446808511,3.1102304458618164,12.44679304269643,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Nova_Era,2021-12-31T00:00:00,1.5,1.4118554592132568,-5.876302719116211,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Nova_Ponte,2021-12-31T00:00:00,2.5482352941176467,2.3301773071289062,-8.557215555883166,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Paula_Candido,2021-12-31T00:00:00,1.5,1.7900842428207395,19.33894952138265,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Pecanha,2021-12-31T00:00:00,1.807692307692308,1.615246295928955,-10.645949586908891,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Pedra_Bonita,2021-12-31T00:00:00,1.08,2.435365915298462,125.49684400911684,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Pedra_Dourada,2021-12-31T00:00:00,0.96,1.6920713186264038,76.25742902358375,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Pedra_do_Anta,2021-12-31T00:00:00,0.9,1.6840698719024658,87.11887465582953,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Piedade_de_Caratinga,2021-12-31T00:00:00,1.2,1.6174211502075195,34.78509585062663,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Pocrane,2021-12-31T00:00:00,1.3228346456692908,1.210155725479126,-8.517989800089843,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Presidente_Bernardes,2021-12-31T00:00:00,1.56,1.8112773895263672,16.107524969638916,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sabinopolis,2021-12-31T00:00:00,1.2,1.1728709936141968,-2.260750532150265,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Santa_Barbara,2021-12-31T00:00:00,0.9333333333333332,1.1409724950790403,22.24705304418294,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Santo_Antonio_do_Grama,2021-12-31T00:00:00,1.9130434782608696,2.074552059173584,8.44249400225551,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Domingos_do_Prata,2021-12-31T00:00:00,0.903846153846154,0.9220368266105652,2.012585071807211,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Geraldo,2021-12-31T00:00:00,1.5,3.250124454498291,116.6749636332194,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Jose_da_Barra,2021-12-31T00:00:00,1.682068965517241,3.475766897201538,106.63640840271552,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Jose_do_Alegre,2021-12-31T00:00:00,1.7823529411764714,1.9055397510528564,6.911471181183318,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Miguel_do_Anta,2021-12-31T00:00:00,1.2603053435114495,1.91666579246521,52.07947838458063,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Sebastiao_da_Vargem_Alegre,2021-12-31T00:00:00,1.020238095238095,2.2631430625915527,121.82499096579986,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Sebastiao_do_Anta,2021-12-31T00:00:00,1.5,1.673372745513916,11.558183034261068,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Senhora_dos_Remedios,2021-12-31T00:00:00,1.5,2.283947706222534,52.26318041483561,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Teixeiras,2021-12-31T00:00:00,1.32,2.090442657470703,58.36686799020477,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Visconde_do_Rio_Branco,2021-12-31T00:00:00,1.25,1.588275671005249,27.06205368041992,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Abre_Campo,2022-12-31T00:00:00,1.2,1.928468108177185,60.70567568143209,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Aimores,2022-12-31T00:00:00,2.332558139534884,2.5758256912231445,10.42921707138107,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Alvarenga,2022-12-31T00:00:00,0.9,1.0104670524597168,12.274116939968527,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Andrelandia,2022-12-31T00:00:00,1.8000000000000005,2.084213256835937,15.78962537977429,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Antonio_Dias,2022-12-31T00:00:00,1.5,1.958724856376648,30.58165709177653,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Antonio_Prado_de_Minas,2022-12-31T00:00:00,1.2,2.049685478210449,70.80712318420412,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Bocaiuva,2022-12-31T00:00:00,3.6000000000000005,2.020330905914306,-43.879697057935935,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Bom_Jesus_do_Amparo,2022-12-31T00:00:00,1.8000000000000005,1.4214718341827393,-21.029342545403388,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Campo_Belo,2022-12-31T00:00:00,1.2,2.2802155017852783,90.01795848210654,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Capela_Nova,2022-12-31T00:00:00,2.1016393442622947,2.3279292583465576,10.767304804321403,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Capitao_Eneas,2022-12-31T00:00:00,2.6000000000000005,8.66652774810791,233.32799031184263,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Casa_Grande,2022-12-31T00:00:00,2.107692307692308,2.8761801719665527,36.46110304950794,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Cataguases,2022-12-31T00:00:00,1.5,4.267797470092773,184.51983133951825,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Caxambu,2022-12-31T00:00:00,1.4387755102040822,2.890634536743164,100.90935078073046,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Coimbra,2022-12-31T00:00:00,1.799054373522459,2.293972969055176,27.509929817390173,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Conselheiro_Pena,2022-12-31T00:00:00,1.8000000000000005,1.4376329183578491,-20.13150453567506,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Corrego_Novo,2022-12-31T00:00:00,1.377777777777778,3.1122987270355225,125.89264954290078,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Cruzilia,2022-12-31T00:00:00,1.5027322404371577,2.2037887573242188,46.65212457830263,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Divisopolis,2022-12-31T00:00:00,1.259523809523809,1.234466791152954,-1.989404105058428,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Esmeraldas,2022-12-31T00:00:00,2.111111111111112,2.0341720581054688,-3.644481458162029,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Espirito_Santo_do_Dourado,2022-12-31T00:00:00,1.319148936170213,1.8848881721496584,42.88668401779668,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Eugenopolis,2022-12-31T00:00:00,1.8000000000000005,2.768878936767578,53.82660759819876,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Felicio_dos_Santos,2022-12-31T00:00:00,3.306397306397306,5.215751647949219,57.747274892150536,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Formiga,2022-12-31T00:00:00,1.8000000000000005,2.734970569610596,51.94280942281085,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Guaraciaba,2022-12-31T00:00:00,1.8000000000000005,3.334778070449829,85.26544835832381,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Guiricema,2022-12-31T00:00:00,2.4,3.2346441745758057,34.77684060732524,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Iapu,2022-12-31T00:00:00,1.5614035087719298,1.6757402420043943,7.322689656461224,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Ijaci,2022-12-31T00:00:00,1.173913043478261,3.330453872680664,183.7053298950196,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Imbe_de_Minas,2022-12-31T00:00:00,1.3799999999999997,1.3216841220855713,-4.225788254668724,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Inhapim,2022-12-31T00:00:00,1.8000000000000005,2.0525565147399902,14.030917485554998,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Irai_de_Minas,2022-12-31T00:00:00,2.386666666666667,5.122172832489014,114.6161801322212,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Itamarati_de_Minas,2022-12-31T00:00:00,1.261538461538461,1.7525691986083984,38.923168182373104,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Jequeri,2022-12-31T00:00:00,1.8000000000000005,2.501237869262696,38.95765940348305,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Lamim,2022-12-31T00:00:00,2.4,3.363729953765869,40.15541474024455,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Mar_de_Espanha,2022-12-31T00:00:00,2.1,2.512204647064209,19.62879271734328,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Mata_Verde,2022-12-31T00:00:00,1.6792452830188678,1.6249690055847168,-3.2321828134943846,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Monte_Alegre_de_Minas,2022-12-31T00:00:00,2.3296703296703294,3.8614730834960938,65.75191065950216,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Nova_Era,2022-12-31T00:00:00,1.5,1.49756920337677,-0.162053108215332,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Nova_Ponte,2022-12-31T00:00:00,2.710714285714286,3.4543068408966064,27.431609413840548,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Paula_Candido,2022-12-31T00:00:00,1.6198529411764713,1.8856782913208008,16.41046192447971,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Pecanha,2022-12-31T00:00:00,2.287671232876712,2.050818920135498,-10.353424449166845,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Pedra_Bonita,2022-12-31T00:00:00,1.8000000000000005,2.342030763626098,30.112820201449903,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Pedra_Dourada,2022-12-31T00:00:00,1.2,1.804336667060852,50.361388921737685,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Pedra_do_Anta,2022-12-31T00:00:00,1.438297872340426,1.8703820705413816,30.04135697551023,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Piedade_de_Caratinga,2022-12-31T00:00:00,1.56,1.5496740341186523,-0.6619208898299813,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Pocrane,2022-12-31T00:00:00,1.440944881889764,1.3619368076324463,-5.483074005835702,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Presidente_Bernardes,2022-12-31T00:00:00,1.501449275362319,2.0079240798950195,33.73239528258333,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sabinopolis,2022-12-31T00:00:00,1.32,1.090633988380432,-17.37621300148242,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Santa_Barbara,2022-12-31T00:00:00,1.083333333333333,1.1200460195541382,3.388863343458937,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Santo_Antonio_do_Grama,2022-12-31T00:00:00,1.565217391304348,3.492873191833496,123.15578725602892,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Domingos_do_Prata,2022-12-31T00:00:00,1.078125,1.0945583581924438,1.524253513502038,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Geraldo,2022-12-31T00:00:00,1.561038961038961,3.8433375358581534,146.20381885281023,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Jose_da_Barra,2022-12-31T00:00:00,2.3076923076923066,3.323957920074463,44.03817653656012,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Jose_do_Alegre,2022-12-31T00:00:00,1.682352941176471,2.4406237602233887,45.07204169159999,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Miguel_do_Anta,2022-12-31T00:00:00,1.5,1.8235514163970947,21.570094426472984,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Sebastiao_da_Vargem_Alegre,2022-12-31T00:00:00,1.020238095238095,2.379272937774658,133.20761583788956,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Sao_Sebastiao_do_Anta,2022-12-31T00:00:00,1.8000000000000005,1.691335916519165,-6.036893526713067,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Senhora_dos_Remedios,2022-12-31T00:00:00,1.466666666666667,2.6363041400909424,79.74800955165512,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Teixeiras,2022-12-31T00:00:00,1.5,2.1400041580200195,42.6669438680013,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_2_2022,Visconde_do_Rio_Branco,2022-12-31T00:00:00,1.6666666666666672,2.15122652053833,29.07359123229977,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:18
V43_cluster_3_2022,Aiuruoca,2021-12-31T00:00:00,1.2,1.676437258720398,39.7031048933665,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Albertina,2021-12-31T00:00:00,1.56,1.7626198530197144,12.988452116648352,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Baependi,2021-12-31T00:00:00,1.079646017699115,1.7257128953933716,59.84062063889427,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Bandeira_do_Sul,2021-12-31T00:00:00,1.8011695906432754,1.681325912475586,-6.653658755413927,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Borda_da_Mata,2021-12-31T00:00:00,1.2,1.779351830482483,48.27931920687358,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Brazopolis,2021-12-31T00:00:00,1.200934579439252,1.4902037382125854,24.087003882293136,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Bueno_Brandao,2021-12-31T00:00:00,1.2,1.8360673189163208,53.005609909693405,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Cachoeira_de_Minas,2021-12-31T00:00:00,1.5602040816326532,2.04069447517395,30.79663738852001,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Caldas,2021-12-31T00:00:00,1.2,1.714519500732422,42.87662506103516,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Cambuquira,2021-12-31T00:00:00,1.2,1.8044235706329343,50.368630886077895,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Campanha,2021-12-31T00:00:00,1.325757575757576,1.7347352504730225,30.84860174996511,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Careacu,2021-12-31T00:00:00,1.2,1.4504601955413818,20.871682961781826,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Carmo_da_Cachoeira,2021-12-31T00:00:00,1.439980158730159,1.7661020755767822,22.647667391071035,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Carmo_de_Minas,2021-12-31T00:00:00,1.3799999999999997,1.63044273853302,18.14802453137829,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Carrancas,2021-12-31T00:00:00,1.214285714285714,1.7254549264907837,42.09628806394693,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Carvalhopolis,2021-12-31T00:00:00,1.14,1.6456130743026731,44.352024061638026,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Conceicao_das_Pedras,2021-12-31T00:00:00,1.5,1.6236701011657717,8.244673411051433,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Conceicao_do_Rio_Verde,2021-12-31T00:00:00,1.500115340253749,1.9246060848236084,28.29720709995909,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Conceicao_dos_Ouros,2021-12-31T00:00:00,1.26,1.5164563655853271,20.353679808359296,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Congonhal,2021-12-31T00:00:00,1.6215384615384625,1.8290530443191528,12.797388881162124,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Cordislandia,2021-12-31T00:00:00,1.319791666666667,1.7890280485153198,35.55382214480716,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Cristina,2021-12-31T00:00:00,1.68,1.7021852731704712,1.3205519744328127,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Datas,2021-12-31T00:00:00,1.0,2.0885980129241943,108.85980129241943,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Dom_Vicoso,2021-12-31T00:00:00,1.2,1.5474357604980469,28.95298004150392,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Fama,2021-12-31T00:00:00,1.5,1.632153868675232,8.810257911682129,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Fortaleza_de_Minas,2021-12-31T00:00:00,1.26,1.5206985473632812,20.69036090184772,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Heliodora,2021-12-31T00:00:00,1.2,1.7021303176879885,41.844193140665695,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Ibitiura_de_Minas,2021-12-31T00:00:00,1.9198795180722887,1.7873473167419434,-6.903151999007657,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Inconfidentes,2021-12-31T00:00:00,1.5,2.5137951374053955,67.58634249369302,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Ingai,2021-12-31T00:00:00,1.320075757575758,1.8097147941589355,37.09173763499536,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Itajuba,2021-12-31T00:00:00,1.181818181818182,1.8955196142196653,60.390121203202426,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Itutinga,2021-12-31T00:00:00,1.2,1.64433753490448,37.02812790870667,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Jesuania,2021-12-31T00:00:00,1.2,1.6144170761108398,34.53475634256999,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Lambari,2021-12-31T00:00:00,1.199954863461973,1.640364646911621,36.70219579585085,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Luminarias,2021-12-31T00:00:00,1.380229885057471,2.0289506912231445,47.00092449734644,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Maria_da_Fe,2021-12-31T00:00:00,1.444444444444444,1.6753737926483154,15.987416414114184,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Monsenhor_Paulo,2021-12-31T00:00:00,1.41,1.813206672668457,28.59621791974871,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Monte_Siao,2021-12-31T00:00:00,1.5,1.7584550380706787,17.23033587137858,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Natercia,2021-12-31T00:00:00,1.4399193548387097,1.615408420562744,12.187423214662712,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Olimpio_Noronha,2021-12-31T00:00:00,1.20026525198939,1.518959403038025,26.55197678349953,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Ouro_Fino,2021-12-31T00:00:00,1.2,1.8317482471466064,52.64568726221721,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Paraisopolis,2021-12-31T00:00:00,1.2,1.874094009399414,56.17450078328451,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Pedralva,2021-12-31T00:00:00,1.5,1.7858377695083618,19.055851300557457,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Pirangucu,2021-12-31T00:00:00,1.333333333333333,1.3264280557632446,-0.5178958177566307,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Piranguinho,2021-12-31T00:00:00,1.380549682875264,1.4831923246383667,7.434911110864874,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Poco_Fundo,2021-12-31T00:00:00,0.9601760412194076,1.5526766777038574,61.70750060915745,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Pocos_de_Caldas,2021-12-31T00:00:00,1.4199999999999997,1.7515528202056885,23.3487901553302,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Pouso_Alegre,2021-12-31T00:00:00,1.2,1.6262975931167605,35.52479942639669,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Pouso_Alto,2021-12-31T00:00:00,1.5047619047619047,1.6127740144729614,7.1780199491525005,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Santa_Rita_de_Caldas,2021-12-31T00:00:00,1.682051282051282,2.013676166534424,19.71550380311361,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Santa_Rita_do_Sapucai,2021-12-31T00:00:00,1.5,1.761400580406189,17.426705360412598,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Bento_Abade,2021-12-31T00:00:00,1.32,2.077394485473633,57.37837011163885,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Goncalo_do_Sapucai,2021-12-31T00:00:00,1.62,2.0590622425079346,27.10260756221817,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Joao_da_Mata,2021-12-31T00:00:00,0.8995327102803738,1.4999399185180664,66.7465675651253,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Joao_del_Rei,2021-12-31T00:00:00,1.296875,1.8501768112182613,42.66423604574548,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Lourenco,2021-12-31T00:00:00,1.5087719298245608,2.457550048828125,62.88413114325952,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Sebastiao_da_Bela_Vista,2021-12-31T00:00:00,1.2,1.549487829208374,29.12398576736451,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Tome_das_Letras,2021-12-31T00:00:00,1.2,1.7727999687194824,47.73333072662354,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Senador_Jose_Bento,2021-12-31T00:00:00,1.32,1.4937429428100586,13.16234415227716,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Serrania,2021-12-31T00:00:00,1.08,1.7676440477371216,63.670745160844575,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Silvianopolis,2021-12-31T00:00:00,0.9601265822784812,1.353496551513672,40.97063621566257,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Soledade_de_Minas,2021-12-31T00:00:00,1.7204819277108432,2.3410255908966064,36.06801403670753,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Tocos_do_Moji,2021-12-31T00:00:00,1.259776536312849,1.5961310863494873,26.69954077896153,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Tres_Coracoes,2021-12-31T00:00:00,1.5,2.14533805847168,43.02253723144531,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Turvolandia,2021-12-31T00:00:00,1.3797385620915028,1.955830216407776,41.75368219345798,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Virginia,2021-12-31T00:00:00,1.433333333333333,1.6241607666015625,13.313541855923,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Aiuruoca,2022-12-31T00:00:00,1.5,1.5870304107666016,5.802027384440104,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Albertina,2022-12-31T00:00:00,1.44,1.6877877712249756,17.20748411284553,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Baependi,2022-12-31T00:00:00,1.079558011049724,1.5747692584991455,45.87166621716749,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Bandeira_do_Sul,2022-12-31T00:00:00,1.110344827586207,1.7718300819396973,59.57475893245721,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Borda_da_Mata,2022-12-31T00:00:00,1.2,1.688502311706543,40.70852597554525,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Brazopolis,2022-12-31T00:00:00,1.200934579439252,1.4483699798583984,20.603570307275227,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Bueno_Brandao,2022-12-31T00:00:00,1.440196078431373,1.787065505981445,24.08487516004586,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Cachoeira_de_Minas,2022-12-31T00:00:00,1.5,1.9237085580825808,28.24723720550537,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Caldas,2022-12-31T00:00:00,1.2,1.7189157009124756,43.24297507603964,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Cambuquira,2022-12-31T00:00:00,1.32,1.719867467880249,30.29298999092795,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Campanha,2022-12-31T00:00:00,1.266469038208169,1.6767005920410156,32.39175545998758,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Careacu,2022-12-31T00:00:00,1.2,1.4304182529449463,19.20152107874553,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Carmo_da_Cachoeira,2022-12-31T00:00:00,1.2,1.764576435089111,47.04803625742595,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Carmo_de_Minas,2022-12-31T00:00:00,1.14,1.551015853881836,36.0540222703365,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Carrancas,2022-12-31T00:00:00,1.6785714285714293,1.7195942401885986,2.443912181448386,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Carvalhopolis,2022-12-31T00:00:00,1.44,1.601171374320984,11.192456550068329,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Conceicao_das_Pedras,2022-12-31T00:00:00,1.375,1.6064441204071045,16.832299665971238,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Conceicao_do_Rio_Verde,2022-12-31T00:00:00,1.5,1.837035179138184,22.46901194254557,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Conceicao_dos_Ouros,2022-12-31T00:00:00,1.261168384879725,1.4907383918762207,18.20296240762404,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Congonhal,2022-12-31T00:00:00,1.080597014925373,1.7641944885253906,63.26109217016739,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Cordislandia,2022-12-31T00:00:00,1.260122699386503,1.7437065839767456,38.3759363136366,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Cristina,2022-12-31T00:00:00,1.320183486238532,1.739603877067566,31.769855872386863,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Datas,2022-12-31T00:00:00,0.75,2.0724613666534424,176.32818222045898,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Dom_Vicoso,2022-12-31T00:00:00,1.320588235294118,1.457338571548462,10.355259315473695,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Fama,2022-12-31T00:00:00,1.379787234042553,1.666416883468628,20.77346726757984,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Fortaleza_de_Minas,2022-12-31T00:00:00,1.5,1.5216858386993408,1.445722579956055,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Heliodora,2022-12-31T00:00:00,1.080140597539543,1.639488935470581,51.78477127932975,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Ibitiura_de_Minas,2022-12-31T00:00:00,1.3799999999999997,1.8487138748168943,33.96477353745615,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Inconfidentes,2022-12-31T00:00:00,1.739917695473251,2.295414447784424,31.9266108825958,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Ingai,2022-12-31T00:00:00,1.380228136882129,1.7732971906661987,28.47855678931415,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Itajuba,2022-12-31T00:00:00,1.068965517241379,1.7983146905899048,68.22943879712018,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Itutinga,2022-12-31T00:00:00,1.8000000000000005,1.607688069343567,-10.68399614757963,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Jesuania,2022-12-31T00:00:00,1.2,1.5407567024230957,28.39639186859132,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Lambari,2022-12-31T00:00:00,1.2,1.5727005004882812,31.058375040690112,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Luminarias,2022-12-31T00:00:00,1.380229885057471,1.938398361206055,40.44025435120485,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Maria_da_Fe,2022-12-31T00:00:00,1.2,1.6638054847717283,38.65045706431072,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Monsenhor_Paulo,2022-12-31T00:00:00,1.23,1.7785687446594238,44.59908493166048,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Monte_Siao,2022-12-31T00:00:00,1.2,1.730663180351257,44.22193169593812,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Natercia,2022-12-31T00:00:00,1.4399193548387097,1.5735241174697876,9.278628152480346,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Olimpio_Noronha,2022-12-31T00:00:00,1.2,1.4711050987243652,22.592091560363777,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Ouro_Fino,2022-12-31T00:00:00,1.2,1.7168670892715454,43.072257439295456,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Paraisopolis,2022-12-31T00:00:00,1.322222222222222,1.8091882467269893,36.82936319783959,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Pedralva,2022-12-31T00:00:00,1.320091324200913,1.7694602012634275,34.04074163842642,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Pirangucu,2022-12-31T00:00:00,1.333333333333333,1.3115429878234863,-1.6342759132385036,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Piranguinho,2022-12-31T00:00:00,1.380549682875264,1.468949317932129,6.403220119739227,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Poco_Fundo,2022-12-31T00:00:00,1.079978925184405,1.4974099397659302,38.65177410848544,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Pocos_de_Caldas,2022-12-31T00:00:00,1.169867549668874,1.7407680749893188,48.80044116806521,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Pouso_Alegre,2022-12-31T00:00:00,1.5,1.5026631355285645,0.1775423685709635,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Pouso_Alto,2022-12-31T00:00:00,1.5,1.5647684335708618,4.317895571390787,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Santa_Rita_de_Caldas,2022-12-31T00:00:00,1.8000000000000005,1.9795078039169312,9.972655773162826,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Santa_Rita_do_Sapucai,2022-12-31T00:00:00,1.14,1.6863034963607788,47.921359329892894,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Bento_Abade,2022-12-31T00:00:00,1.2,1.9486308097839355,62.385900815327965,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Goncalo_do_Sapucai,2022-12-31T00:00:00,1.08,1.9951573610305784,84.73679268801652,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Joao_da_Mata,2022-12-31T00:00:00,0.959748427672956,1.4549801349639893,51.60015823019285,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Joao_del_Rei,2022-12-31T00:00:00,1.836244541484716,1.8948352336883545,3.1907891830281163,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Lourenco,2022-12-31T00:00:00,1.8000000000000005,2.055173397064209,14.176299836900483,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Sebastiao_da_Bela_Vista,2022-12-31T00:00:00,1.5,1.4707304239273071,-1.951305071512858,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Sao_Tome_das_Letras,2022-12-31T00:00:00,1.434375,1.578534483909607,10.050334390212251,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Senador_Jose_Bento,2022-12-31T00:00:00,1.32,1.4378405809402466,8.927316737897463,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Serrania,2022-12-31T00:00:00,1.2,1.6873023509979248,40.60852924982707,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Silvianopolis,2022-12-31T00:00:00,0.9,1.319972038269043,46.66355980767144,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Soledade_de_Minas,2022-12-31T00:00:00,1.5,2.152904510498047,43.52696736653645,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Tocos_do_Moji,2022-12-31T00:00:00,1.5,1.5321295261383057,2.141968409220378,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Tres_Coracoes,2022-12-31T00:00:00,1.08,2.080026626586914,92.59505801730684,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Turvolandia,2022-12-31T00:00:00,1.4398692810457523,1.885019898414612,30.9160437845826,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_3_2022,Virginia,2022-12-31T00:00:00,1.62,1.557275652885437,-3.8718732786767336,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-26T23:59:52
V43_cluster_4_2022,Abadia_dos_Dourados,2021-12-31T00:00:00,1.8000000000000005,2.3814096450805664,32.30053583780922,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Acucena,2021-12-31T00:00:00,0.9,1.110315203666687,23.36835596296522,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Agua_Boa,2021-12-31T00:00:00,0.6171428571428572,1.2720597982406616,106.12080064084792,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Aguas_Vermelhas,2021-12-31T00:00:00,3.0,3.985809326171875,32.86031087239583,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Angelandia,2021-12-31T00:00:00,1.5133433283358322,1.7664614915847778,16.72575935080709,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Aricanduva,2021-12-31T00:00:00,0.8394736842105264,1.2185083627700806,45.15146641148294,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Ataleia,2021-12-31T00:00:00,0.6266666666666667,1.0739566087722778,71.37605459132092,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Bandeira,2021-12-31T00:00:00,0.96,1.0233484506607056,6.598796943823512,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Berilo,2021-12-31T00:00:00,1.8017241379310345,0.9031962752342224,-49.87044596786133,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Berizal,2021-12-31T00:00:00,3.541935483870968,2.9874958992004395,-15.653576616381038,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Bonfinopolis_de_Minas,2021-12-31T00:00:00,3.0,3.103191614151001,3.4397204717000327,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Buritis,2021-12-31T00:00:00,3.1195039458850062,3.4200921058654785,9.63576790396382,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Buritizeiro,2021-12-31T00:00:00,3.0,2.761703491210937,-7.943216959635417,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Capelinha,2021-12-31T00:00:00,1.4350318471337582,1.3759136199951172,-4.11964565502292,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Carai,2021-12-31T00:00:00,1.218,1.353729248046875,11.143616424209773,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Caranaiba,2021-12-31T00:00:00,2.28,1.8668714761734009,-18.119672097657848,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Catuji,2021-12-31T00:00:00,1.384615384615385,1.281373381614685,-7.456366883383884,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Congonhas_do_Norte,2021-12-31T00:00:00,0.7333333333333333,1.1956217288970947,63.03932666778566,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Coroaci,2021-12-31T00:00:00,1.5,1.7477266788482666,16.515111923217773,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Cuparaque,2021-12-31T00:00:00,1.32,1.230689525604248,-6.7659450299812125,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Diamantina,2021-12-31T00:00:00,2.9196787148594376,2.111607789993286,-27.67670705525058,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Formoso,2021-12-31T00:00:00,3.0,3.2496163845062256,8.32054615020752,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Franciscopolis,2021-12-31T00:00:00,1.2,2.531545877456665,110.96215645472208,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Frei_Gaspar,2021-12-31T00:00:00,1.2,1.20826256275177,0.6885468959808387,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Grao_Mogol,2021-12-31T00:00:00,1.155555555555555,1.542750597000122,33.507263201933704,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Indaiabira,2021-12-31T00:00:00,1.984444444444444,3.2960028648376465,66.09196967266982,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Itabirinha,2021-12-31T00:00:00,0.9659090909090908,0.9986484050750732,3.389481937184062,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Itacambira,2021-12-31T00:00:00,0.5,1.9272981882095337,285.45963764190674,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Itaipe,2021-12-31T00:00:00,0.7792792792792793,1.0017805099487305,28.55218104544402,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Itamarandiba,2021-12-31T00:00:00,1.632,1.7566295862197876,7.63661680268307,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Itambacuri,2021-12-31T00:00:00,0.8987341772151899,1.1396387815475464,26.804878510219947,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Jequitinhonha,2021-12-31T00:00:00,1.8000000000000005,2.664459228515625,48.02551269531248,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Joao_Pinheiro,2021-12-31T00:00:00,2.4,3.0238258838653564,25.99274516105653,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Jose_Goncalves_de_Minas,2021-12-31T00:00:00,1.502673796791444,1.3833723068237305,-7.939280649096954,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Juiz_de_Fora,2021-12-31T00:00:00,1.142857142857143,1.81267523765564,58.60908329486845,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Ladainha,2021-12-31T00:00:00,0.7199999999999999,1.2520315647125244,73.89327287673953,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Malacacheta,2021-12-31T00:00:00,1.8000000000000005,1.81186318397522,0.659065776401081,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Mantena,2021-12-31T00:00:00,0.7289999999999999,0.7612475752830505,4.423535704122177,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Minas_Novas,2021-12-31T00:00:00,1.7848101265822778,1.0851167440414429,-39.20267887994751,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Monte_Formoso,2021-12-31T00:00:00,0.55,1.3391722440719604,143.48586255853823,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Ninheira,2021-12-31T00:00:00,2.100246002460024,3.050626039505005,45.25089136852535,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Nova_Belem,2021-12-31T00:00:00,1.0,1.1586686372756958,15.86686372756958,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Novo_Cruzeiro,2021-12-31T00:00:00,1.226392251815981,1.20297110080719,-1.9097601908451625,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Novorizonte,2021-12-31T00:00:00,1.307692307692308,1.4249212741851809,8.96456802592556,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Ouro_Verde_de_Minas,2021-12-31T00:00:00,1.942857142857143,1.392892599105835,-28.30699857543497,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Padre_Paraiso,2021-12-31T00:00:00,0.4787878787878789,0.7606023550033569,58.85998553867579,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Paracatu,2021-12-31T00:00:00,2.4,2.665627956390381,11.067831516265873,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Pedra_Azul,2021-12-31T00:00:00,1.2,1.2962925434112549,8.024378617604578,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Pirapora,2021-12-31T00:00:00,3.0,3.185765027999878,6.192167599995932,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Pote,2021-12-31T00:00:00,0.6000000000000001,0.8229413032531738,37.15688387552895,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Rio_Pardo_de_Minas,2021-12-31T00:00:00,2.764006791171477,3.267575025558472,18.218777030340288,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Santa_Barbara_do_Monte_Verde,2021-12-31T00:00:00,1.4,1.609138011932373,14.93842942374094,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Santa_Maria_do_Suacui,2021-12-31T00:00:00,0.8,0.8449730277061462,5.621628463268275,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Santo_Antonio_do_Retiro,2021-12-31T00:00:00,1.2,1.6792542934417725,39.93785778681438,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Sao_Goncalo_do_Rio_Preto,2021-12-31T00:00:00,3.36,3.247896432876587,-3.3364156881968143,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Sao_Joao_do_Manteninha,2021-12-31T00:00:00,0.7,0.8631441593170166,23.30630847385952,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Sao_Joao_do_Paraiso,2021-12-31T00:00:00,3.0614754098360666,3.21134090423584,4.895204904088978,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Sao_Sebastiao_do_Maranhao,2021-12-31T00:00:00,0.9655172413793104,0.9055342078208924,-6.212528475693298,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Senador_Modestino_Goncalves,2021-12-31T00:00:00,2.7000000000000006,2.7446653842926025,1.6542734923185891,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Setubinha,2021-12-31T00:00:00,0.9329787234042556,1.1475727558135986,23.000956723464373,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Taiobeiras,2021-12-31T00:00:00,3.49869451697128,3.3396780490875244,-4.545022925334206,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Teofilo_Otoni,2021-12-31T00:00:00,0.6800000000000002,1.050141215324402,54.43253166535318,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Turmalina,2021-12-31T00:00:00,1.2797783933518008,1.6432087421417236,28.39791253531648,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Urucuia,2021-12-31T00:00:00,1.799276672694394,2.480233669281006,37.846152674612696,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Vargem_Grande_do_Rio_Pardo,2021-12-31T00:00:00,1.644444444444444,2.1507568359375,30.78926705025342,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Varzea_da_Palma,2021-12-31T00:00:00,1.68,3.457509279251098,105.80412376494634,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Abadia_dos_Dourados,2022-12-31T00:00:00,2.0384615384615383,2.3532581329345703,15.442851804337415,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Acucena,2022-12-31T00:00:00,1.0,1.02629816532135,2.6298165321350098,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Agua_Boa,2022-12-31T00:00:00,0.9136363636363636,1.213620901107788,32.8341284794594,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Aguas_Vermelhas,2022-12-31T00:00:00,3.0,3.3942997455596924,13.143324851989746,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Angelandia,2022-12-31T00:00:00,1.9799126637554585,1.775359869003296,-10.3314049400629,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Aricanduva,2022-12-31T00:00:00,1.2,1.1132444143295288,-7.22963213920593,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Ataleia,2022-12-31T00:00:00,0.7142857142857143,0.997592568397522,39.66295957565308,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Bandeira,2022-12-31T00:00:00,1.5,1.023829221725464,-31.744718551635746,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Berilo,2022-12-31T00:00:00,1.5625,1.2776747941970823,-18.22881317138672,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Berizal,2022-12-31T00:00:00,3.570967741935484,3.495850086212158,-2.10356578809674,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Bonfinopolis_de_Minas,2022-12-31T00:00:00,3.3,3.129200935363769,-5.175729231400919,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Buritis,2022-12-31T00:00:00,3.0,3.653621196746826,21.787373224894203,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Buritizeiro,2022-12-31T00:00:00,3.0,2.9342548847198486,-2.191503842671712,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Capelinha,2022-12-31T00:00:00,1.576751592356688,1.3972976207733154,-11.381245622536651,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Carai,2022-12-31T00:00:00,1.2,1.3937361240386963,16.144677003224693,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Caranaiba,2022-12-31T00:00:00,3.405405405405405,2.018629312515259,-40.72279002931382,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Catuji,2022-12-31T00:00:00,1.3230769230769233,1.4147099256515503,6.925750194593902,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Congonhas_do_Norte,2022-12-31T00:00:00,0.9,1.1025816202163696,22.509068912929955,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Coroaci,2022-12-31T00:00:00,2.1,1.6906285285949707,-19.49387959071569,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Cuparaque,2022-12-31T00:00:00,1.02,1.2862298488616943,26.10096557467591,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Diamantina,2022-12-31T00:00:00,2.965183752417796,2.5287182331085205,-14.719678635544362,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Formoso,2022-12-31T00:00:00,3.3607142857142858,3.1178948879241943,-7.225231815220575,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Franciscopolis,2022-12-31T00:00:00,1.255555555555556,2.238363742828369,78.27675827836562,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Frei_Gaspar,2022-12-31T00:00:00,1.133333333333333,1.2883723974227903,13.679917419658011,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Grao_Mogol,2022-12-31T00:00:00,1.177777777777778,1.6013953685760498,35.96753129419288,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Indaiabira,2022-12-31T00:00:00,2.1723404255319148,2.858743667602539,31.597406833809348,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Itabirinha,2022-12-31T00:00:00,0.8674242424242423,1.0304007530212402,18.788558426902817,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Itacambira,2022-12-31T00:00:00,0.75,1.7155654430389404,128.7420590718587,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Itaipe,2022-12-31T00:00:00,0.9604651162790696,0.961387813091278,0.0960677068401184,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Itamarandiba,2022-12-31T00:00:00,2.136,1.707093596458435,-20.079887806253044,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Itambacuri,2022-12-31T00:00:00,0.9620253164556964,1.076520919799805,11.901516663400734,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Jequitinhonha,2022-12-31T00:00:00,2.4,2.380857229232788,-0.797615448633826,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Joao_Pinheiro,2022-12-31T00:00:00,2.4,2.8689005374908447,19.537522395451862,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Jose_Goncalves_de_Minas,2022-12-31T00:00:00,1.5,1.480008602142334,-1.3327598571777344,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Juiz_de_Fora,2022-12-31T00:00:00,1.5714285714285707,1.1449376344680786,-27.14033235203133,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Ladainha,2022-12-31T00:00:00,0.6000000000000001,1.1090022325515747,84.83370542526242,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Malacacheta,2022-12-31T00:00:00,1.5595238095238098,1.8306108713150024,17.382681824778764,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Mantena,2022-12-31T00:00:00,0.75,0.7484172582626343,-0.211032231648763,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Minas_Novas,2022-12-31T00:00:00,1.7848101265822778,1.362476825714111,-23.662645935166783,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Monte_Formoso,2022-12-31T00:00:00,0.6000000000000001,1.0388702154159546,73.14503590265907,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Ninheira,2022-12-31T00:00:00,2.9401197604790417,2.9012258052825928,-1.3228697592274878,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Nova_Belem,2022-12-31T00:00:00,0.96,1.192116379737854,24.17878955602648,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Novo_Cruzeiro,2022-12-31T00:00:00,1.180722891566265,1.236011028289795,4.68256668168671,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Novorizonte,2022-12-31T00:00:00,1.461538461538461,1.401264786720276,-4.123988277033721,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Ouro_Verde_de_Minas,2022-12-31T00:00:00,2.0,1.6596152782440186,-17.019236087799055,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Padre_Paraiso,2022-12-31T00:00:00,0.6000000000000001,0.6869027614593506,14.483793576558416,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Paracatu,2022-12-31T00:00:00,2.4,2.691657543182373,12.15239763259888,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Pedra_Azul,2022-12-31T00:00:00,1.5333333333333332,1.2561193704605105,-18.079171491705846,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Pirapora,2022-12-31T00:00:00,3.3595505617977524,3.2314438819885254,-3.813208863886689,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Pote,2022-12-31T00:00:00,1.2,0.7476630210876465,-37.69474824269612,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Rio_Pardo_de_Minas,2022-12-31T00:00:00,2.515254237288135,3.176835775375366,26.30277004524707,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Santa_Barbara_do_Monte_Verde,2022-12-31T00:00:00,1.3,1.6176670789718628,24.435929151681748,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Santa_Maria_do_Suacui,2022-12-31T00:00:00,1.0,0.8271256685256958,-17.28743314743042,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Santo_Antonio_do_Retiro,2022-12-31T00:00:00,1.2,1.5895946025848389,32.46621688206991,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Sao_Goncalo_do_Rio_Preto,2022-12-31T00:00:00,3.0,3.4631333351135254,15.437777837117514,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Sao_Joao_do_Manteninha,2022-12-31T00:00:00,1.2,0.8498480319976807,-29.179330666859943,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Sao_Joao_do_Paraiso,2022-12-31T00:00:00,3.09016393442623,3.4233205318450928,10.781194929735074,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Sao_Sebastiao_do_Maranhao,2022-12-31T00:00:00,1.141666666666667,0.9292038679122924,-18.60988018286492,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Senador_Modestino_Goncalves,2022-12-31T00:00:00,2.7000000000000006,2.974059581756592,10.150354879873746,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Setubinha,2022-12-31T00:00:00,1.079761904761905,1.1066821813583374,2.493167843550527,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Taiobeiras,2022-12-31T00:00:00,3.14031971580817,3.5975890159606934,14.561233935852416,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Teofilo_Otoni,2022-12-31T00:00:00,0.8181818181818183,0.9610638618469238,17.463360892401777,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Turmalina,2022-12-31T00:00:00,1.205163043478261,1.5428420305252075,28.01936127018632,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Urucuia,2022-12-31T00:00:00,1.9193245778611627,2.360870122909546,23.0052566481709,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Vargem_Grande_do_Rio_Pardo,2022-12-31T00:00:00,1.8000000000000005,2.0009636878967285,11.164649327596011,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_4_2022,Varzea_da_Palma,2022-12-31T00:00:00,2.5200000000000005,3.149365425109864,24.974818456740586,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2022_(2022)
    Modelo LSTM treinado com dados de 2012 a 2020, validado com os dados de 2021 e testado com os dados de 2022.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:00:27
V43_cluster_0_2023,Aguanil,2022-12-31T00:00:00,1.56,1.8338476419448853,17.554336022108025,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Alfenas,2022-12-31T00:00:00,0.9243951612903224,1.839494585990905,98.99439796106635,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Alto_Caparao,2022-12-31T00:00:00,1.5,1.8289363384246824,21.92908922831217,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Alto_Jequitiba,2022-12-31T00:00:00,0.9,1.520846962928772,68.98299588097466,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Amparo_do_Serra,2022-12-31T00:00:00,1.8000000000000005,1.2849713563919067,-28.61270242267186,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Araponga,2022-12-31T00:00:00,1.260041407867495,1.237014651298523,-1.8274603060817507,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Astolfo_Dutra,2022-12-31T00:00:00,0.625,1.9712672233581543,215.4027557373047,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Bambui,2022-12-31T00:00:00,1.5,1.4804102182388306,-1.305985450744629,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Boa_Esperanca,2022-12-31T00:00:00,0.9726256983240223,1.890313982963562,94.35163868493832,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Bom_Jesus_do_Galho,2022-12-31T00:00:00,0.7801587301587303,1.0918704271316528,39.954907241697086,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Bom_Sucesso,2022-12-31T00:00:00,1.440136054421769,1.571062088012695,9.091226706597151,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Caete,2022-12-31T00:00:00,1.5333333333333332,1.2517409324645996,-18.364721795786977,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Caiana,2022-12-31T00:00:00,0.9,1.239912986755371,37.76810963948567,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Cajuri,2022-12-31T00:00:00,1.050602409638554,1.2565486431121826,19.602680479714653,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Camacho,2022-12-31T00:00:00,1.380176211453745,1.5670430660247805,13.539347586219275,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Campo_do_Meio,2022-12-31T00:00:00,1.580968858131488,1.73191499710083,9.547698437763154,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Campos_Altos,2022-12-31T00:00:00,1.680042238648363,1.6617190837860107,-1.0906365590602074,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Campos_Gerais,2022-12-31T00:00:00,1.535771358328211,1.9012600183486936,23.79837715025116,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Cana_Verde,2022-12-31T00:00:00,1.02,1.351691722869873,32.51879635979147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Canaa,2022-12-31T00:00:00,1.320338983050847,1.322846293449402,0.1898989903911924,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Candeias,2022-12-31T00:00:00,1.020017406440383,1.5490801334381104,51.868009668975134,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Caparao,2022-12-31T00:00:00,1.32,1.9599684476852417,48.48245815797284,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Capitolio,2022-12-31T00:00:00,1.08,1.4385643005371094,33.20039819788049,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Caputira,2022-12-31T00:00:00,1.440044247787611,1.4317235946655271,-0.5778053788879707,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Carangola,2022-12-31T00:00:00,1.02,1.2914884090423584,26.61651069042729,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Caratinga,2022-12-31T00:00:00,1.620022123893805,1.3506301641464231,-16.62890622134743,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Carmo_da_Mata,2022-12-31T00:00:00,1.56,1.2538777589797974,-19.62322057821812,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Carmo_do_Rio_Claro,2022-12-31T00:00:00,1.619555143651529,2.007013320922852,23.9237409599861,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Carmopolis_de_Minas,2022-12-31T00:00:00,1.8000000000000005,1.7432522773742676,-3.1526512569851493,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Cassia,2022-12-31T00:00:00,1.413626373626374,1.649250030517578,16.66802921105376,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Catas_Altas_da_Noruega,2022-12-31T00:00:00,1.0,0.8953014612197876,-10.46985387802124,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Chale,2022-12-31T00:00:00,1.44,1.3107837438583374,-8.973351120948788,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Claudio,2022-12-31T00:00:00,1.140522875816993,1.8511327505111688,62.30562225112266,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Conceicao_da_Barra_de_Minas,2022-12-31T00:00:00,1.370833333333333,1.8838586807250977,37.424341451070994,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Conceicao_de_Ipanema,2022-12-31T00:00:00,1.5,1.3201143741607666,-11.992375055948894,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Coqueiral,2022-12-31T00:00:00,1.2,1.6457693576812744,37.14744647343954,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Corrego_Danta,2022-12-31T00:00:00,1.5,1.3916882276535034,-7.220784823099772,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Cristais,2022-12-31T00:00:00,1.059063136456212,1.7836809158325195,68.42064032187825,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Desterro_de_Entre_Rios,2022-12-31T00:00:00,1.8000000000000005,1.9873539209365845,10.408551163143564,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Divinesia,2022-12-31T00:00:00,2.2230769230769227,2.06185245513916,-7.252311706542954,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Divino,2022-12-31T00:00:00,1.08,1.3069868087768557,21.01729710896809,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Doresopolis,2022-12-31T00:00:00,1.32,1.4032673835754397,6.308135119351468,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Durande,2022-12-31T00:00:00,1.5,1.5540499687194824,3.603331247965495,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Eloi_Mendes,2022-12-31T00:00:00,1.090201870999508,1.5285229682922363,40.205498536786685,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Entre_Folhas,2022-12-31T00:00:00,1.2,0.944838523864746,-21.26345634460449,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Entre_Rios_de_Minas,2022-12-31T00:00:00,1.8000000000000005,1.984394907951355,10.244161552853038,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ervalia,2022-12-31T00:00:00,1.2,1.2705645561218262,5.880379676818852,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Espera_Feliz,2022-12-31T00:00:00,1.2,1.650442361831665,37.53686348597209,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Faria_Lemos,2022-12-31T00:00:00,1.200305810397553,1.0299354791641235,-14.19391039830101,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ferros,2022-12-31T00:00:00,1.230769230769231,1.1415057182312012,-7.252660393714927,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Fervedouro,2022-12-31T00:00:00,1.4399108138238568,1.1572635173797607,-19.629500225329377,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Guape,2022-12-31T00:00:00,1.262758620689655,1.7548342943191528,38.96830839774832,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ibituruna,2022-12-31T00:00:00,1.2,1.649746060371399,37.47883836428325,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ilicinea,2022-12-31T00:00:00,1.080069324090121,1.9787254333496087,83.20355825460928,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Itapecerica,2022-12-31T00:00:00,1.040506329113924,1.4504040479660034,39.39406300403196,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ituiutaba,2022-12-31T00:00:00,1.75,1.607232689857483,-8.158132008143834,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Itumirim,2022-12-31T00:00:00,1.249307479224377,1.4543720483779907,16.414259304757103,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Lajinha,2022-12-31T00:00:00,1.419975786924939,1.2982685565948486,-8.571077862789211,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Lavras,2022-12-31T00:00:00,1.260078277886497,1.5831305980682373,25.637480293969457,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Luisburgo,2022-12-31T00:00:00,1.5,1.6660418510437012,11.069456736246746,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Machado,2022-12-31T00:00:00,0.964047619047619,1.6414690017700195,70.26845659259278,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Manhuacu,2022-12-31T00:00:00,1.44,1.1888306140899658,-17.442318465974594,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Manhumirim,2022-12-31T00:00:00,1.3799999999999997,1.3466871976852417,-2.413971182228839,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Martins_Soares,2022-12-31T00:00:00,1.3799999999999997,1.4263101816177368,3.3558102621548667,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Matipo,2022-12-31T00:00:00,1.26,1.3187224864959717,4.660514801267593,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Medeiros,2022-12-31T00:00:00,1.5,1.5701669454574585,4.677796363830566,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Miradouro,2022-12-31T00:00:00,0.96,1.2568511962890625,30.92199961344403,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Mirai,2022-12-31T00:00:00,1.2,1.2121782302856443,1.0148525238037147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Moeda,2022-12-31T00:00:00,1.25,1.1366751194000244,-9.065990447998049,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Muriae,2022-12-31T00:00:00,0.9897142857142858,1.1525298357009888,16.450762845076802,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Mutum,2022-12-31T00:00:00,1.379940564635958,1.4554014205932615,5.468413487591845,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Nazareno,2022-12-31T00:00:00,1.319811320754717,1.7219703197479248,30.47094631399572,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Nepomuceno,2022-12-31T00:00:00,0.8699884125144843,1.5883212089538574,82.56808781661947,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Oliveira,2022-12-31T00:00:00,1.535560504825538,1.5845770835876465,3.1920968667839897,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Orizania,2022-12-31T00:00:00,1.5,1.348680019378662,-10.087998708089192,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Paraguacu,2022-12-31T00:00:00,1.043954802259887,1.453705072402954,39.24980940324866,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Passa_Tempo,2022-12-31T00:00:00,1.507692307692308,1.5011858940124512,-0.43154784611296,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Perdoes,2022-12-31T00:00:00,1.259859154929577,1.65135657787323,31.074697628842223,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Pimenta,2022-12-31T00:00:00,1.3502325581395351,1.586627721786499,17.5077368873914,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Piranga,2022-12-31T00:00:00,1.8000000000000005,2.403970956802368,33.55394204457599,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Piumhi,2022-12-31T00:00:00,1.2,1.5037376880645752,25.311474005381275,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ponte_Nova,2022-12-31T00:00:00,1.25,1.3154455423355105,5.23564338684082,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Porto_Firme,2022-12-31T00:00:00,1.32,1.332795023918152,0.9693199937993784,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Raul_Soares,2022-12-31T00:00:00,0.8399548532731377,1.2480260133743286,48.58251113271368,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Reduto,2022-12-31T00:00:00,1.260059171597633,1.379413604736328,9.472129232420508,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ribeirao_Vermelho,2022-12-31T00:00:00,1.32,1.4902169704437256,12.89522503361557,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ritapolis,2022-12-31T00:00:00,1.8000000000000005,1.7727012634277344,-1.5165964762369937,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Rosario_da_Limeira,2022-12-31T00:00:00,1.02,1.035417914390564,1.5115602343690144,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santa_Barbara_do_Leste,2022-12-31T00:00:00,1.05015873015873,1.188334822654724,13.157638795718904,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santa_Margarida,2022-12-31T00:00:00,1.3799999999999997,1.2717279195785522,-7.845802929090395,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santa_Rita_de_Minas,2022-12-31T00:00:00,1.019909502262443,1.2279622554779053,20.39913862494108,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santa_Rita_do_Itueto,2022-12-31T00:00:00,1.6399999999999997,1.3615556955337524,-16.978311247941907,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santana_da_Vargem,2022-12-31T00:00:00,0.9900921658986176,1.7631421089172363,78.07858395859448,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santana_do_Jacare,2022-12-31T00:00:00,1.5,1.316655158996582,-12.222989400227863,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santana_do_Manhuacu,2022-12-31T00:00:00,1.26,1.5097755193710327,19.82345391833593,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Domingos_das_Dores,2022-12-31T00:00:00,1.2,1.490880250930786,24.24002091089885,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Francisco_de_Paula,2022-12-31T00:00:00,1.62,1.5056447982788086,-7.058963069209352,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Francisco_do_Gloria,2022-12-31T00:00:00,0.9601476014760146,1.021582007408142,6.3984335156058965,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Joao_do_Manhuacu,2022-12-31T00:00:00,1.2,1.3429075479507446,11.908962329228723,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Jose_do_Mantimento,2022-12-31T00:00:00,1.499236641221374,1.5259087085723877,1.7790431888914424,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Roque_de_Minas,2022-12-31T00:00:00,1.32,1.3645012378692627,3.371305899186563,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Tiago,2022-12-31T00:00:00,1.3210526315789468,1.858639359474182,40.69381605581464,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Tomas_de_Aquino,2022-12-31T00:00:00,1.2,1.61405348777771,34.504457314809166,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Senador_Firmino,2022-12-31T00:00:00,1.565217391304348,1.48509418964386,-5.118982328308958,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Senhora_de_Oliveira,2022-12-31T00:00:00,1.5,1.901776432991028,26.785095532735188,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sericita,2022-12-31T00:00:00,1.3799999999999997,1.3071587085723877,-5.278354451276232,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Simonesia,2022-12-31T00:00:00,1.8000000000000005,1.2262707948684692,-31.87384472952949,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Tapirai,2022-12-31T00:00:00,1.324520819563781,1.6004663705825806,20.833613707157863,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Tombos,2022-12-31T00:00:00,1.2,0.9714371562004088,-19.04690364996592,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Tres_Pontas,2022-12-31T00:00:00,0.975023651844844,1.7758013010025024,82.12904862794923,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ubaporanga,2022-12-31T00:00:00,1.2,1.2943439483642578,7.861995697021489,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Vargem_Bonita,2022-12-31T00:00:00,1.235217391304348,1.5952095985412598,29.144036488732727,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Vermelho_Novo,2022-12-31T00:00:00,0.9598214285714286,1.078586220741272,12.373634160951124,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Vicosa,2022-12-31T00:00:00,1.079768786127168,1.1019880771636963,2.0577823069161547,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Vieiras,2022-12-31T00:00:00,1.32,1.0477471351623535,-20.62521703315504,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Aguanil,2023-12-31T00:00:00,1.717774762550882,1.689192533493042,-1.663910175010112,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Alfenas,2023-12-31T00:00:00,1.698430922311519,1.3882646560668943,-18.2619300066968,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Alto_Caparao,2023-12-31T00:00:00,1.32,1.5471328496932983,17.207034067674112,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Alto_Jequitiba,2023-12-31T00:00:00,1.08,0.9930594563484192,-8.05005033810934,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Amparo_do_Serra,2023-12-31T00:00:00,1.319444444444444,1.2305474281311035,-6.737458078484752,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Araponga,2023-12-31T00:00:00,1.5,1.0834558010101318,-27.76961326599121,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Astolfo_Dutra,2023-12-31T00:00:00,0.625,0.923721969127655,47.795515060424805,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Bambui,2023-12-31T00:00:00,1.5,1.3441777229309082,-10.38815180460612,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Boa_Esperanca,2023-12-31T00:00:00,1.08,1.4078598022460938,30.35738909686053,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Bom_Jesus_do_Galho,2023-12-31T00:00:00,1.2003192338387871,0.839687168598175,-30.044679371441944,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Bom_Sucesso,2023-12-31T00:00:00,1.5,1.3493739366531372,-10.04173755645752,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Caete,2023-12-31T00:00:00,1.166666666666667,1.2855435609817505,10.189448084150014,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Caiana,2023-12-31T00:00:00,1.08,0.9260145425796508,-14.257912724106406,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Cajuri,2023-12-31T00:00:00,0.8200000000000001,1.169594168663025,42.63343520280791,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Camacho,2023-12-31T00:00:00,1.680155642023346,1.4604803323745728,-13.0746999953068,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Campo_do_Meio,2023-12-31T00:00:00,0.8771626297577856,1.559078574180603,77.74110766792671,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Campos_Altos,2023-12-31T00:00:00,1.380040526849037,1.422587275505066,3.0830071891564907,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Campos_Gerais,2023-12-31T00:00:00,1.560242401107029,1.56988525390625,0.6180355560379024,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Cana_Verde,2023-12-31T00:00:00,1.3196428571428571,1.1594924926757812,-12.135886887897492,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Canaa,2023-12-31T00:00:00,1.560135135135135,1.2682006359100342,-18.712129010530496,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Candeias,2023-12-31T00:00:00,1.080032206119163,1.1177176237106323,3.4892864655289206,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Caparao,2023-12-31T00:00:00,1.32,1.5982990264892578,21.083259582519524,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Capitolio,2023-12-31T00:00:00,1.32,1.2184083461761477,-7.696337410897924,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Caputira,2023-12-31T00:00:00,1.380065005417118,0.9662996530532836,-29.981584254342835,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Carangola,2023-12-31T00:00:00,1.140118343195266,1.012637495994568,-11.181369720219006,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Caratinga,2023-12-31T00:00:00,1.3799999999999997,1.1559714078903198,-16.233955949976806,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Carmo_da_Mata,2023-12-31T00:00:00,1.2,1.1707783937454224,-2.4351338545481327,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Carmo_do_Rio_Claro,2023-12-31T00:00:00,1.816856256463288,1.744497299194336,-3.982646233654541,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Carmopolis_de_Minas,2023-12-31T00:00:00,1.5,1.701650857925415,13.443390528361002,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Cassia,2023-12-31T00:00:00,1.6377649325626198,1.5422792434692385,-5.8302438399370615,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Catas_Altas_da_Noruega,2023-12-31T00:00:00,1.1,0.7447828054428101,-32.292472232471816,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Chale,2023-12-31T00:00:00,1.3799999999999997,1.0646591186523438,-22.85078850345333,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Claudio,2023-12-31T00:00:00,2.398692810457516,1.2904587984085083,-46.2015814287461,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Conceicao_da_Barra_de_Minas,2023-12-31T00:00:00,1.680769230769231,1.5554015636444092,-7.458945870126699,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Conceicao_de_Ipanema,2023-12-31T00:00:00,1.5,1.2912747859954834,-13.915014266967772,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Coqueiral,2023-12-31T00:00:00,1.32,1.3914426565170288,5.412322463411268,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Corrego_Danta,2023-12-31T00:00:00,1.44,1.2697745561599731,-11.82121137777964,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Cristais,2023-12-31T00:00:00,1.5631111111111111,1.4067714214324951,-10.001828313246689,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Desterro_de_Entre_Rios,2023-12-31T00:00:00,1.375,1.6459523439407349,19.70562501387163,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Divinesia,2023-12-31T00:00:00,2.1,1.920541405677796,-8.545647348676413,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Divino,2023-12-31T00:00:00,1.02,0.981387972831726,-3.785492859634701,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Doresopolis,2023-12-31T00:00:00,1.501960784313725,1.3050590753555298,-13.10964380792162,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Durande,2023-12-31T00:00:00,1.3799999999999997,1.2392795085906982,-10.197137058645032,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Eloi_Mendes,2023-12-31T00:00:00,1.577412806790921,1.2972010374069214,-17.764010040850415,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Entre_Folhas,2023-12-31T00:00:00,1.3210526315789468,0.8315335512161255,-37.05522919081119,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Entre_Rios_de_Minas,2023-12-31T00:00:00,1.56,1.785879611968994,14.479462305704748,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ervalia,2023-12-31T00:00:00,1.380044843049327,1.2056095600128174,-12.639827170476575,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Espera_Feliz,2023-12-31T00:00:00,1.08,1.0482378005981443,-2.940944389060698,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Faria_Lemos,2023-12-31T00:00:00,1.380152671755725,0.8642846345901489,-37.37760667516066,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ferros,2023-12-31T00:00:00,1.17948717948718,0.9074821472167968,-23.06129621422812,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Fervedouro,2023-12-31T00:00:00,1.2,1.0667197704315186,-11.10668579737345,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Guape,2023-12-31T00:00:00,1.560674157303371,1.5138390064239502,-3.0009563918419304,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ibituruna,2023-12-31T00:00:00,1.8000000000000005,1.4446805715560913,-19.73996824688383,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ilicinea,2023-12-31T00:00:00,1.560032362459547,1.5399508476257324,-1.287249887698097,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Itapecerica,2023-12-31T00:00:00,0.9037974683544304,1.143013596534729,26.46789093311425,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ituiutaba,2023-12-31T00:00:00,1.0,1.2450703382492063,24.50703382492065,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Itumirim,2023-12-31T00:00:00,1.532033426183844,1.2569127082824707,-17.957879586653274,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Lajinha,2023-12-31T00:00:00,1.4399536768963517,1.0877466201782229,-24.459610220050223,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Lavras,2023-12-31T00:00:00,1.5,1.4096091985702517,-6.026053428649902,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Luisburgo,2023-12-31T00:00:00,1.44,1.3936551809310913,-3.2183902131186555,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Machado,2023-12-31T00:00:00,1.500560931145702,1.353499174118042,-9.80045221591742,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Manhuacu,2023-12-31T00:00:00,1.2,1.0210256576538086,-14.91452852884928,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Manhumirim,2023-12-31T00:00:00,1.44,1.2336132526397705,-14.332413011127048,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Martins_Soares,2023-12-31T00:00:00,1.2,1.304135799407959,8.677983283996586,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Matipo,2023-12-31T00:00:00,1.25990675990676,1.0096580982208252,-19.86247472030823,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Medeiros,2023-12-31T00:00:00,1.86,1.412104249000549,-24.080416720400567,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Miradouro,2023-12-31T00:00:00,1.140084388185654,1.0831843614578247,-4.990860967614926,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Mirai,2023-12-31T00:00:00,1.08,1.0177335739135742,-5.765409822817208,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Moeda,2023-12-31T00:00:00,1.0,1.083225965499878,8.322596549987793,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Muriae,2023-12-31T00:00:00,1.057297297297297,1.0065107345581057,-4.803432569913305,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Mutum,2023-12-31T00:00:00,1.019985196150999,1.3696272373199463,34.27912899994543,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Nazareno,2023-12-31T00:00:00,1.5599056603773582,1.4016046524047852,-10.148114209309192,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Nepomuceno,2023-12-31T00:00:00,1.650045578851413,1.1810784339904783,-28.42146610200791,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Oliveira,2023-12-31T00:00:00,1.8240227434257288,1.4303085803985596,-21.584937164090828,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Orizania,2023-12-31T00:00:00,1.2,1.2374862432479858,3.123853603998824,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Paraguacu,2023-12-31T00:00:00,1.298291457286432,1.216479778289795,-6.301487892990713,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Passa_Tempo,2023-12-31T00:00:00,1.625,1.5145390033721924,-6.797599792480469,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Perdoes,2023-12-31T00:00:00,1.6799401197604789,1.4881175756454468,-11.418415564858444,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Pimenta,2023-12-31T00:00:00,1.504186046511628,1.3237383365631104,-11.996369090578623,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Piranga,2023-12-31T00:00:00,2.1,1.825415134429932,-13.075469789050878,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Piumhi,2023-12-31T00:00:00,1.7399633363886338,1.2383137941360474,-28.831040962838955,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ponte_Nova,2023-12-31T00:00:00,1.333333333333333,1.1499570608139038,-13.753220438957197,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Porto_Firme,2023-12-31T00:00:00,1.200764818355641,1.1486244201660156,-4.3422656454098805,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Raul_Soares,2023-12-31T00:00:00,1.5,0.9144582748413086,-39.03611501057942,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Reduto,2023-12-31T00:00:00,0.9,1.173702597618103,30.41139973534478,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ribeirao_Vermelho,2023-12-31T00:00:00,1.5,1.3267828226089478,-11.547811826070149,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ritapolis,2023-12-31T00:00:00,2.102222222222222,1.623354196548462,-22.779134413656674,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Rosario_da_Limeira,2023-12-31T00:00:00,1.2,0.8549901247024536,-28.7508229414622,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santa_Barbara_do_Leste,2023-12-31T00:00:00,1.08,0.9710050225257874,-10.092127543908584,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santa_Margarida,2023-12-31T00:00:00,1.32,1.0211776494979858,-22.6380568562132,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santa_Rita_de_Minas,2023-12-31T00:00:00,1.019930675909879,1.1331655979156494,11.10221750167027,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santa_Rita_do_Itueto,2023-12-31T00:00:00,1.2,1.3481143712997437,12.34286427497864,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santana_da_Vargem,2023-12-31T00:00:00,1.5593593593593589,1.3660001754760742,-12.399911715201016,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santana_do_Jacare,2023-12-31T00:00:00,0.9011235955056182,1.1958361864089966,32.70501320498837,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Santana_do_Manhuacu,2023-12-31T00:00:00,1.32,1.25494122505188,-4.928695071827286,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Domingos_das_Dores,2023-12-31T00:00:00,1.296078431372549,1.3290916681289673,2.5471635016298464,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Francisco_de_Paula,2023-12-31T00:00:00,1.56,1.4618589878082275,-6.291090525113622,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Francisco_do_Gloria,2023-12-31T00:00:00,1.08,0.7278532981872559,-32.60617609377261,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Joao_do_Manhuacu,2023-12-31T00:00:00,1.2,1.0765950679779053,-10.283744335174555,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Jose_do_Mantimento,2023-12-31T00:00:00,1.5,1.3130488395690918,-12.46341069539388,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Roque_de_Minas,2023-12-31T00:00:00,1.8000000000000005,1.3617398738861084,-24.3477847841051,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Tiago,2023-12-31T00:00:00,1.560526315789474,1.5334124565124512,-1.7374817074652054,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sao_Tomas_de_Aquino,2023-12-31T00:00:00,1.319968346082828,1.304689884185791,-1.1574869914401904,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Senador_Firmino,2023-12-31T00:00:00,1.436170212765957,1.5226826667785645,6.023830131248223,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Senhora_de_Oliveira,2023-12-31T00:00:00,1.2,1.568655252456665,30.721271038055427,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Sericita,2023-12-31T00:00:00,1.26,0.8268060088157654,-34.38047549081227,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Simonesia,2023-12-31T00:00:00,1.5,1.0986328125,-26.7578125,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Tapirai,2023-12-31T00:00:00,1.5579665220086798,1.4238152503967283,-8.610664588542672,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Tombos,2023-12-31T00:00:00,1.32,0.8998643159866333,-31.82846091010354,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Tres_Pontas,2023-12-31T00:00:00,1.5900000000000003,1.3602516651153564,-14.449580810354956,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Ubaporanga,2023-12-31T00:00:00,1.5,1.1223748922348022,-25.17500718434652,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Vargem_Bonita,2023-12-31T00:00:00,1.487234042553192,1.5713634490966797,5.656769824812473,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Vermelho_Novo,2023-12-31T00:00:00,1.5,0.9767507910728456,-34.88328059514363,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Vicosa,2023-12-31T00:00:00,1.5004329004329,1.050010323524475,-30.019508155177785,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_0_2023,Vieiras,2023-12-31T00:00:00,1.5,0.8718109726905823,-41.87926848729451,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:01
V43_cluster_1_2023,Almenara,2022-12-31T00:00:00,0.78,0.7376985549926758,-5.423262180426185,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Alpinopolis,2022-12-31T00:00:00,1.4420494699646638,2.167276620864868,50.29141967771573,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Alterosa,2022-12-31T00:00:00,1.080104712041885,1.559004783630371,44.33830037489134,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Andradas,2022-12-31T00:00:00,1.26,1.3780523538589478,9.36923443324982,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Araguari,2022-12-31T00:00:00,1.919968366943456,2.477799415588379,29.054179133845665,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Arapua,2022-12-31T00:00:00,1.14,1.4802415370941162,29.84574886790494,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Araxa,2022-12-31T00:00:00,1.077872465471643,1.7500064373016355,62.35746745194833,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Arceburgo,2022-12-31T00:00:00,0.9244897959183672,1.6200590133666992,75.23817142377102,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Areado,2022-12-31T00:00:00,0.9076923076923076,1.7060036659240725,87.94955641536392,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Bom_Jesus_da_Penha,2022-12-31T00:00:00,1.6298200514138823,1.768557071685791,8.512413388923102,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Botelhos,2022-12-31T00:00:00,0.9,1.1233205795288086,24.813397725423176,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Botumirim,2022-12-31T00:00:00,0.7241379310344828,0.7145667672157288,-1.321732146399362,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Cabo_Verde,2022-12-31T00:00:00,1.35,1.3703001737594604,1.503716574774841,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Campestre,2022-12-31T00:00:00,1.020018115942029,1.2240020036697388,19.99806518527588,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Capetinga,2022-12-31T00:00:00,1.407056229327453,2.19808316230774,56.218572967647695,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Carmo_do_Paranaiba,2022-12-31T00:00:00,1.392969472710453,2.0488944053649902,47.08824891748938,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Cascalho_Rico,2022-12-31T00:00:00,2.580434782608696,2.309065818786621,-10.516404663702984,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Claraval,2022-12-31T00:00:00,1.289915966386555,2.5833895206451416,100.27579997183828,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Conceicao_da_Aparecida,2022-12-31T00:00:00,1.53,1.8900827169418333,23.534818100773432,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Coromandel,2022-12-31T00:00:00,1.260025542784164,1.9619885683059688,55.71022187143455,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Corrego_Fundo,2022-12-31T00:00:00,1.079051383399209,1.914556741714477,77.42961745559084,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Cruzeiro_da_Fortaleza,2022-12-31T00:00:00,1.5598526703499078,2.09608793258667,34.37730193560352,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Delfinopolis,2022-12-31T00:00:00,1.3799999999999997,1.7945400476455688,30.03913388736009,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Divisa_Nova,2022-12-31T00:00:00,1.260204081632653,1.3970870971679688,10.86197208296433,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Dom_Cavati,2022-12-31T00:00:00,0.6000000000000001,0.9200295805931092,53.33826343218483,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Dores_do_Turvo,2022-12-31T00:00:00,1.2,0.995980143547058,-17.001654704411823,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Estrela_do_Indaia,2022-12-31T00:00:00,1.86,1.7677987813949585,-4.957054763711902,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Estrela_do_Sul,2022-12-31T00:00:00,1.460045146726862,1.892543077468872,29.622229950326297,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Guaranesia,2022-12-31T00:00:00,1.086968085106383,1.303581476211548,19.92821997933496,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Guarani,2022-12-31T00:00:00,1.2,0.90304696559906,-24.746086200078327,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Guarda-Mor,2022-12-31T00:00:00,1.858757062146893,2.119126319885254,14.00770778713978,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Guaxupe,2022-12-31T00:00:00,1.14,1.0916403532028198,-4.242074280454393,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Guimarania,2022-12-31T00:00:00,1.2220588235294123,1.8567960262298584,51.939987705932985,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Ibia,2022-12-31T00:00:00,1.14,1.6264004707336426,42.66670795909147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Ibiraci,2022-12-31T00:00:00,1.377007874015748,2.581559896469116,87.47604463150603,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Indianopolis,2022-12-31T00:00:00,1.8000000000000005,2.4437954425811768,35.766413476732026,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Itamogi,2022-12-31T00:00:00,1.32,1.805880308151245,36.8091142538822,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Itanhomi,2022-12-31T00:00:00,1.081818181818182,1.1796709299087524,9.045212008372056,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Jacui,2022-12-31T00:00:00,1.08,1.425468683242798,31.9878410409998,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Jacutinga,2022-12-31T00:00:00,1.289920424403183,1.3828558921813965,7.204744263291484,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Juruaia,2022-12-31T00:00:00,1.5,1.5736974477767944,4.913163185119629,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Lagoa_Dourada,2022-12-31T00:00:00,1.5,1.5380308628082275,2.535390853881836,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Lagoa_Formosa,2022-12-31T00:00:00,2.088607594936709,2.291145086288452,9.69724958593195,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Lagoa_Grande,2022-12-31T00:00:00,2.4,1.4567022323608398,-39.30407365163167,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Matutina,2022-12-31T00:00:00,1.8097165991902835,1.7030131816864014,-5.896139624934862,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Monte_Belo,2022-12-31T00:00:00,0.96,1.418539047241211,47.764484087626165,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Monte_Carmelo,2022-12-31T00:00:00,1.7458874458874465,2.322014570236206,32.99909886550049,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Monte_Santo_de_Minas,2022-12-31T00:00:00,1.4699677072120565,1.5643556118011477,6.421086948100887,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Muzambinho,2022-12-31T00:00:00,1.43993993993994,1.1883115768432615,-17.47492073226149,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Nova_Resende,2022-12-31T00:00:00,1.5,1.678809404373169,11.920626958211262,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Passos,2022-12-31T00:00:00,1.290038314176245,1.703622817993164,32.05986204223816,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Patis,2022-12-31T00:00:00,2.044444444444444,2.289736032485962,11.997958110726431,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Patos_de_Minas,2022-12-31T00:00:00,1.91614730878187,1.852648377418518,-3.313885684692962,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Patrocinio,2022-12-31T00:00:00,0.9438953724513282,2.1938610076904297,132.42629127345953,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Pedrinopolis,2022-12-31T00:00:00,2.02051282051282,2.191006183624268,8.438123301201088,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Perdizes,2022-12-31T00:00:00,1.501272727272727,2.1772894859313965,45.02957699676253,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Piracema,2022-12-31T00:00:00,1.0,1.1607284545898438,16.072845458984375,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Ponto_dos_Volantes,2022-12-31T00:00:00,0.6000000000000001,0.6105940341949463,1.7656723658243665,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Pratapolis,2022-12-31T00:00:00,1.2,1.7272063493728638,43.933862447738655,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Pratinha,2022-12-31T00:00:00,1.720111731843575,1.798987865447998,4.585523843842717,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Presidente_Kubitschek,2022-12-31T00:00:00,0.896551724137931,0.7134430408477783,-20.42366082851704,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Presidente_Olegario,2022-12-31T00:00:00,1.8899598393574304,2.227457523345948,17.85739976904818,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Quartel_Geral,2022-12-31T00:00:00,3.0,3.061163902282715,2.038796742757161,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Rio_Paranaiba,2022-12-31T00:00:00,1.230031446540881,1.71150541305542,39.14322417272742,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Rio_Vermelho,2022-12-31T00:00:00,0.9090909090909092,0.8802261352539062,-3.1751251220703094,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Romaria,2022-12-31T00:00:00,1.910526315789474,2.445417881011963,27.997079171425028,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sacramento,2022-12-31T00:00:00,1.5575892857142857,1.8531343936920168,18.974521119808465,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Santa_Rosa_da_Serra,2022-12-31T00:00:00,2.22,1.6027063131332395,-27.80602193093513,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Santo_Antonio_do_Amparo,2022-12-31T00:00:00,1.26,1.6232106685638428,28.82624353681292,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sao_Goncalo_do_Abaete,2022-12-31T00:00:00,1.5,1.8974539041519165,26.4969269434611,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sao_Gotardo,2022-12-31T00:00:00,1.50025974025974,1.5374404191970823,2.4782827892792394,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sao_Joao_Batista_do_Gloria,2022-12-31T00:00:00,1.232209737827715,1.4961252212524414,21.41806506820728,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sao_Pedro_da_Uniao,2022-12-31T00:00:00,1.4700000000000002,1.647864580154419,12.099631303021685,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sao_Sebastiao_do_Paraiso,2022-12-31T00:00:00,1.3172147001934242,1.5955686569213867,21.13201110548554,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Serra_do_Salitre,2022-12-31T00:00:00,1.5168750000000002,2.4603195190429688,62.19658963612482,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Tapira,2022-12-31T00:00:00,1.8000000000000005,2.094580173492432,16.36556519402396,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Tiros,2022-12-31T00:00:00,1.6801801801801797,1.4742876291275024,-12.254194727532,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Tupaciguara,2022-12-31T00:00:00,2.4,2.3030266761779785,-4.040555159250891,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Uberaba,2022-12-31T00:00:00,2.102941176470588,2.5375006198883057,20.66436514154183,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Uberlandia,2022-12-31T00:00:00,1.681818181818182,2.495191097259521,48.36271389110668,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Unai,2022-12-31T00:00:00,2.52010582010582,2.80326771736145,11.23611139645477,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Varginha,2022-12-31T00:00:00,1.020039292730845,1.4061331748962402,37.8508832862454,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Varjao_de_Minas,2022-12-31T00:00:00,2.383928571428572,2.439461231231689,2.3294598868723395,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Virginopolis,2022-12-31T00:00:00,1.314606741573034,1.348399043083191,2.5705254994905657,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Almenara,2023-12-31T00:00:00,0.78,0.906208872795105,16.180624717321148,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Alpinopolis,2023-12-31T00:00:00,1.8000000000000005,2.361475944519043,31.193108028835702,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Alterosa,2023-12-31T00:00:00,1.2603960396039595,1.996961116790772,58.43917737303066,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Andradas,2023-12-31T00:00:00,1.22,1.3439425230026243,10.159223196936438,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Araguari,2023-12-31T00:00:00,3.0,2.467189073562622,-17.760364214579262,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Arapua,2023-12-31T00:00:00,0.9,1.5717735290527344,74.64150322808159,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Araxa,2023-12-31T00:00:00,1.638401296246287,1.7942821979522705,9.514207664698478,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Arceburgo,2023-12-31T00:00:00,1.8482558139534884,1.6800309419631958,-9.101817547131274,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Areado,2023-12-31T00:00:00,1.590034364261168,2.007795810699463,26.273736959918697,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Bom_Jesus_da_Penha,2023-12-31T00:00:00,1.2,2.0559301376342773,71.32751146952312,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Botelhos,2023-12-31T00:00:00,1.080052666227781,1.012446641921997,-6.259511820095439,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Botumirim,2023-12-31T00:00:00,0.59375,0.6624594330787659,11.572115044844775,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Cabo_Verde,2023-12-31T00:00:00,1.319976635514019,1.657073974609375,25.538129238483464,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Campestre,2023-12-31T00:00:00,1.319964428634949,1.3418549299240112,1.658416000778176,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Capetinga,2023-12-31T00:00:00,1.4484046164290565,2.444963216781616,68.80388180545212,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Carmo_do_Paranaiba,2023-12-31T00:00:00,2.369801007771799,1.9314922094345093,-18.495595068946688,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Cascalho_Rico,2023-12-31T00:00:00,2.4,2.40999698638916,0.4165410995483435,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Claraval,2023-12-31T00:00:00,1.8600214362272245,2.4419169425964355,31.28434409602824,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Conceicao_da_Aparecida,2023-12-31T00:00:00,1.679948420373952,2.1350765228271484,27.091790255791665,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Coromandel,2023-12-31T00:00:00,2.0926575541308825,2.08335280418396,-0.4446379642266395,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Corrego_Fundo,2023-12-31T00:00:00,1.320158102766798,2.21067214012146,67.45510522476934,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Cruzeiro_da_Fortaleza,2023-12-31T00:00:00,1.5,2.125016689300537,41.66777928670247,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Delfinopolis,2023-12-31T00:00:00,1.501818181818182,1.7644693851470947,17.488881577591044,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Divisa_Nova,2023-12-31T00:00:00,1.680092592592593,1.7550615072250366,4.462189462829385,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Dom_Cavati,2023-12-31T00:00:00,0.6000000000000001,0.7549187541007996,25.81979235013324,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Dores_do_Turvo,2023-12-31T00:00:00,1.5,0.9205362796783448,-38.63091468811035,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Estrela_do_Indaia,2023-12-31T00:00:00,1.8000000000000005,1.6361490488052368,-9.102830621931302,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Estrela_do_Sul,2023-12-31T00:00:00,2.43015873015873,1.6908527612686155,-30.422126740742783,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Guaranesia,2023-12-31T00:00:00,1.1961439588688951,1.452085256576538,21.39719854035527,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Guarani,2023-12-31T00:00:00,0.9655172413793104,0.642638087272644,-33.44105524676187,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Guarda-Mor,2023-12-31T00:00:00,1.7994350282485878,2.1190402507781982,17.761420529902992,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Guaxupe,2023-12-31T00:00:00,1.2,1.390803337097168,15.90027809143067,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Guimarania,2023-12-31T00:00:00,1.7704600484261497,1.8353368043899536,3.6644010138198895,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Ibia,2023-12-31T00:00:00,1.668,1.6878001689910889,1.1870604910724785,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Ibiraci,2023-12-31T00:00:00,1.804169884169884,2.479879379272461,37.45265349074805,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Indianopolis,2023-12-31T00:00:00,2.7000000000000006,2.1712324619293213,-19.58398289150664,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Itamogi,2023-12-31T00:00:00,1.740011254924029,2.1458840370178223,23.32587107958185,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Itanhomi,2023-12-31T00:00:00,1.078787878787879,1.024864912033081,-4.9984772553604895,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Jacui,2023-12-31T00:00:00,1.32,1.772716760635376,34.29672429055878,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Jacutinga,2023-12-31T00:00:00,1.160053262316911,1.3563239574432373,16.919110656550846,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Juruaia,2023-12-31T00:00:00,1.5,1.7211925983428955,14.7461732228597,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Lagoa_Dourada,2023-12-31T00:00:00,1.8000000000000005,1.5279111862182615,-15.116045210096583,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Lagoa_Formosa,2023-12-31T00:00:00,1.978723404255319,2.2574732303619385,14.08735680323776,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Lagoa_Grande,2023-12-31T00:00:00,2.4,1.3977314233779907,-41.76119069258372,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Matutina,2023-12-31T00:00:00,1.502024291497976,1.829001426696777,21.76909768035146,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Monte_Belo,2023-12-31T00:00:00,1.3799999999999997,1.7079402208328247,23.76378411832066,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Monte_Carmelo,2023-12-31T00:00:00,2.4900284900284904,2.1231822967529297,-14.732610279144367,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Monte_Santo_de_Minas,2023-12-31T00:00:00,1.620050377833753,1.894329309463501,16.930271760838668,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Muzambinho,2023-12-31T00:00:00,1.68,1.5978480577468872,-4.8899965626852815,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Nova_Resende,2023-12-31T00:00:00,1.56,1.994015455245972,27.82150354140844,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Passos,2023-12-31T00:00:00,1.829801324503311,1.6472666263580322,-9.975656684740157,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Patis,2023-12-31T00:00:00,1.2,1.847825646400452,53.985470533370986,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Patos_de_Minas,2023-12-31T00:00:00,1.782452316076294,1.8653031587600708,4.648137957830823,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Patrocinio,2023-12-31T00:00:00,2.4370275910039414,1.7744026184082031,-27.18988389962248,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Pedrinopolis,2023-12-31T00:00:00,2.187804878048781,2.2063608169555664,0.848153283364748,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Perdizes,2023-12-31T00:00:00,2.106451612903226,2.1180667877197266,0.5514095242136655,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Piracema,2023-12-31T00:00:00,1.2,1.13106107711792,-5.744910240173336,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Ponto_dos_Volantes,2023-12-31T00:00:00,0.6000000000000001,0.6237134337425232,3.952238957087183,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Pratapolis,2023-12-31T00:00:00,1.8011363636363642,2.041170597076416,13.326821793517068,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Pratinha,2023-12-31T00:00:00,2.13,1.876394271850586,-11.90637221358751,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Presidente_Kubitschek,2023-12-31T00:00:00,0.8947368421052632,1.010403394699097,12.927438231075511,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Presidente_Olegario,2023-12-31T00:00:00,2.160074626865672,2.0046072006225586,-7.197317366238454,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Quartel_Geral,2023-12-31T00:00:00,3.0,3.2158877849578857,7.196259498596191,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Rio_Paranaiba,2023-12-31T00:00:00,1.8000000000000005,1.6669600009918213,-7.391111056009943,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Rio_Vermelho,2023-12-31T00:00:00,0.9,0.9497578144073486,5.528646045260956,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Romaria,2023-12-31T00:00:00,2.131578947368421,2.312541961669922,8.489622893156842,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sacramento,2023-12-31T00:00:00,1.75,1.7588834762573242,0.5076272147042411,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Santa_Rosa_da_Serra,2023-12-31T00:00:00,1.68,1.86435341835022,10.973417758941654,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Santo_Antonio_do_Amparo,2023-12-31T00:00:00,1.8000000000000005,1.784807205200195,-0.8440441555447196,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sao_Goncalo_do_Abaete,2023-12-31T00:00:00,1.619047619047619,1.7490335702896118,8.028544047299551,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sao_Gotardo,2023-12-31T00:00:00,1.5,1.564592361450195,4.306157430013021,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sao_Joao_Batista_do_Gloria,2023-12-31T00:00:00,1.5232974910394272,1.6818912029266355,10.411210733301449,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sao_Pedro_da_Uniao,2023-12-31T00:00:00,1.5,1.843830227851868,22.92201519012451,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Sao_Sebastiao_do_Paraiso,2023-12-31T00:00:00,1.440017746228926,1.903550148010254,32.18935342951241,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Serra_do_Salitre,2023-12-31T00:00:00,1.489636363636364,1.9427201747894287,30.41573247091242,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Tapira,2023-12-31T00:00:00,1.92,2.146697998046875,11.807187398274744,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Tiros,2023-12-31T00:00:00,2.382038834951457,1.7172536849975586,-27.90824146943204,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Tupaciguara,2023-12-31T00:00:00,2.622222222222222,2.365929365158081,-9.773880142276557,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Uberaba,2023-12-31T00:00:00,2.1200980392156863,2.5226311683654785,18.986533721747424,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Uberlandia,2023-12-31T00:00:00,1.8000000000000005,2.4648995399475098,36.93886333041719,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Unai,2023-12-31T00:00:00,2.520095187731359,2.7239761352539062,8.090208199876972,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Varginha,2023-12-31T00:00:00,1.679990280646337,1.682317852973938,0.1385467734197592,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Varjao_de_Minas,2023-12-31T00:00:00,2.3892857142857142,2.4218270778656006,1.3619703740460656,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_1_2023,Virginopolis,2023-12-31T00:00:00,1.3258426966292132,1.393238186836243,5.083219176631888,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:01:36
V43_cluster_2_2023,Abre_Campo,2022-12-31T00:00:00,1.2,1.3134199380874634,9.45166150728862,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Aimores,2022-12-31T00:00:00,2.332558139534884,1.5835232734680176,-32.112162752617394,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Alvarenga,2022-12-31T00:00:00,0.9,0.7378742694854736,-18.013970057169598,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Andrelandia,2022-12-31T00:00:00,1.8000000000000005,1.8193151950836184,1.0730663935343274,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Antonio_Dias,2022-12-31T00:00:00,1.5,1.1805330514907837,-21.29779656728109,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Antonio_Prado_de_Minas,2022-12-31T00:00:00,1.2,1.5280156135559082,27.33463446299236,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Bocaiuva,2022-12-31T00:00:00,3.6000000000000005,1.782172918319702,-50.49519671334161,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Bom_Jesus_do_Amparo,2022-12-31T00:00:00,1.8000000000000005,1.4347765445709229,-20.29019196828208,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Campo_Belo,2022-12-31T00:00:00,1.2,2.0419514179229736,70.16261816024782,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Capela_Nova,2022-12-31T00:00:00,2.1016393442622947,2.20091199874878,4.723581843740687,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Capitao_Eneas,2022-12-31T00:00:00,2.6000000000000005,2.56743597984314,-1.2524623137254185,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Casa_Grande,2022-12-31T00:00:00,2.107692307692308,2.2445008754730225,6.490917449449945,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Cataguases,2022-12-31T00:00:00,1.5,3.089200258255005,105.946683883667,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Caxambu,2022-12-31T00:00:00,1.4387755102040822,2.4115469455718994,67.61106430216032,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Coimbra,2022-12-31T00:00:00,1.799054373522459,1.797670841217041,-0.076903306858313,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Conselheiro_Pena,2022-12-31T00:00:00,1.8000000000000005,1.3732844591140747,-23.70641893810697,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Corrego_Novo,2022-12-31T00:00:00,1.377777777777778,1.3237766027450562,-3.9194401233427136,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Cruzilia,2022-12-31T00:00:00,1.5027322404371577,1.951294183731079,29.84975840828642,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Divisopolis,2022-12-31T00:00:00,1.259523809523809,1.10673725605011,-12.130501410010147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Esmeraldas,2022-12-31T00:00:00,2.111111111111112,1.954519391059876,-7.417502528742761,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Espirito_Santo_do_Dourado,2022-12-31T00:00:00,1.319148936170213,1.4804062843322754,12.224347360672496,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Eugenopolis,2022-12-31T00:00:00,1.8000000000000005,2.126360893249512,18.131160736083967,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Felicio_dos_Santos,2022-12-31T00:00:00,3.306397306397306,3.0223605632781982,-8.590520642197044,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Formiga,2022-12-31T00:00:00,1.8000000000000005,1.925395965576172,6.966442532009533,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Guaraciaba,2022-12-31T00:00:00,1.8000000000000005,2.8211708068847656,56.73171149359807,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Guiricema,2022-12-31T00:00:00,2.4,2.486724138259888,3.613505760828658,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Iapu,2022-12-31T00:00:00,1.5614035087719298,1.3677971363067627,-12.39950924776913,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Ijaci,2022-12-31T00:00:00,1.173913043478261,1.899214625358581,61.784949567582856,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Imbe_de_Minas,2022-12-31T00:00:00,1.3799999999999997,1.1892471313476562,-13.822671641474162,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Inhapim,2022-12-31T00:00:00,1.8000000000000005,1.4747748374938965,-18.06806458367243,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Irai_de_Minas,2022-12-31T00:00:00,2.386666666666667,4.123744010925293,72.78257029016586,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Itamarati_de_Minas,2022-12-31T00:00:00,1.261538461538461,1.420406937599182,12.593232858471795,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Jequeri,2022-12-31T00:00:00,1.8000000000000005,1.6053853034973145,-10.811927583482545,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Lamim,2022-12-31T00:00:00,2.4,2.338550090789795,-2.5604128837585414,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Mar_de_Espanha,2022-12-31T00:00:00,2.1,1.9668174982070925,-6.342023894900371,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Mata_Verde,2022-12-31T00:00:00,1.6792452830188678,1.196159839630127,-28.76800955011603,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Monte_Alegre_de_Minas,2022-12-31T00:00:00,2.3296703296703294,3.635853290557861,56.06728747205916,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Nova_Era,2022-12-31T00:00:00,1.5,1.4957886934280396,-0.2807537714640299,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Nova_Ponte,2022-12-31T00:00:00,2.710714285714286,2.9680395126342773,9.492893746719052,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Paula_Candido,2022-12-31T00:00:00,1.6198529411764713,1.5696288347244265,-3.100534942114443,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Pecanha,2022-12-31T00:00:00,2.287671232876712,1.5193110704421997,-33.58700111240683,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Pedra_Bonita,2022-12-31T00:00:00,1.8000000000000005,1.4247663021087646,-20.846316549513087,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Pedra_Dourada,2022-12-31T00:00:00,1.2,1.2472773790359497,3.939781586329146,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Pedra_do_Anta,2022-12-31T00:00:00,1.438297872340426,1.3399248123168943,-6.839547072641983,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Piedade_de_Caratinga,2022-12-31T00:00:00,1.56,1.4477014541625977,-7.198624733166819,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Pocrane,2022-12-31T00:00:00,1.440944881889764,1.2357313632965088,-14.241593913302404,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Presidente_Bernardes,2022-12-31T00:00:00,1.501449275362319,1.8633019924163816,24.10022922464318,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sabinopolis,2022-12-31T00:00:00,1.32,1.0849595069885254,-17.806097955414746,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Santa_Barbara,2022-12-31T00:00:00,1.083333333333333,1.065513014793396,-1.6449524806095734,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Santo_Antonio_do_Grama,2022-12-31T00:00:00,1.565217391304348,1.9008194208145144,21.441240774260624,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Domingos_do_Prata,2022-12-31T00:00:00,1.078125,0.9049542546272278,-16.06221406356148,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Geraldo,2022-12-31T00:00:00,1.561038961038961,1.9113943576812744,22.44373173166234,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Jose_da_Barra,2022-12-31T00:00:00,2.3076923076923066,2.497297525405884,8.216226100921682,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Jose_do_Alegre,2022-12-31T00:00:00,1.682352941176471,2.1335065364837646,26.81682209868528,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Miguel_do_Anta,2022-12-31T00:00:00,1.5,1.4057550430297852,-6.282997131347656,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Sebastiao_da_Vargem_Alegre,2022-12-31T00:00:00,1.020238095238095,1.5767080783843994,54.54314887315005,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Sebastiao_do_Anta,2022-12-31T00:00:00,1.8000000000000005,1.5521810054779053,-13.767721917894162,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Senhora_dos_Remedios,2022-12-31T00:00:00,1.466666666666667,2.04367733001709,39.341636137528816,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Teixeiras,2022-12-31T00:00:00,1.5,1.641018629074097,9.401241938273111,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Visconde_do_Rio_Branco,2022-12-31T00:00:00,1.6666666666666672,1.7191393375396729,3.148360252380339,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Abre_Campo,2023-12-31T00:00:00,1.8000000000000005,1.4982523918151855,-16.763756010267482,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Aimores,2023-12-31T00:00:00,1.544827586206897,2.1064658164978027,36.3560461572238,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Alvarenga,2023-12-31T00:00:00,1.75,0.9329990148544312,-46.6857705797468,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Andrelandia,2023-12-31T00:00:00,1.8000000000000005,2.1137166023254395,17.428700129191064,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Antonio_Dias,2023-12-31T00:00:00,1.477272727272727,1.847738981246948,25.0777156536396,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Antonio_Prado_de_Minas,2023-12-31T00:00:00,1.4857142857142862,1.5737287998199463,5.924053834034812,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Bocaiuva,2023-12-31T00:00:00,3.0,3.4171371459960938,13.904571533203123,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Bom_Jesus_do_Amparo,2023-12-31T00:00:00,1.25,1.5992462635040283,27.939701080322266,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Campo_Belo,2023-12-31T00:00:00,1.5,1.7657749652862549,17.718331019083656,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Capela_Nova,2023-12-31T00:00:00,1.8000000000000005,2.2076854705810547,22.649192810058576,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Capitao_Eneas,2023-12-31T00:00:00,3.0,3.815783739089966,27.19279130299886,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Casa_Grande,2023-12-31T00:00:00,2.523076923076923,2.671190023422241,5.870336294174198,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Cataguases,2023-12-31T00:00:00,1.333333333333333,3.1471643447875977,136.03732585906988,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Caxambu,2023-12-31T00:00:00,1.316326530612245,1.906376957893372,44.82553633608559,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Coimbra,2023-12-31T00:00:00,1.8000000000000005,2.060003757476806,14.444653193155906,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Conselheiro_Pena,2023-12-31T00:00:00,1.320048602673147,1.5902807712554932,20.47138022305512,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Corrego_Novo,2023-12-31T00:00:00,1.8000000000000005,2.565057277679444,42.50318209330239,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Cruzilia,2023-12-31T00:00:00,1.5,1.8596445322036743,23.97630214691162,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Divisopolis,2023-12-31T00:00:00,1.616883116883117,1.335966944694519,-17.37393193455586,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Esmeraldas,2023-12-31T00:00:00,2.222222222222222,2.327150821685791,4.721786975860612,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Espirito_Santo_do_Dourado,2023-12-31T00:00:00,1.5,1.571238994598389,4.749266306559244,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Eugenopolis,2023-12-31T00:00:00,1.68,2.138967990875244,27.319523266383584,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Felicio_dos_Santos,2023-12-31T00:00:00,3.542087542087541,6.1658854484558105,74.07490286990267,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Formiga,2023-12-31T00:00:00,2.021543985637344,2.374451875686645,17.457344117003647,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Guaraciaba,2023-12-31T00:00:00,1.5,3.15425181388855,110.28345425923663,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Guiricema,2023-12-31T00:00:00,1.5,2.958502054214477,97.23347028096518,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Iapu,2023-12-31T00:00:00,1.559210526315789,1.7123823165893557,9.82367600066756,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Ijaci,2023-12-31T00:00:00,1.971428571428572,1.617438554763794,-17.956015338068447,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Imbe_de_Minas,2023-12-31T00:00:00,1.3799999999999997,1.471363544464111,6.620546700297949,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Inhapim,2023-12-31T00:00:00,2.7000000000000006,1.819582462310791,-32.608056951452205,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Irai_de_Minas,2023-12-31T00:00:00,2.18825561312608,2.941941499710083,34.44231478548837,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Itamarati_de_Minas,2023-12-31T00:00:00,1.2,1.510317087173462,25.85975726445516,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Jequeri,2023-12-31T00:00:00,1.5,2.11882758140564,41.255172093709305,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Lamim,2023-12-31T00:00:00,1.8000000000000005,3.4651341438293457,92.50745243496362,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Mar_de_Espanha,2023-12-31T00:00:00,1.5625,2.805814743041992,79.5721435546875,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Mata_Verde,2023-12-31T00:00:00,1.739700374531835,1.8399800062179563,5.764189808437994,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Monte_Alegre_de_Minas,2023-12-31T00:00:00,2.338983050847458,3.732177972793579,59.56413072088488,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Nova_Era,2023-12-31T00:00:00,2.636363636363636,1.582672357559204,-39.967600230512936,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Nova_Ponte,2023-12-31T00:00:00,2.6142857142857143,2.3663575649261475,-9.483590412661028,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Paula_Candido,2023-12-31T00:00:00,1.6197080291970802,1.7541308403015137,8.299200144798279,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Pecanha,2023-12-31T00:00:00,2.30379746835443,2.55309534072876,10.82117138328136,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Pedra_Bonita,2023-12-31T00:00:00,1.08,1.865316152572632,72.71445857153998,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Pedra_Dourada,2023-12-31T00:00:00,1.2,1.630709886550903,35.892490545908615,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Pedra_do_Anta,2023-12-31T00:00:00,1.5,1.6171318292617798,7.808788617451985,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Piedade_de_Caratinga,2023-12-31T00:00:00,2.4,1.7386382818222046,-27.556738257408146,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Pocrane,2023-12-31T00:00:00,1.377952755905512,1.409956455230713,2.322554179600291,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Presidente_Bernardes,2023-12-31T00:00:00,1.320588235294118,1.7806675434112549,34.8389676525226,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sabinopolis,2023-12-31T00:00:00,1.2,1.3983434438705444,16.528620322545372,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Santa_Barbara,2023-12-31T00:00:00,1.3,1.1890640258789062,-8.533536470853369,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Santo_Antonio_do_Grama,2023-12-31T00:00:00,1.521739130434783,2.9598703384399414,94.5057650974818,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Domingos_do_Prata,2023-12-31T00:00:00,1.2,1.173596739768982,-2.200271685918169,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Geraldo,2023-12-31T00:00:00,1.5,2.3687939643859863,57.91959762573242,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Jose_da_Barra,2023-12-31T00:00:00,2.2413698630136984,2.5493760108947754,13.741870673095354,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Jose_do_Alegre,2023-12-31T00:00:00,1.592307692307692,2.1917495727539062,37.64610843382023,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Miguel_do_Anta,2023-12-31T00:00:00,1.5598870056497178,1.5702767372131348,0.6660566775533493,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Sebastiao_da_Vargem_Alegre,2023-12-31T00:00:00,1.5,1.9636054039001465,30.90702692667644,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Sao_Sebastiao_do_Anta,2023-12-31T00:00:00,1.7998212689901698,1.8269248008728027,1.505901299735166,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Senhora_dos_Remedios,2023-12-31T00:00:00,1.5,2.047669649124145,36.511309941609696,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Teixeiras,2023-12-31T00:00:00,1.5007092198581562,1.7765402793884275,18.380046972480287,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_2_2023,Visconde_do_Rio_Branco,2023-12-31T00:00:00,1.333333333333333,2.310014486312866,73.251086473465,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:10
V43_cluster_3_2023,Aiuruoca,2022-12-31T00:00:00,1.5,1.371873140335083,-8.5417906443278,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Albertina,2022-12-31T00:00:00,1.44,1.5108537673950195,4.920400513543027,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Baependi,2022-12-31T00:00:00,1.079558011049724,1.3709640502929688,26.99308756552061,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Bandeira_do_Sul,2022-12-31T00:00:00,1.110344827586207,1.6122030019760132,45.19840701026206,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Borda_da_Mata,2022-12-31T00:00:00,1.2,1.5565980672836304,29.7165056069692,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Brazopolis,2022-12-31T00:00:00,1.200934579439252,1.1584724187850952,-3.5357596809297944,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Bueno_Brandao,2022-12-31T00:00:00,1.440196078431373,1.5274417400360107,6.057901622650135,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Cachoeira_de_Minas,2022-12-31T00:00:00,1.5,1.7333836555480957,15.558910369873049,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Caldas,2022-12-31T00:00:00,1.2,1.468317985534668,22.359832127889,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Cambuquira,2022-12-31T00:00:00,1.32,1.5284459590911863,15.791360537211094,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Campanha,2022-12-31T00:00:00,1.266469038208169,1.5111289024353027,19.31826652258981,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Careacu,2022-12-31T00:00:00,1.2,1.325353741645813,10.446145137151088,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Carmo_da_Cachoeira,2022-12-31T00:00:00,1.2,1.580737829208374,31.728152434031177,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Carmo_de_Minas,2022-12-31T00:00:00,1.14,1.4285657405853271,25.312784261870814,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Carrancas,2022-12-31T00:00:00,1.6785714285714293,1.4589407444000244,-13.084381184679431,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Carvalhopolis,2022-12-31T00:00:00,1.44,1.4504975080490112,0.7289936145146725,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Conceicao_das_Pedras,2022-12-31T00:00:00,1.375,1.520805835723877,10.604060779918324,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Conceicao_do_Rio_Verde,2022-12-31T00:00:00,1.5,1.6829791069030762,12.198607126871746,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Conceicao_dos_Ouros,2022-12-31T00:00:00,1.261168384879725,1.431952953338623,13.54177368434314,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Congonhal,2022-12-31T00:00:00,1.080597014925373,1.6233060359954834,50.223072391847246,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Cordislandia,2022-12-31T00:00:00,1.260122699386503,1.5596415996551514,23.769026652283205,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Cristina,2022-12-31T00:00:00,1.320183486238532,1.559688925743103,18.14182967755264,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Datas,2022-12-31T00:00:00,0.75,1.486151933670044,98.15359115600586,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Dom_Vicoso,2022-12-31T00:00:00,1.320588235294118,1.3051906824111938,-1.1659616882392496,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Fama,2022-12-31T00:00:00,1.379787234042553,1.5052566528320312,9.093388871403976,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Fortaleza_de_Minas,2022-12-31T00:00:00,1.5,1.311408758163452,-12.572749455769856,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Heliodora,2022-12-31T00:00:00,1.080140597539543,1.4981515407562256,38.69967892780546,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Ibitiura_de_Minas,2022-12-31T00:00:00,1.3799999999999997,1.5769667625427246,14.27295380744384,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Inconfidentes,2022-12-31T00:00:00,1.739917695473251,1.7946250438690186,3.1442492100689536,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Ingai,2022-12-31T00:00:00,1.380228136882129,1.5583776235580444,12.907249310128313,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Itajuba,2022-12-31T00:00:00,1.068965517241379,1.6486870050430298,54.23201014918671,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Itutinga,2022-12-31T00:00:00,1.8000000000000005,1.4392049312591553,-20.044170485602496,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Jesuania,2022-12-31T00:00:00,1.2,1.4309505224227903,19.24587686856588,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Lambari,2022-12-31T00:00:00,1.2,1.4211297035217283,18.42747529347738,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Luminarias,2022-12-31T00:00:00,1.380229885057471,1.7002136707305908,23.18336888204649,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Maria_da_Fe,2022-12-31T00:00:00,1.2,1.5490810871124268,29.090090592702232,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Monsenhor_Paulo,2022-12-31T00:00:00,1.23,1.590286135673523,29.291555745814872,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Monte_Siao,2022-12-31T00:00:00,1.2,1.505465388298035,25.45544902483623,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Natercia,2022-12-31T00:00:00,1.4399193548387097,1.4965335130691528,3.931758958597003,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Olimpio_Noronha,2022-12-31T00:00:00,1.2,1.352325201034546,12.69376675287883,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Ouro_Fino,2022-12-31T00:00:00,1.2,1.4683043956756592,22.358699639638267,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Paraisopolis,2022-12-31T00:00:00,1.322222222222222,1.503871202468872,13.738158169914716,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Pedralva,2022-12-31T00:00:00,1.320091324200913,1.5965054035186768,20.93901188882404,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Pirangucu,2022-12-31T00:00:00,1.333333333333333,1.2332932949066162,-7.503002882003764,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Piranguinho,2022-12-31T00:00:00,1.380549682875264,1.4403451681137085,4.331280936873552,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Poco_Fundo,2022-12-31T00:00:00,1.079978925184405,1.2713735103607178,17.72206667307257,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Pocos_de_Caldas,2022-12-31T00:00:00,1.169867549668874,1.501051664352417,28.3095393813841,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Pouso_Alegre,2022-12-31T00:00:00,1.5,1.409465789794922,-6.035614013671875,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Pouso_Alto,2022-12-31T00:00:00,1.5,1.4887235164642334,-0.7517655690511067,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Santa_Rita_de_Caldas,2022-12-31T00:00:00,1.8000000000000005,1.840538024902344,2.2521124945746376,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Santa_Rita_do_Sapucai,2022-12-31T00:00:00,1.14,1.6063389778137207,40.906927878396566,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Bento_Abade,2022-12-31T00:00:00,1.2,1.6319456100463867,35.99546750386556,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Goncalo_do_Sapucai,2022-12-31T00:00:00,1.08,1.6975140571594238,57.177227514761455,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Joao_da_Mata,2022-12-31T00:00:00,0.959748427672956,1.2721266746520996,32.54793005877053,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Joao_del_Rei,2022-12-31T00:00:00,1.836244541484716,1.5835896730422974,-13.759325772488436,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Lourenco,2022-12-31T00:00:00,1.8000000000000005,1.4633731842041016,-18.70148976643881,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Sebastiao_da_Bela_Vista,2022-12-31T00:00:00,1.5,1.381449818611145,-7.903345425923665,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Tome_das_Letras,2022-12-31T00:00:00,1.434375,1.331135392189026,-7.1975325706997175,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Senador_Jose_Bento,2022-12-31T00:00:00,1.32,1.291950225830078,-2.124982891660753,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Serrania,2022-12-31T00:00:00,1.2,1.49474835395813,24.56236282984416,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Silvianopolis,2022-12-31T00:00:00,0.9,1.1797016859054563,31.07796510060628,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Soledade_de_Minas,2022-12-31T00:00:00,1.5,1.6206889152526855,8.045927683512371,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Tocos_do_Moji,2022-12-31T00:00:00,1.5,1.343982458114624,-10.401169459025066,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Tres_Coracoes,2022-12-31T00:00:00,1.08,1.7369444370269775,60.82818861360902,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Turvolandia,2022-12-31T00:00:00,1.4398692810457523,1.636911153793335,13.684705642478502,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Virginia,2022-12-31T00:00:00,1.62,1.4401512145996094,-11.101776876567328,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Aiuruoca,2023-12-31T00:00:00,1.6000000000000003,1.5606718063354492,-2.458012104034443,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Albertina,2023-12-31T00:00:00,1.5,1.581799030303955,5.453268686930338,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Baependi,2023-12-31T00:00:00,1.439779005524862,1.3883016109466553,-3.575367773850892,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Bandeira_do_Sul,2023-12-31T00:00:00,1.5,1.525317907333374,1.6878604888916016,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Borda_da_Mata,2023-12-31T00:00:00,1.290476190476191,1.4871511459350586,15.24049470345468,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Brazopolis,2023-12-31T00:00:00,1.440389294403893,1.1963047981262207,-16.94573107603434,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Bueno_Brandao,2023-12-31T00:00:00,1.379901960784314,1.4703088998794556,6.551692921992501,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Cachoeira_de_Minas,2023-12-31T00:00:00,1.6204081632653062,1.7975865602493286,10.934183189190296,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Caldas,2023-12-31T00:00:00,1.56,1.5081487894058228,-3.3237955509088013,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Cambuquira,2023-12-31T00:00:00,1.56,1.5661215782165527,0.3924088600354283,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Campanha,2023-12-31T00:00:00,1.327075098814229,1.5491605997085571,16.734961050265085,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Careacu,2023-12-31T00:00:00,1.5,1.2946690320968628,-13.68873119354248,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Carmo_da_Cachoeira,2023-12-31T00:00:00,1.32,1.5482285022735596,17.290038051027235,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Carmo_de_Minas,2023-12-31T00:00:00,1.5,1.4362620115280151,-4.249199231465658,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Carrancas,2023-12-31T00:00:00,1.214285714285714,1.5921621322631836,31.119234421673976,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Carvalhopolis,2023-12-31T00:00:00,1.560106382978723,1.4276773929595947,-8.488458957925712,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Conceicao_das_Pedras,2023-12-31T00:00:00,1.5598885793871868,1.5269560813903809,-2.1112083537238115,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Conceicao_do_Rio_Verde,2023-12-31T00:00:00,1.44,1.7554070949554443,21.90327048301697,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Conceicao_dos_Ouros,2023-12-31T00:00:00,1.422222222222222,1.3985700607299805,-1.6630426049232367,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Congonhal,2023-12-31T00:00:00,1.2,1.5553539991378784,29.612833261489875,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Cordislandia,2023-12-31T00:00:00,1.14,1.560110330581665,36.851783384356594,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Cristina,2023-12-31T00:00:00,1.68,1.5880115032196045,-5.475505760737824,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Datas,2023-12-31T00:00:00,0.6666666666666667,1.4119943380355835,111.7991507053375,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Dom_Vicoso,2023-12-31T00:00:00,1.32,1.3585188388824463,2.918093854730775,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Fama,2023-12-31T00:00:00,1.559677419354839,1.4729050397872925,-5.563482454175684,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Fortaleza_de_Minas,2023-12-31T00:00:00,1.5,1.445031762123108,-3.664549191792806,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Heliodora,2023-12-31T00:00:00,1.439872408293461,1.4196596145629885,-1.4037906146440455,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Ibitiura_de_Minas,2023-12-31T00:00:00,1.150344827586207,1.529332399368286,32.94556229520473,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Inconfidentes,2023-12-31T00:00:00,1.7401360544217692,1.8169306516647337,4.413137527254028,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Ingai,2023-12-31T00:00:00,1.6197718631178712,1.5599592924118042,-3.6926540130740912,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Itajuba,2023-12-31T00:00:00,1.5862068965517242,1.552261233329773,-2.140052681383883,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Itutinga,2023-12-31T00:00:00,1.5,1.4629309177398682,-2.471272150675456,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Jesuania,2023-12-31T00:00:00,1.26,1.4009957313537598,11.190137409028551,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Lambari,2023-12-31T00:00:00,1.56,1.4263362884521484,-8.568186637682796,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Luminarias,2023-12-31T00:00:00,1.260224719101124,1.6971700191497805,34.67201471498787,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Maria_da_Fe,2023-12-31T00:00:00,1.422222222222222,1.4548863172531128,2.296694181859505,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Monsenhor_Paulo,2023-12-31T00:00:00,1.389931972789116,1.5814285278320312,13.777404850875364,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Monte_Siao,2023-12-31T00:00:00,1.5,1.4823014736175537,-1.1799017588297525,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Natercia,2023-12-31T00:00:00,1.5,1.4950579404830933,-0.3294706344604492,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Olimpio_Noronha,2023-12-31T00:00:00,1.2,1.339949131011963,11.662427584330246,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Ouro_Fino,2023-12-31T00:00:00,1.68,1.4663197994232178,-12.719059558141796,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Paraisopolis,2023-12-31T00:00:00,1.2,1.5622706413269043,30.189220110575366,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Pedralva,2023-12-31T00:00:00,1.67998417721519,1.503880262374878,-10.482474610697173,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Pirangucu,2023-12-31T00:00:00,1.333333333333333,1.2427693605422974,-6.792297959327677,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Piranguinho,2023-12-31T00:00:00,1.460887949260042,1.4299111366271973,-2.1204098951281534,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Poco_Fundo,2023-12-31T00:00:00,1.380160799652325,1.2344481945037842,-10.557654237480676,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Pocos_de_Caldas,2023-12-31T00:00:00,1.5,1.461760401725769,-2.549306551615397,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Pouso_Alegre,2023-12-31T00:00:00,1.566666666666667,1.4379966259002686,-8.212981325514798,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Pouso_Alto,2023-12-31T00:00:00,1.8000000000000005,1.5458693504333496,-14.118369420369476,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Santa_Rita_de_Caldas,2023-12-31T00:00:00,1.68,1.850582838058472,10.15374036062332,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Santa_Rita_do_Sapucai,2023-12-31T00:00:00,1.3799999999999997,1.5128486156463623,9.626711278721933,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Bento_Abade,2023-12-31T00:00:00,1.5,1.6645557880401611,10.970385869344074,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Goncalo_do_Sapucai,2023-12-31T00:00:00,1.2,1.7319824695587158,44.331872463226325,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Joao_da_Mata,2023-12-31T00:00:00,1.08,1.241295576095581,14.934775564405644,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Joao_del_Rei,2023-12-31T00:00:00,1.799568965517241,1.7037395238876345,-5.325133043848811,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Lourenco,2023-12-31T00:00:00,1.5,1.9531893730163568,30.21262486775716,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Sebastiao_da_Bela_Vista,2023-12-31T00:00:00,1.5,1.404810667037964,-6.345955530802409,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Sao_Tome_das_Letras,2023-12-31T00:00:00,1.09812734082397,1.4547479152679443,32.47533880509589,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Senador_Jose_Bento,2023-12-31T00:00:00,1.2,1.30984628200531,9.153856833775842,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Serrania,2023-12-31T00:00:00,0.9,1.4087955951690674,56.53284390767415,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Silvianopolis,2023-12-31T00:00:00,1.13974358974359,1.1008379459381104,-3.4135435509869576,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Soledade_de_Minas,2023-12-31T00:00:00,1.5,1.9346152544021609,28.97435029347737,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Tocos_do_Moji,2023-12-31T00:00:00,1.5,1.4766004085540771,-1.5599727630615234,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Tres_Coracoes,2023-12-31T00:00:00,1.44,1.7155243158340454,19.133633044030933,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Turvolandia,2023-12-31T00:00:00,1.259748427672956,1.7038757801055908,35.255241655910595,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_3_2023,Virginia,2023-12-31T00:00:00,1.5,1.5212477445602417,1.4165163040161133,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:02:45
V43_cluster_4_2023,Abadia_dos_Dourados,2022-12-31T00:00:00,2.0384615384615383,1.9734591245651243,-3.188797662842942,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Acucena,2022-12-31T00:00:00,1.0,0.971447229385376,-2.8552770614624023,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Agua_Boa,2022-12-31T00:00:00,0.9136363636363636,1.136336326599121,24.37512032428192,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Aguas_Vermelhas,2022-12-31T00:00:00,3.0,3.2168984413146973,7.229948043823242,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Angelandia,2022-12-31T00:00:00,1.9799126637554585,1.498353123664856,-24.32226172932244,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Aricanduva,2022-12-31T00:00:00,1.2,1.048161506652832,-12.65320777893066,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Ataleia,2022-12-31T00:00:00,0.7142857142857143,0.9363046288490297,31.08264803886413,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Bandeira,2022-12-31T00:00:00,1.5,0.981049656867981,-34.5966895421346,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Berilo,2022-12-31T00:00:00,1.5625,0.9913174510002136,-36.55568313598633,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Berizal,2022-12-31T00:00:00,3.570967741935484,2.534869909286499,-29.01448311844492,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Bonfinopolis_de_Minas,2022-12-31T00:00:00,3.3,2.856172800064087,-13.44930908896706,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Buritis,2022-12-31T00:00:00,3.0,3.0832204818725586,2.77401606241862,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Buritizeiro,2022-12-31T00:00:00,3.0,2.652841329574585,-11.571955680847168,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Capelinha,2022-12-31T00:00:00,1.576751592356688,1.2998719215393066,-17.5601326270769,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Carai,2022-12-31T00:00:00,1.2,1.131272315979004,-5.72730700174967,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Caranaiba,2022-12-31T00:00:00,3.405405405405405,1.7152754068374634,-49.630801545249085,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Catuji,2022-12-31T00:00:00,1.3230769230769233,1.1926015615463257,-9.86150988312656,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Congonhas_do_Norte,2022-12-31T00:00:00,0.9,1.027984619140625,14.220513237847218,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Coroaci,2022-12-31T00:00:00,2.1,1.6607383489608765,-20.917221478053506,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Cuparaque,2022-12-31T00:00:00,1.02,1.1787351369857788,15.562268331939096,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Diamantina,2022-12-31T00:00:00,2.965183752417796,2.299429416656494,-22.45238040369163,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Formoso,2022-12-31T00:00:00,3.3607142857142858,2.9569833278656006,-12.0132484800884,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Franciscopolis,2022-12-31T00:00:00,1.255555555555556,1.6881332397460938,34.45308989128176,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Frei_Gaspar,2022-12-31T00:00:00,1.133333333333333,1.0484427213668823,-7.490348114686833,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Grao_Mogol,2022-12-31T00:00:00,1.177777777777778,1.333387017250061,13.212105238212704,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Indaiabira,2022-12-31T00:00:00,2.1723404255319148,2.5845870971679688,18.97707499206125,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Itabirinha,2022-12-31T00:00:00,0.8674242424242423,0.9424304962158204,8.647009170732137,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Itacambira,2022-12-31T00:00:00,0.75,1.414995193481445,88.66602579752603,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Itaipe,2022-12-31T00:00:00,0.9604651162790696,0.8779413104057312,-8.592066955335467,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Itamarandiba,2022-12-31T00:00:00,2.136,1.60080885887146,-25.055765034107687,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Itambacuri,2022-12-31T00:00:00,0.9620253164556964,1.0415221452713013,8.263486153201038,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Jequitinhonha,2022-12-31T00:00:00,2.4,1.9992269277572632,-16.698878010114033,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Joao_Pinheiro,2022-12-31T00:00:00,2.4,2.768449306488037,15.35205443700155,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Jose_Goncalves_de_Minas,2022-12-31T00:00:00,1.5,1.2262654304504397,-18.24897130330404,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Juiz_de_Fora,2022-12-31T00:00:00,1.5714285714285707,1.08453106880188,-30.98438653078944,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Ladainha,2022-12-31T00:00:00,0.6000000000000001,0.9792865514755248,63.21442524592079,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Malacacheta,2022-12-31T00:00:00,1.5595238095238098,1.6891701221466064,8.313198671996123,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Mantena,2022-12-31T00:00:00,0.75,0.6861532926559448,-8.512894312540691,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Minas_Novas,2022-12-31T00:00:00,1.7848101265822778,1.1349962949752808,-36.40800900493105,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Monte_Formoso,2022-12-31T00:00:00,0.6000000000000001,0.8979924321174622,49.665405352910334,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Ninheira,2022-12-31T00:00:00,2.9401197604790417,2.735528945922852,-6.958587786330702,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Nova_Belem,2022-12-31T00:00:00,0.96,1.0738390684127808,11.858236292998011,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Novo_Cruzeiro,2022-12-31T00:00:00,1.180722891566265,1.129772067070007,-4.315222891009586,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Novorizonte,2022-12-31T00:00:00,1.461538461538461,1.2480864524841309,-14.604611145822592,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Ouro_Verde_de_Minas,2022-12-31T00:00:00,2.0,1.4954819679260254,-25.22590160369872,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Padre_Paraiso,2022-12-31T00:00:00,0.6000000000000001,0.6476125717163086,7.935428619384749,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Paracatu,2022-12-31T00:00:00,2.4,2.591517925262451,7.979913552602136,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Pedra_Azul,2022-12-31T00:00:00,1.5333333333333332,1.1900887489318848,-22.38551637400751,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Pirapora,2022-12-31T00:00:00,3.3595505617977524,2.962404727935791,-11.82139773033932,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Pote,2022-12-31T00:00:00,1.2,0.7203888893127441,-39.96759255727132,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Rio_Pardo_de_Minas,2022-12-31T00:00:00,2.515254237288135,2.919856309890747,16.085931457920562,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Santa_Barbara_do_Monte_Verde,2022-12-31T00:00:00,1.3,1.490126132965088,14.625087151160605,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Santa_Maria_do_Suacui,2022-12-31T00:00:00,1.0,0.8051002025604248,-19.48997974395752,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Santo_Antonio_do_Retiro,2022-12-31T00:00:00,1.2,1.279287815093994,6.607317924499516,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Sao_Goncalo_do_Rio_Preto,2022-12-31T00:00:00,3.0,3.0504608154296875,1.6820271809895833,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Sao_Joao_do_Manteninha,2022-12-31T00:00:00,1.2,0.7799816131591797,-35.001532236735024,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Sao_Joao_do_Paraiso,2022-12-31T00:00:00,3.09016393442623,2.390723943710327,-22.634397577543805,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Sao_Sebastiao_do_Maranhao,2022-12-31T00:00:00,1.141666666666667,0.9137150645256042,-19.96656369118798,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Senador_Modestino_Goncalves,2022-12-31T00:00:00,2.7000000000000006,2.429800033569336,-10.00740616409869,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Setubinha,2022-12-31T00:00:00,1.079761904761905,1.0319972038269043,-4.423632721653862,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Taiobeiras,2022-12-31T00:00:00,3.14031971580817,2.7503135204315186,-12.41931493196011,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Teofilo_Otoni,2022-12-31T00:00:00,0.8181818181818183,0.9037282466888428,10.455674595302984,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Turmalina,2022-12-31T00:00:00,1.205163043478261,1.296249508857727,7.558020126187939,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Urucuia,2022-12-31T00:00:00,1.9193245778611627,2.2617149353027344,17.839106599839464,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Vargem_Grande_do_Rio_Pardo,2022-12-31T00:00:00,1.8000000000000005,1.752935767173767,-2.6146796014573983,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Varzea_da_Palma,2022-12-31T00:00:00,2.5200000000000005,2.9920895099639893,18.73371071285669,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Abadia_dos_Dourados,2023-12-31T00:00:00,2.103030303030303,1.8756972551345823,-10.809784698211494,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Acucena,2023-12-31T00:00:00,1.6666666666666672,0.9151873588562012,-45.08875846862795,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Agua_Boa,2023-12-31T00:00:00,1.213636363636364,1.0339405536651611,-14.806396327215218,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Aguas_Vermelhas,2023-12-31T00:00:00,3.0,3.030796766281128,1.0265588760375977,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Angelandia,2023-12-31T00:00:00,2.095663265306122,1.5674200057983398,-25.206495158496733,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Aricanduva,2023-12-31T00:00:00,1.2,1.037027359008789,-13.58105341593424,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Ataleia,2023-12-31T00:00:00,0.6833333333333333,0.8296682834625244,21.41487075061333,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Bandeira,2023-12-31T00:00:00,0.95,1.0613772869110107,11.723924938001124,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Berilo,2023-12-31T00:00:00,1.7988826815642458,1.1720784902572632,-34.84408392669251,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Berizal,2023-12-31T00:00:00,3.570967741935484,2.322296142578125,-34.96731669383751,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Bonfinopolis_de_Minas,2023-12-31T00:00:00,3.0,2.77237868309021,-7.587377230326335,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Buritis,2023-12-31T00:00:00,3.0,2.7982425689697266,-6.725247701009114,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Buritizeiro,2023-12-31T00:00:00,3.0,2.6247568130493164,-12.508106231689451,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Capelinha,2023-12-31T00:00:00,1.541750580945004,1.3606600761413574,-11.745771789665785,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Carai,2023-12-31T00:00:00,1.2,1.1469734907150269,-4.418875773747759,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Caranaiba,2023-12-31T00:00:00,1.45,1.5792540311813354,8.914071115954172,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Catuji,2023-12-31T00:00:00,1.384615384615385,1.1030598878860474,-20.33456365267438,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Congonhas_do_Norte,2023-12-31T00:00:00,1.111111111111111,0.8981010317802429,-19.170907139778123,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Coroaci,2023-12-31T00:00:00,2.4,1.7135611772537231,-28.6016176144282,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Cuparaque,2023-12-31T00:00:00,1.318367346938776,1.1338130235671997,-13.998702546760423,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Diamantina,2023-12-31T00:00:00,2.965183752417796,2.2223262786865234,-25.05266235610356,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Formoso,2023-12-31T00:00:00,3.3803921568627446,2.9795470237731934,-11.857947672602736,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Franciscopolis,2023-12-31T00:00:00,1.2,1.4336220026016235,19.468500216801964,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Frei_Gaspar,2023-12-31T00:00:00,1.2,1.040231466293335,-13.314044475555416,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Grao_Mogol,2023-12-31T00:00:00,1.155555555555555,1.2093921899795532,4.658939517461387,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Indaiabira,2023-12-31T00:00:00,1.9320754716981128,2.5061047077178955,29.710497567430167,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Itabirinha,2023-12-31T00:00:00,1.027027027027027,0.8925777673721313,-13.09111212429247,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Itacambira,2023-12-31T00:00:00,0.75,0.7914313077926636,5.524174372355143,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Itaipe,2023-12-31T00:00:00,0.9598214285714286,0.8853649497032166,-7.757326170455581,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Itamarandiba,2023-12-31T00:00:00,2.4,1.7061340808868408,-28.91107996304829,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Itambacuri,2023-12-31T00:00:00,0.8987341772151899,0.9797547459602356,9.014964691350157,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Jequitinhonha,2023-12-31T00:00:00,2.7000000000000006,2.1162803173065186,-21.619247507166,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Joao_Pinheiro,2023-12-31T00:00:00,3.3,2.398066282272339,-27.33132477962609,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Jose_Goncalves_de_Minas,2023-12-31T00:00:00,1.3210526315789468,1.2851871252059937,-2.714918809108009,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Juiz_de_Fora,2023-12-31T00:00:00,0.7142857142857143,1.1685740947723389,63.60037326812744,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Ladainha,2023-12-31T00:00:00,1.081818181818182,0.8577257990837097,-20.71442193343861,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Malacacheta,2023-12-31T00:00:00,1.619230769230769,1.6474995613098145,1.7458161378982924,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Mantena,2023-12-31T00:00:00,1.2,0.6888535618782043,-42.59553651014964,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Minas_Novas,2023-12-31T00:00:00,1.26,1.2361325025558472,-1.894245828901019,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Monte_Formoso,2023-12-31T00:00:00,0.6000000000000001,0.8852455019950867,47.540916999181086,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Ninheira,2023-12-31T00:00:00,3.0,2.682527542114258,-10.582415262858074,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Nova_Belem,2023-12-31T00:00:00,0.96,0.9728139638900756,1.3347879052162326,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Novo_Cruzeiro,2023-12-31T00:00:00,1.209891435464415,1.151355862617493,-4.838084734805446,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Novorizonte,2023-12-31T00:00:00,1.333333333333333,1.2510173320770264,-6.173700094223002,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Ouro_Verde_de_Minas,2023-12-31T00:00:00,2.5,1.5285232067108154,-38.85907173156738,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Padre_Paraiso,2023-12-31T00:00:00,0.7212121212121212,0.6020218729972839,-16.52637895415811,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Paracatu,2023-12-31T00:00:00,2.4,2.5594406127929688,6.643358866373703,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Pedra_Azul,2023-12-31T00:00:00,1.166666666666667,1.289820432662964,10.556037085396872,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Pirapora,2023-12-31T00:00:00,3.6000000000000005,2.8297834396362305,-21.394904454549167,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Pote,2023-12-31T00:00:00,1.125,0.7765738368034363,-30.97121450636122,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Rio_Pardo_de_Minas,2023-12-31T00:00:00,2.568224299065421,2.69423770904541,4.906635686993748,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Santa_Barbara_do_Monte_Verde,2023-12-31T00:00:00,1.4,1.1252249479293823,-19.626789433615546,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Santa_Maria_do_Suacui,2023-12-31T00:00:00,0.6666666666666667,0.8237816095352173,23.56724143028258,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Santo_Antonio_do_Retiro,2023-12-31T00:00:00,1.02,1.235487461090088,21.12622167549881,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Sao_Goncalo_do_Rio_Preto,2023-12-31T00:00:00,2.868421052631579,2.884951114654541,0.5762773916261915,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Sao_Joao_do_Manteninha,2023-12-31T00:00:00,1.2,0.879604697227478,-26.69960856437683,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Sao_Joao_do_Paraiso,2023-12-31T00:00:00,3.601190476190476,2.454797983169556,-31.83370889710985,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Sao_Sebastiao_do_Maranhao,2023-12-31T00:00:00,1.2,0.9498473405838012,-20.84605495134989,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Senador_Modestino_Goncalves,2023-12-31T00:00:00,2.7000000000000006,2.29465126991272,-15.012915929158549,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Setubinha,2023-12-31T00:00:00,1.2,0.941925883293152,-21.506176392237343,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Taiobeiras,2023-12-31T00:00:00,3.0,2.70733642578125,-9.755452473958332,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Teofilo_Otoni,2023-12-31T00:00:00,1.2,0.8504455089569092,-29.12954092025757,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Turmalina,2023-12-31T00:00:00,1.360606060606061,1.1771684885025024,-13.482048729214773,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Urucuia,2023-12-31T00:00:00,2.0994575045207946,2.111419677734375,0.5697744864005136,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Vargem_Grande_do_Rio_Pardo,2023-12-31T00:00:00,2.1,1.7653197050094604,-15.937156904311411,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_4_2023,Varzea_da_Palma,2023-12-31T00:00:00,3.3,2.826230764389038,-14.35664350336248,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2023_(2023)
    Modelo LSTM treinado com dados de 2012 a 2021, validado com os dados de 2022 e testado com os dados de 2023.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:19
V43_cluster_0_2024,Aguanil,2023-12-31T00:00:00,1.717774762550882,1.5185816287994385,-11.595998386636165,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Alfenas,2023-12-31T00:00:00,1.698430922311519,0.9591559171676636,-43.526939802633954,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Alto_Caparao,2023-12-31T00:00:00,1.32,1.3375306129455566,1.3280767382997407,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Alto_Jequitiba,2023-12-31T00:00:00,1.08,0.982153296470642,-9.059879956422034,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Amparo_do_Serra,2023-12-31T00:00:00,1.319444444444444,1.2090836763381958,-8.36418453015776,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Araponga,2023-12-31T00:00:00,1.5,0.9990946054458618,-33.39369297027588,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Astolfo_Dutra,2023-12-31T00:00:00,0.625,0.7497360110282898,19.957761764526367,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Bambui,2023-12-31T00:00:00,1.5,1.359010100364685,-9.399326642354328,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Boa_Esperanca,2023-12-31T00:00:00,1.08,1.0390735864639282,-3.7894827348214672,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Bom_Jesus_do_Galho,2023-12-31T00:00:00,1.2003192338387871,0.7675137519836426,-36.05753116785213,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Bom_Sucesso,2023-12-31T00:00:00,1.5,1.2246230840682983,-18.35846106211344,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Caete,2023-12-31T00:00:00,1.166666666666667,1.1469268798828125,-1.691981724330382,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Caiana,2023-12-31T00:00:00,1.08,0.9622355699539183,-10.904113893155705,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Cajuri,2023-12-31T00:00:00,0.8200000000000001,0.978239119052887,19.297453543034987,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Camacho,2023-12-31T00:00:00,1.680155642023346,1.2689173221588137,-24.47620384557316,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Campo_do_Meio,2023-12-31T00:00:00,0.8771626297577856,1.2160680294036863,38.63655246456227,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Campos_Altos,2023-12-31T00:00:00,1.380040526849037,1.1107653379440308,-19.5121218302064,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Campos_Gerais,2023-12-31T00:00:00,1.560242401107029,1.2781295776367188,-18.081345774870915,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Cana_Verde,2023-12-31T00:00:00,1.3196428571428571,1.030504584312439,-21.9103427313984,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Canaa,2023-12-31T00:00:00,1.560135135135135,1.1764119863510132,-24.59550715463405,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Candeias,2023-12-31T00:00:00,1.080032206119163,0.9417645335197448,-12.802180510546982,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Caparao,2023-12-31T00:00:00,1.32,1.3365739583969116,1.2556029088569365,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Capitolio,2023-12-31T00:00:00,1.32,1.0117006301879885,-23.356012864546347,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Caputira,2023-12-31T00:00:00,1.380065005417118,1.0229804515838623,-25.87447347998862,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Carangola,2023-12-31T00:00:00,1.140118343195266,1.0679407119750977,-6.330713969383664,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Caratinga,2023-12-31T00:00:00,1.3799999999999997,1.0438714027404783,-24.35714472895081,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Carmo_da_Mata,2023-12-31T00:00:00,1.2,1.073803186416626,-10.516401131947832,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Carmo_do_Rio_Claro,2023-12-31T00:00:00,1.816856256463288,1.3702651262283323,-24.58043274729365,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Carmopolis_de_Minas,2023-12-31T00:00:00,1.5,1.5447571277618408,2.9838085174560547,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Cassia,2023-12-31T00:00:00,1.6377649325626198,1.180586814880371,-27.91475800906908,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Catas_Altas_da_Noruega,2023-12-31T00:00:00,1.1,0.7465927600860596,-32.12793090126731,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Chale,2023-12-31T00:00:00,1.3799999999999997,1.1113814115524292,-19.465115104896416,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Claudio,2023-12-31T00:00:00,2.398692810457516,0.8751367926597595,-63.5160955648656,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Conceicao_da_Barra_de_Minas,2023-12-31T00:00:00,1.680769230769231,1.2100077867507937,-28.008690033133583,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Conceicao_de_Ipanema,2023-12-31T00:00:00,1.5,1.261401653289795,-15.906556447347006,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Coqueiral,2023-12-31T00:00:00,1.32,1.176377296447754,-10.880507844867132,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Corrego_Danta,2023-12-31T00:00:00,1.44,1.1949232816696167,-17.019216550721058,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Cristais,2023-12-31T00:00:00,1.5631111111111111,1.027701735496521,-34.25280338734228,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Desterro_de_Entre_Rios,2023-12-31T00:00:00,1.375,1.5373923778533936,11.810354752974076,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Divinesia,2023-12-31T00:00:00,2.1,1.5594873428344729,-25.738697960263213,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Divino,2023-12-31T00:00:00,1.02,1.0378702878952026,1.75198900933359,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Doresopolis,2023-12-31T00:00:00,1.501960784313725,1.240469217300415,-17.410012947361373,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Durande,2023-12-31T00:00:00,1.3799999999999997,1.2167155742645264,-11.832204763440098,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Eloi_Mendes,2023-12-31T00:00:00,1.577412806790921,0.9206491708755492,-41.63549535593587,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Entre_Folhas,2023-12-31T00:00:00,1.3210526315789468,0.821843147277832,-37.7887657439091,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Entre_Rios_de_Minas,2023-12-31T00:00:00,1.56,1.6699730157852173,7.049552293924181,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ervalia,2023-12-31T00:00:00,1.380044843049327,0.9918004870414734,-28.132734813891595,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Espera_Feliz,2023-12-31T00:00:00,1.08,0.9952709674835204,-7.845280788562922,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Faria_Lemos,2023-12-31T00:00:00,1.380152671755725,0.962186336517334,-30.284065219153337,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ferros,2023-12-31T00:00:00,1.17948717948718,0.7727629542350769,-34.48314083659133,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Fervedouro,2023-12-31T00:00:00,1.2,1.0671433210372925,-11.071389913558956,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Guape,2023-12-31T00:00:00,1.560674157303371,1.2022581100463867,-22.965463071181848,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ibituruna,2023-12-31T00:00:00,1.8000000000000005,1.267049789428711,-29.60834503173829,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ilicinea,2023-12-31T00:00:00,1.560032362459547,1.1078453063964844,-28.985748433458426,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Itapecerica,2023-12-31T00:00:00,0.9037974683544304,0.9303871393203736,2.941994406595934,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ituiutaba,2023-12-31T00:00:00,1.0,0.8931843042373657,-10.681569576263428,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Itumirim,2023-12-31T00:00:00,1.532033426183844,1.0807833671569824,-29.45432203466241,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Lajinha,2023-12-31T00:00:00,1.4399536768963517,1.0908030271530151,-24.24735290762193,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Lavras,2023-12-31T00:00:00,1.5,1.098706603050232,-26.75289312998454,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Luisburgo,2023-12-31T00:00:00,1.44,1.4284725189208984,-0.8005195193820492,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Machado,2023-12-31T00:00:00,1.500560931145702,0.9256104826927184,-38.31570158327391,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Manhuacu,2023-12-31T00:00:00,1.2,1.0460381507873535,-12.83015410105387,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Manhumirim,2023-12-31T00:00:00,1.44,1.235182523727417,-14.223435852262703,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Martins_Soares,2023-12-31T00:00:00,1.2,1.2922916412353516,7.690970102945968,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Matipo,2023-12-31T00:00:00,1.25990675990676,1.060253620147705,-15.846659936472625,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Medeiros,2023-12-31T00:00:00,1.86,1.2659521102905271,-31.938058586530783,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Miradouro,2023-12-31T00:00:00,1.140084388185654,1.0363788604736328,-9.096302763785715,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Mirai,2023-12-31T00:00:00,1.08,1.0535430908203125,-2.4497138129340343,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Moeda,2023-12-31T00:00:00,1.0,0.9018581509590148,-9.81418490409851,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Muriae,2023-12-31T00:00:00,1.057297297297297,0.9264485239982604,-12.375778660696191,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Mutum,2023-12-31T00:00:00,1.019985196150999,1.3352434635162354,30.908121858522104,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Nazareno,2023-12-31T00:00:00,1.5599056603773582,1.2834429740905762,-17.7230388547922,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Nepomuceno,2023-12-31T00:00:00,1.650045578851413,0.9580578207969666,-41.93749354100479,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Oliveira,2023-12-31T00:00:00,1.8240227434257288,1.2654428482055664,-30.62351592015151,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Orizania,2023-12-31T00:00:00,1.2,1.262573003768921,5.214416980743413,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Paraguacu,2023-12-31T00:00:00,1.298291457286432,0.8027240037918091,-38.17073976057826,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Passa_Tempo,2023-12-31T00:00:00,1.625,1.3946106433868408,-14.177806560809795,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Perdoes,2023-12-31T00:00:00,1.6799401197604789,1.2515907287597656,-25.497896381079705,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Pimenta,2023-12-31T00:00:00,1.504186046511628,1.0817302465438845,-28.085342298412147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Piranga,2023-12-31T00:00:00,2.1,1.8240617513656616,-13.139916601635166,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Piumhi,2023-12-31T00:00:00,1.7399633363886338,1.1669199466705322,-32.93422210306321,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ponte_Nova,2023-12-31T00:00:00,1.333333333333333,1.1451901197433472,-14.110741019248945,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Porto_Firme,2023-12-31T00:00:00,1.200764818355641,1.1555321216583252,-3.766990505206392,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Raul_Soares,2023-12-31T00:00:00,1.5,0.9325305223464966,-37.831298510233566,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Reduto,2023-12-31T00:00:00,0.9,1.1391443014144895,26.571589046054413,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ribeirao_Vermelho,2023-12-31T00:00:00,1.5,1.166093826293945,-22.260411580403648,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ritapolis,2023-12-31T00:00:00,2.102222222222222,1.5233001708984375,-27.53857538009547,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Rosario_da_Limeira,2023-12-31T00:00:00,1.2,0.8464329242706299,-29.46392297744751,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santa_Barbara_do_Leste,2023-12-31T00:00:00,1.08,0.9226845502853394,-14.566245343950063,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santa_Margarida,2023-12-31T00:00:00,1.32,1.0793814659118652,-18.2286768248587,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santa_Rita_de_Minas,2023-12-31T00:00:00,1.019930675909879,1.0249325037002563,0.490408604086279,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santa_Rita_do_Itueto,2023-12-31T00:00:00,1.2,1.3087213039398191,9.060108661651617,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santana_da_Vargem,2023-12-31T00:00:00,1.5593593593593589,1.05553936958313,-32.30942160652542,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santana_do_Jacare,2023-12-31T00:00:00,0.9011235955056182,1.0026391744613647,11.26544454745816,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santana_do_Manhuacu,2023-12-31T00:00:00,1.32,1.2377886772155762,-6.228130513971506,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Domingos_das_Dores,2023-12-31T00:00:00,1.296078431372549,1.062956929206848,-17.98668171021293,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Francisco_de_Paula,2023-12-31T00:00:00,1.56,1.346134066581726,-13.709354706299614,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Francisco_do_Gloria,2023-12-31T00:00:00,1.08,0.850751519203186,-21.22671118489019,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Joao_do_Manhuacu,2023-12-31T00:00:00,1.2,1.1077264547348022,-7.689462105433142,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Jose_do_Mantimento,2023-12-31T00:00:00,1.5,1.3401085138320925,-10.659432411193848,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Roque_de_Minas,2023-12-31T00:00:00,1.8000000000000005,1.1811553239822388,-34.38025977876452,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Tiago,2023-12-31T00:00:00,1.560526315789474,1.1715538501739502,-24.92572292308584,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Tomas_de_Aquino,2023-12-31T00:00:00,1.319968346082828,1.0402034521102903,-21.194818406272766,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Senador_Firmino,2023-12-31T00:00:00,1.436170212765957,1.1565322875976562,-19.47108515986688,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Senhora_de_Oliveira,2023-12-31T00:00:00,1.2,1.5321751832962036,27.681265274683643,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sericita,2023-12-31T00:00:00,1.26,0.8152996301651001,-35.29368014562698,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Simonesia,2023-12-31T00:00:00,1.5,1.1251641511917114,-24.98905658721924,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Tapirai,2023-12-31T00:00:00,1.5579665220086798,1.3583239316940308,-12.814305538301982,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Tombos,2023-12-31T00:00:00,1.32,0.9357792139053344,-29.10763531020193,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Tres_Pontas,2023-12-31T00:00:00,1.5900000000000003,0.9965540170669556,-37.32364672534872,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ubaporanga,2023-12-31T00:00:00,1.5,1.0716012716293335,-28.5599152247111,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Vargem_Bonita,2023-12-31T00:00:00,1.487234042553192,1.1988834142684937,-19.38838273158916,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Vermelho_Novo,2023-12-31T00:00:00,1.5,0.9235809445381165,-38.42793703079224,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Vicosa,2023-12-31T00:00:00,1.5004329004329,0.7846493721008301,-47.70513417331454,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Vieiras,2023-12-31T00:00:00,1.5,0.9202008843421936,-38.65327437718709,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Aguanil,2024-12-31T00:00:00,2.025039123630673,1.5528620481491089,-23.316935953069503,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Alfenas,2024-12-31T00:00:00,1.635197497066875,1.114241123199463,-31.858926814765447,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Alto_Caparao,2024-12-31T00:00:00,1.14,1.2759615182876587,11.92644897260165,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Alto_Jequitiba,2024-12-31T00:00:00,1.02,0.9696608781814576,-4.935208021425734,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Amparo_do_Serra,2024-12-31T00:00:00,1.680555555555556,1.2193310260772705,-27.444765390443425,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Araponga,2024-12-31T00:00:00,1.5,1.0914621353149414,-27.23585764567057,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Astolfo_Dutra,2024-12-31T00:00:00,0.8749999999999999,0.6314535737037659,-27.833877290998178,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Bambui,2024-12-31T00:00:00,1.8000000000000005,1.3639612197875977,-24.224376678466808,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Boa_Esperanca,2024-12-31T00:00:00,1.083893395133256,1.0106960535049438,-6.753186425618289,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Bom_Jesus_do_Galho,2024-12-31T00:00:00,0.9,0.8711017370223999,-3.210918108622236,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Bom_Sucesso,2024-12-31T00:00:00,1.6799426934097417,1.3569202423095703,-19.22818274500424,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Caete,2024-12-31T00:00:00,1.8000000000000005,1.1404106616973877,-36.64385212792291,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Caiana,2024-12-31T00:00:00,1.14,0.9727771878242492,-14.668667734714967,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Cajuri,2024-12-31T00:00:00,1.32,0.8366564512252808,-36.61693551323631,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Camacho,2024-12-31T00:00:00,1.5,1.4143580198287964,-5.709465344746908,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Campo_do_Meio,2024-12-31T00:00:00,1.372340425531915,0.9455086588859558,-31.102469817612526,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Campos_Altos,2024-12-31T00:00:00,1.5,1.2252540588378906,-18.31639607747396,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Campos_Gerais,2024-12-31T00:00:00,1.611315789473684,1.3070038557052612,-18.88592762240743,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Cana_Verde,2024-12-31T00:00:00,1.2,1.0947530269622805,-8.770581086476641,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Canaa,2024-12-31T00:00:00,1.319791666666667,1.2371973991394043,-6.258129189121712,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Candeias,2024-12-31T00:00:00,1.14003294892916,0.9863726496696472,-13.47858405354397,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Caparao,2024-12-31T00:00:00,1.6799283154121862,1.3567736148834229,-19.23621963890015,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Capitolio,2024-12-31T00:00:00,1.32,1.1001410484313965,-16.655981179439664,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Caputira,2024-12-31T00:00:00,1.38008658008658,1.1867645978927612,-14.00796044127106,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Carangola,2024-12-31T00:00:00,1.44,0.9991210103034972,-30.616596506701573,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Caratinga,2024-12-31T00:00:00,1.6200335289186922,1.1071606874465942,-31.65816215016365,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Carmo_da_Mata,2024-12-31T00:00:00,1.62,1.1927300691604614,-26.37468708886041,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Carmo_do_Rio_Claro,2024-12-31T00:00:00,1.7634782608695652,1.4319089651107788,-18.80200641630199,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Carmopolis_de_Minas,2024-12-31T00:00:00,1.98,1.5921034812927246,-19.590733268044204,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Cassia,2024-12-31T00:00:00,1.7162790697674415,1.2187182903289795,-28.99066872066921,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Catas_Altas_da_Noruega,2024-12-31T00:00:00,0.9,0.9514732360839844,5.719248453776039,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Chale,2024-12-31T00:00:00,1.320168067226891,1.1808847188949585,-10.550425494271138,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Claudio,2024-12-31T00:00:00,2.699367088607595,1.3798203468322754,-48.88356042215721,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Conceicao_da_Barra_de_Minas,2024-12-31T00:00:00,1.8000000000000005,1.458690166473389,-18.961657418145087,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Conceicao_de_Ipanema,2024-12-31T00:00:00,1.2901734104046243,1.2332801818847656,-4.409735006243526,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Coqueiral,2024-12-31T00:00:00,0.9,1.1660012006759644,29.55568896399604,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Corrego_Danta,2024-12-31T00:00:00,1.5,1.239293336868286,-17.380444208780922,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Cristais,2024-12-31T00:00:00,1.439664804469274,1.162161946296692,-19.275518670117258,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Desterro_de_Entre_Rios,2024-12-31T00:00:00,1.3780487804878048,1.5994293689727783,16.06478606705118,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Divinesia,2024-12-31T00:00:00,1.316666666666667,1.686539649963379,28.091618984560363,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Divino,2024-12-31T00:00:00,1.2,1.0065499544143677,-16.120837132136025,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Doresopolis,2024-12-31T00:00:00,1.5615384615384622,1.290351629257202,-17.366644431804822,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Durande,2024-12-31T00:00:00,1.380095693779904,1.1077805757522583,-19.731611311807644,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Eloi_Mendes,2024-12-31T00:00:00,1.421623345558922,1.0204471349716189,-28.21958515527739,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Entre_Folhas,2024-12-31T00:00:00,1.2,0.9323970079421996,-22.30024933815002,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Entre_Rios_de_Minas,2024-12-31T00:00:00,1.88,1.6439611911773682,-12.555255788437858,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ervalia,2024-12-31T00:00:00,1.32,1.0869345664978027,-17.65647223501495,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Espera_Feliz,2024-12-31T00:00:00,1.44,1.0285468101501465,-28.573138184017605,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Faria_Lemos,2024-12-31T00:00:00,1.37956204379562,0.9485626816749572,-31.24175270398456,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ferros,2024-12-31T00:00:00,1.205128205128205,0.9536682963371276,-20.865822218834083,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Fervedouro,2024-12-31T00:00:00,1.56,1.0994433164596558,-29.522864329509247,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Guape,2024-12-31T00:00:00,1.7459340659340663,1.2424970865249634,-28.834821957595896,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ibituruna,2024-12-31T00:00:00,1.8000000000000005,1.3845378160476685,-23.08123244179621,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ilicinea,2024-12-31T00:00:00,1.5,1.136857271194458,-24.2095152537028,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Itapecerica,2024-12-31T00:00:00,1.615189873417721,0.9240360260009766,-42.79087299837212,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ituiutaba,2024-12-31T00:00:00,1.0,0.5968891382217407,-40.31108617782593,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Itumirim,2024-12-31T00:00:00,1.62116991643454,1.213871717453003,-25.12372052136973,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Lajinha,2024-12-31T00:00:00,1.564997053624043,1.0940192937850952,-30.094482206743507,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Lavras,2024-12-31T00:00:00,1.55996015936255,1.195322036743164,-23.37483559633913,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Luisburgo,2024-12-31T00:00:00,1.2,1.3791699409484863,14.930828412373865,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Machado,2024-12-31T00:00:00,1.3347736360118658,1.113678812980652,-16.564218611016116,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Manhuacu,2024-12-31T00:00:00,1.5,0.9752835035324096,-34.98109976450603,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Manhumirim,2024-12-31T00:00:00,1.56,1.2488596439361572,-19.944894619477104,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Martins_Soares,2024-12-31T00:00:00,1.2,1.1796293258666992,-1.6975561777750614,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Matipo,2024-12-31T00:00:00,1.2,1.1211683750152588,-6.569302082061765,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Medeiros,2024-12-31T00:00:00,1.8600609756097564,1.3790366649627686,-25.860674298018683,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Miradouro,2024-12-31T00:00:00,1.13996383363472,1.0074976682662964,-11.62020771712218,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Mirai,2024-12-31T00:00:00,1.2,1.026374578475952,-14.468785127003986,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Moeda,2024-12-31T00:00:00,1.5,1.0691184997558594,-28.72543334960937,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Muriae,2024-12-31T00:00:00,1.170285714285714,0.8601075410842896,-26.50448257336391,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Mutum,2024-12-31T00:00:00,1.15997150997151,1.0902670621871948,-6.00915170632313,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Nazareno,2024-12-31T00:00:00,1.619811320754717,1.4171867370605469,-12.509147275237057,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Nepomuceno,2024-12-31T00:00:00,1.3800383877159308,1.0670678615570068,-22.678392785646647,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Oliveira,2024-12-31T00:00:00,1.8240227434257288,1.4881525039672852,-18.41370896656913,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Orizania,2024-12-31T00:00:00,1.5,1.193267822265625,-20.448811848958336,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Paraguacu,2024-12-31T00:00:00,1.323316582914573,0.9308420419692992,-29.658401172670107,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Passa_Tempo,2024-12-31T00:00:00,1.5,1.4942240715026855,-0.3850618998209635,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Perdoes,2024-12-31T00:00:00,1.6799401197604789,1.3201788663864136,-21.41512361912989,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Pimenta,2024-12-31T00:00:00,1.715219421101774,1.2089132070541382,-29.518451564780506,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Piranga,2024-12-31T00:00:00,1.8000000000000005,1.9631620645523071,9.064559141794824,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Piumhi,2024-12-31T00:00:00,1.3800316957210783,1.3328728675842283,-3.417227900132316,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ponte_Nova,2024-12-31T00:00:00,2.0,1.1597501039505005,-42.01249480247496,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Porto_Firme,2024-12-31T00:00:00,1.3810526315789473,1.1331340074539185,-17.951424765150716,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Raul_Soares,2024-12-31T00:00:00,1.5,0.9732127785682678,-35.11914809544881,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Reduto,2024-12-31T00:00:00,1.2,0.93124657869339,-22.396118442217507,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ribeirao_Vermelho,2024-12-31T00:00:00,1.43859649122807,1.212348699569702,-15.726980639667037,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ritapolis,2024-12-31T00:00:00,1.8000000000000005,1.77732515335083,-1.259713702731677,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Rosario_da_Limeira,2024-12-31T00:00:00,1.259493670886076,0.9305919408798218,-26.11380569898903,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santa_Barbara_do_Leste,2024-12-31T00:00:00,1.4101226993865028,0.9746882915496826,-30.879185763498672,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santa_Margarida,2024-12-31T00:00:00,1.5,1.0418362617492676,-30.544249216715496,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santa_Rita_de_Minas,2024-12-31T00:00:00,1.200173310225303,0.973793625831604,-18.862249515547195,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santa_Rita_do_Itueto,2024-12-31T00:00:00,1.365238095238095,1.227823257446289,-10.065265412026244,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santana_da_Vargem,2024-12-31T00:00:00,1.44,1.1248383522033691,-21.886225541432697,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santana_do_Jacare,2024-12-31T00:00:00,1.2,0.939564883708954,-21.702926357587177,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Santana_do_Manhuacu,2024-12-31T00:00:00,1.08,1.2028870582580566,11.378431320190424,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Domingos_das_Dores,2024-12-31T00:00:00,1.41,1.1041120290756226,-21.69418233506224,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Francisco_de_Paula,2024-12-31T00:00:00,1.62,1.4301811456680298,-11.717213230368538,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Francisco_do_Gloria,2024-12-31T00:00:00,1.25,0.8389055132865906,-32.887558937072754,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Joao_do_Manhuacu,2024-12-31T00:00:00,1.32,1.0017175674438477,-24.11230549667821,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Jose_do_Mantimento,2024-12-31T00:00:00,1.44,1.3870457410812378,-3.6773790915807054,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Roque_de_Minas,2024-12-31T00:00:00,1.58,1.2706549167633057,-19.578802736499647,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Tiago,2024-12-31T00:00:00,1.621052631578947,1.4338465929031372,-11.548424463767494,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sao_Tomas_de_Aquino,2024-12-31T00:00:00,1.619975932611312,1.0547361373901367,-34.89186375195339,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Senador_Firmino,2024-12-31T00:00:00,1.804347826086957,1.3115315437316897,-27.312709624508795,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Senhora_de_Oliveira,2024-12-31T00:00:00,1.8000000000000005,1.3847697973251345,-23.068344593048103,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Sericita,2024-12-31T00:00:00,1.3799999999999997,0.8405271768569946,-39.09223356108733,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Simonesia,2024-12-31T00:00:00,1.2,1.148644208908081,-4.279649257659909,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Tapirai,2024-12-31T00:00:00,1.9163050216986977,1.371326208114624,-28.43904323232324,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Tombos,2024-12-31T00:00:00,1.5,0.9341698884963988,-37.72200743357341,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Tres_Pontas,2024-12-31T00:00:00,1.387228956803825,1.0705831050872805,-22.82578158158525,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Ubaporanga,2024-12-31T00:00:00,1.440056417489422,1.2347720861434937,-14.255297837831844,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Vargem_Bonita,2024-12-31T00:00:00,2.187804878048781,1.2065070867538452,-44.853076302221154,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Vermelho_Novo,2024-12-31T00:00:00,1.8000000000000005,0.9622400403022766,-46.54221998320686,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Vicosa,2024-12-31T00:00:00,1.32,0.8493065237998962,-35.65859668182604,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_0_2024,Vieiras,2024-12-31T00:00:00,1.44,1.017812967300415,-29.318543937471176,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:03:54
V43_cluster_1_2024,Almenara,2023-12-31T00:00:00,0.78,0.8785433769226074,12.63376627212915,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Alpinopolis,2023-12-31T00:00:00,1.8000000000000005,2.079359531402588,15.519973966810422,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Alterosa,2023-12-31T00:00:00,1.2603960396039595,1.6178034543991089,28.35675482663793,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Andradas,2023-12-31T00:00:00,1.22,1.3157265186309814,7.846435953359138,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Araguari,2023-12-31T00:00:00,3.0,2.2068374156951904,-26.43875281016032,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Arapua,2023-12-31T00:00:00,0.9,1.4314013719558716,59.044596883985726,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Araxa,2023-12-31T00:00:00,1.638401296246287,1.5717473030090332,-4.068233673274286,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Arceburgo,2023-12-31T00:00:00,1.8482558139534884,1.363430738449097,-26.231491974443337,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Areado,2023-12-31T00:00:00,1.590034364261168,1.6836767196655271,5.889329030185554,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Bom_Jesus_da_Penha,2023-12-31T00:00:00,1.2,1.7928388118743896,49.403234322865806,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Botelhos,2023-12-31T00:00:00,1.080052666227781,1.1675536632537842,8.10154909682427,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Botumirim,2023-12-31T00:00:00,0.59375,0.6752045154571533,13.71865523488898,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Cabo_Verde,2023-12-31T00:00:00,1.319976635514019,1.5138087272644043,14.68450929625009,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Campestre,2023-12-31T00:00:00,1.319964428634949,1.2611281871795654,-4.457411137679635,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Capetinga,2023-12-31T00:00:00,1.4484046164290565,2.0791327953338623,43.54640766471898,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Carmo_do_Paranaiba,2023-12-31T00:00:00,2.369801007771799,1.8631671667099,-21.378750342344592,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Cascalho_Rico,2023-12-31T00:00:00,2.4,2.408557891845703,0.3565788269043006,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Claraval,2023-12-31T00:00:00,1.8600214362272245,2.395597457885742,28.79407791906172,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Conceicao_da_Aparecida,2023-12-31T00:00:00,1.679948420373952,1.944835901260376,15.767596056756354,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Coromandel,2023-12-31T00:00:00,2.0926575541308825,1.8974356651306152,-9.32889801367173,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Corrego_Fundo,2023-12-31T00:00:00,1.320158102766798,2.1087841987609863,59.73724619357178,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Cruzeiro_da_Fortaleza,2023-12-31T00:00:00,1.5,1.984376788139344,32.29178587595622,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Delfinopolis,2023-12-31T00:00:00,1.501818181818182,1.7404260635375977,15.88793401279402,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Divisa_Nova,2023-12-31T00:00:00,1.680092592592593,1.5288914442062378,-8.999572348154505,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Dom_Cavati,2023-12-31T00:00:00,0.6000000000000001,0.6863324642181396,14.38874403635659,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Dores_do_Turvo,2023-12-31T00:00:00,1.5,0.9758726358413696,-34.94182427724202,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Estrela_do_Indaia,2023-12-31T00:00:00,1.8000000000000005,1.5429977178573608,-14.277904563479964,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Estrela_do_Sul,2023-12-31T00:00:00,2.43015873015873,1.6159358024597168,-33.50492778905149,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Guaranesia,2023-12-31T00:00:00,1.1961439588688951,1.1756017208099363,-1.7173717182323005,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Guarani,2023-12-31T00:00:00,0.9655172413793104,0.7428005933761597,-23.067081400326323,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Guarda-Mor,2023-12-31T00:00:00,1.7994350282485878,2.0942158699035645,16.381855250527742,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Guaxupe,2023-12-31T00:00:00,1.2,1.1458134651184082,-4.515544573465979,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Guimarania,2023-12-31T00:00:00,1.7704600484261497,1.8042514324188232,1.9086216615117864,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Ibia,2023-12-31T00:00:00,1.668,1.5551224946975708,-6.76723652892261,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Ibiraci,2023-12-31T00:00:00,1.804169884169884,2.312662124633789,28.1842771529172,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Indianopolis,2023-12-31T00:00:00,2.7000000000000006,2.104160785675049,-22.068119049072283,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Itamogi,2023-12-31T00:00:00,1.740011254924029,1.9248038530349727,10.620195564138028,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Itanhomi,2023-12-31T00:00:00,1.078787878787879,1.0442407131195068,-3.202405806337875,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Jacui,2023-12-31T00:00:00,1.32,1.4508652687072754,9.914035508126918,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Jacutinga,2023-12-31T00:00:00,1.160053262316911,1.3255478143692017,14.266116688621464,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Juruaia,2023-12-31T00:00:00,1.5,1.5800201892852783,5.334679285685221,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Lagoa_Dourada,2023-12-31T00:00:00,1.8000000000000005,1.4147942066192627,-21.40032185448542,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Lagoa_Formosa,2023-12-31T00:00:00,1.978723404255319,2.2766902446746826,15.058539247000096,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Lagoa_Grande,2023-12-31T00:00:00,2.4,1.2156976461410522,-49.34593141078949,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Matutina,2023-12-31T00:00:00,1.502024291497976,1.7315473556518557,15.280915591915962,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Monte_Belo,2023-12-31T00:00:00,1.3799999999999997,1.423831820487976,3.17621887594032,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Monte_Carmelo,2023-12-31T00:00:00,2.4900284900284904,2.0995078086853027,-15.68338205394266,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Monte_Santo_de_Minas,2023-12-31T00:00:00,1.620050377833753,1.7636966705322266,8.866779370808825,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Muzambinho,2023-12-31T00:00:00,1.68,1.4061343669891355,-16.301525774456202,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Nova_Resende,2023-12-31T00:00:00,1.56,1.7365458011627195,11.317038536071774,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Passos,2023-12-31T00:00:00,1.829801324503311,1.3532066345214844,-26.04625341558299,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Patis,2023-12-31T00:00:00,1.2,1.9128384590148928,59.40320491790773,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Patos_de_Minas,2023-12-31T00:00:00,1.782452316076294,1.8688222169876096,4.845565860714954,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Patrocinio,2023-12-31T00:00:00,2.4370275910039414,1.4171682596206665,-41.84849343306534,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Pedrinopolis,2023-12-31T00:00:00,2.187804878048781,2.27451753616333,3.963454830207902,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Perdizes,2023-12-31T00:00:00,2.106451612903226,1.8030482530593872,-14.4035285683905,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Piracema,2023-12-31T00:00:00,1.2,1.1298115253448486,-5.849039554595944,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Ponto_dos_Volantes,2023-12-31T00:00:00,0.6000000000000001,0.6399572491645813,6.6595415274302,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Pratapolis,2023-12-31T00:00:00,1.8011363636363642,1.820228815078736,1.0600225406489974,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Pratinha,2023-12-31T00:00:00,2.13,1.6649997234344482,-21.83099889979116,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Presidente_Kubitschek,2023-12-31T00:00:00,0.8947368421052632,0.9459519386291504,5.724040199728572,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Presidente_Olegario,2023-12-31T00:00:00,2.160074626865672,1.987834334373474,-7.973812124358101,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Quartel_Geral,2023-12-31T00:00:00,3.0,2.812997579574585,-6.233414014180502,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Rio_Paranaiba,2023-12-31T00:00:00,1.8000000000000005,1.465373396873474,-18.59036684036256,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Rio_Vermelho,2023-12-31T00:00:00,0.9,0.9348766803741456,3.8751867082383873,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Romaria,2023-12-31T00:00:00,2.131578947368421,2.332160472869873,9.409997492660723,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sacramento,2023-12-31T00:00:00,1.75,1.6496808528900146,-5.732522691999163,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Santa_Rosa_da_Serra,2023-12-31T00:00:00,1.68,1.7356876134872437,3.314738898050221,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Santo_Antonio_do_Amparo,2023-12-31T00:00:00,1.8000000000000005,1.561107873916626,-13.271784782409682,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sao_Goncalo_do_Abaete,2023-12-31T00:00:00,1.619047619047619,1.6675894260406494,2.9981704319224622,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sao_Gotardo,2023-12-31T00:00:00,1.5,1.4161711931228638,-5.588587125142416,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sao_Joao_Batista_do_Gloria,2023-12-31T00:00:00,1.5232974910394272,1.532506823539734,0.6045655923730712,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sao_Pedro_da_Uniao,2023-12-31T00:00:00,1.5,1.6346921920776367,8.979479471842449,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sao_Sebastiao_do_Paraiso,2023-12-31T00:00:00,1.440017746228926,1.6683554649353027,15.856590608299143,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Serra_do_Salitre,2023-12-31T00:00:00,1.489636363636364,1.921939849853516,29.0207393408316,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Tapira,2023-12-31T00:00:00,1.92,1.3959968090057373,-27.291832864284515,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Tiros,2023-12-31T00:00:00,2.382038834951457,1.3736968040466309,-42.33104918817895,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Tupaciguara,2023-12-31T00:00:00,2.622222222222222,2.2921841144561768,-12.586199024976295,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Uberaba,2023-12-31T00:00:00,2.1200980392156863,2.4935898780822754,17.616724885268017,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Uberlandia,2023-12-31T00:00:00,1.8000000000000005,1.9324334859848025,7.357415888044554,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Unai,2023-12-31T00:00:00,2.520095187731359,2.735416412353516,8.54417030239216,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Varginha,2023-12-31T00:00:00,1.679990280646337,1.3346564769744873,-20.555702473408985,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Varjao_de_Minas,2023-12-31T00:00:00,2.3892857142857142,2.39917516708374,0.4139083383329268,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Virginopolis,2023-12-31T00:00:00,1.3258426966292132,1.3943301439285278,5.165578652236446,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Almenara,2024-12-31T00:00:00,0.78,0.9702731370925904,24.393991934947472,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Alpinopolis,2024-12-31T00:00:00,2.08,1.6289291381835938,-21.686099125788765,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Alterosa,2024-12-31T00:00:00,1.110028116213683,1.5188822746276855,36.8327749938991,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Andradas,2024-12-31T00:00:00,1.26,0.980949878692627,-22.146835024394687,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Araguari,2024-12-31T00:00:00,1.500037950664137,1.8195784091949463,21.302158281351065,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Arapua,2024-12-31T00:00:00,1.0805194805194802,0.9710833430290222,-10.128104070631332,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Araxa,2024-12-31T00:00:00,1.412283279459301,1.21075177192688,-14.269906785951497,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Arceburgo,2024-12-31T00:00:00,1.7586206896551722,1.3501559495925903,-23.226426395715443,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Areado,2024-12-31T00:00:00,1.162105263157895,1.7083299160003662,47.00302719206047,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Bom_Jesus_da_Penha,2024-12-31T00:00:00,1.56,1.3774821758270264,-11.69986052390857,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Botelhos,2024-12-31T00:00:00,1.08,0.9154035449028016,-15.240412508999864,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Botumirim,2024-12-31T00:00:00,0.7250000000000001,0.6204239726066589,-14.424279640460846,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Cabo_Verde,2024-12-31T00:00:00,1.32,1.2937042713165283,-1.9921006578387683,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Campestre,2024-12-31T00:00:00,1.320032051282051,1.1600656509399414,-12.118372443058924,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Capetinga,2024-12-31T00:00:00,1.437691001697793,1.5742309093475342,9.49716646264732,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Carmo_do_Paranaiba,2024-12-31T00:00:00,2.103206239168111,1.475483775138855,-29.84597764780031,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Cascalho_Rico,2024-12-31T00:00:00,1.8000000000000005,2.2151567935943604,23.06426631079778,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Claraval,2024-12-31T00:00:00,1.92,1.625314474105835,-15.348204473654423,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Conceicao_da_Aparecida,2024-12-31T00:00:00,1.5,1.7712664604187012,18.08443069458008,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Coromandel,2024-12-31T00:00:00,1.6144686299615878,1.3773090839385986,-14.68963481988695,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Corrego_Fundo,2024-12-31T00:00:00,1.501960784313725,1.1478519439697266,-23.57643715084064,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Cruzeiro_da_Fortaleza,2024-12-31T00:00:00,2.22,1.5274782180786133,-31.19467486132372,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Delfinopolis,2024-12-31T00:00:00,1.5,1.3278298377990725,-11.478010813395183,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Divisa_Nova,2024-12-31T00:00:00,1.679831932773109,1.44862961769104,-13.763419457111665,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Dom_Cavati,2024-12-31T00:00:00,0.6000000000000001,0.6022224426269531,0.3704071044921726,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Dores_do_Turvo,2024-12-31T00:00:00,1.2,1.0659736394882202,-11.168863375981646,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Estrela_do_Indaia,2024-12-31T00:00:00,1.56,1.6995760202407837,8.947180784665617,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Estrela_do_Sul,2024-12-31T00:00:00,1.7099999999999995,1.585463285446167,-7.282848804317705,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Guaranesia,2024-12-31T00:00:00,1.205714285714286,1.119517207145691,-7.149046800712858,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Guarani,2024-12-31T00:00:00,0.9655172413793104,0.8570522665977478,-11.23387238809041,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Guarda-Mor,2024-12-31T00:00:00,1.740112994350282,1.7488491535186768,0.5020455106512577,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Guaxupe,2024-12-31T00:00:00,1.32,1.0651880502700806,-19.30393558559996,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Guimarania,2024-12-31T00:00:00,1.8219512195121947,1.4008097648620603,-23.11485895670081,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Ibia,2024-12-31T00:00:00,1.681621621621622,1.286699652671814,-23.484591531891503,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Ibiraci,2024-12-31T00:00:00,1.978101265822785,1.3688591718673706,-30.79933795512749,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Indianopolis,2024-12-31T00:00:00,1.8000000000000005,1.841660022735596,2.31444570753308,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Itamogi,2024-12-31T00:00:00,1.44,1.6410338878631592,13.960686657163835,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Itanhomi,2024-12-31T00:00:00,1.02089552238806,1.0461288690567017,2.4716874660803927,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Jacui,2024-12-31T00:00:00,1.3799999999999997,1.1283161640167236,-18.237959129222904,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Jacutinga,2024-12-31T00:00:00,1.319874804381847,1.0778651237487793,-18.33580577715558,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Juruaia,2024-12-31T00:00:00,1.68,1.4770002365112305,-12.083319255283897,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Lagoa_Dourada,2024-12-31T00:00:00,1.5,1.2952691316604614,-13.648724555969238,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Lagoa_Formosa,2024-12-31T00:00:00,1.8142857142857145,1.803404450416565,-0.5997547014491883,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Lagoa_Grande,2024-12-31T00:00:00,2.4,1.0150041580200195,-57.708160082499184,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Matutina,2024-12-31T00:00:00,1.380566801619433,1.5027748346328735,8.852018813583523,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Monte_Belo,2024-12-31T00:00:00,1.5,1.2571649551391602,-16.189002990722656,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Monte_Carmelo,2024-12-31T00:00:00,1.56,1.7960798740386963,15.133325258890784,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Monte_Santo_de_Minas,2024-12-31T00:00:00,1.5,1.5236397981643677,1.5759865442911785,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Muzambinho,2024-12-31T00:00:00,1.26,1.3003023862838743,3.198602086021786,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Nova_Resende,2024-12-31T00:00:00,1.32,1.4430614709854126,9.3228387110161,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Passos,2024-12-31T00:00:00,1.95459940652819,1.2238856554031372,-37.3843227765512,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Patis,2024-12-31T00:00:00,0.9,1.4903496503829956,65.59440559811061,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Patos_de_Minas,2024-12-31T00:00:00,1.6624523160762943,1.8715860843658447,12.579835599925426,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Patrocinio,2024-12-31T00:00:00,1.4995330375904743,1.039558172225952,-30.674540262456173,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Pedrinopolis,2024-12-31T00:00:00,1.8511627906976744,1.8420771360397337,-0.4908079777530571,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Perdizes,2024-12-31T00:00:00,1.142806076854334,1.467121958732605,28.37890771205703,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Piracema,2024-12-31T00:00:00,0.8,1.0589535236358645,32.369190454483025,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Ponto_dos_Volantes,2024-12-31T00:00:00,0.5,0.6018061637878418,20.36123275756836,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Pratapolis,2024-12-31T00:00:00,1.1988636363636362,1.524588108062744,27.169434606181515,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Pratinha,2024-12-31T00:00:00,1.849285714285714,1.5502134561538696,-16.172312143089307,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Presidente_Kubitschek,2024-12-31T00:00:00,0.7368421052631579,0.8177742958068848,10.983654430934369,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Presidente_Olegario,2024-12-31T00:00:00,1.9199630314232905,1.714244365692139,-10.714720146390007,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Quartel_Geral,2024-12-31T00:00:00,3.0,2.610163927078247,-12.994535764058432,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Rio_Paranaiba,2024-12-31T00:00:00,1.680014776505357,1.091763615608215,-35.01464208075469,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Rio_Vermelho,2024-12-31T00:00:00,0.9230769230769232,0.822067141532898,-10.94272633393606,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Romaria,2024-12-31T00:00:00,2.052631578947369,2.0399246215820312,-0.6190568972856865,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sacramento,2024-12-31T00:00:00,1.737021276595745,1.3354718685150146,-23.11712662885144,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Santa_Rosa_da_Serra,2024-12-31T00:00:00,1.92,1.5603783130645752,-18.73029619455337,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Santo_Antonio_do_Amparo,2024-12-31T00:00:00,1.68,1.4160608053207395,-15.710666349955964,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sao_Goncalo_do_Abaete,2024-12-31T00:00:00,1.5,1.5024988651275637,0.1665910085042317,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sao_Gotardo,2024-12-31T00:00:00,1.668148148148148,1.2114118337631226,-27.379841226455788,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sao_Joao_Batista_do_Gloria,2024-12-31T00:00:00,1.548387096774194,1.2847793102264404,-17.024669547875742,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sao_Pedro_da_Uniao,2024-12-31T00:00:00,2.04,1.434637188911438,-29.67464760238049,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Sao_Sebastiao_do_Paraiso,2024-12-31T00:00:00,1.26,1.4227707386016846,12.918312587435285,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Serra_do_Salitre,2024-12-31T00:00:00,1.5168750000000002,1.2550104856491089,-17.26342080599201,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Tapira,2024-12-31T00:00:00,1.98,1.1189677715301514,-43.486476185345886,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Tiros,2024-12-31T00:00:00,1.95,1.359240174293518,-30.295375677255475,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Tupaciguara,2024-12-31T00:00:00,2.8219895287958106,1.976972222328186,-29.94402700098633,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Uberaba,2024-12-31T00:00:00,2.102941176470588,2.141756296157837,1.8457539431698848,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Uberlandia,2024-12-31T00:00:00,1.919565217391304,1.6052381992340088,-16.37490694817166,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Unai,2024-12-31T00:00:00,2.2801061007957566,2.694723129272461,18.18411118377356,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Varginha,2024-12-31T00:00:00,1.3799999999999997,1.4037398099899292,1.720276086226778,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Varjao_de_Minas,2024-12-31T00:00:00,2.6876337184424486,2.3618931770324707,-12.119975247175896,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_1_2024,Virginopolis,2024-12-31T00:00:00,1.325,1.2815511226654053,-3.279160553554316,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:04:28
V43_cluster_2_2024,Abre_Campo,2023-12-31T00:00:00,1.8000000000000005,1.5948266983032229,-11.398516760932088,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Aimores,2023-12-31T00:00:00,1.544827586206897,2.5596399307250977,65.69097765854423,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Alvarenga,2023-12-31T00:00:00,1.75,1.0327223539352417,-40.98729406084333,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Andrelandia,2023-12-31T00:00:00,1.8000000000000005,1.929751992225647,7.208444012535926,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Antonio_Dias,2023-12-31T00:00:00,1.477272727272727,2.0165011882781982,36.5016188988319,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Antonio_Prado_de_Minas,2023-12-31T00:00:00,1.4857142857142862,1.595696210861206,7.402629577196526,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Bocaiuva,2023-12-31T00:00:00,3.0,3.772105693817138,25.73685646057129,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Bom_Jesus_do_Amparo,2023-12-31T00:00:00,1.25,1.88348650932312,50.67892074584961,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Campo_Belo,2023-12-31T00:00:00,1.5,1.6741218566894531,11.608123779296877,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Capela_Nova,2023-12-31T00:00:00,1.8000000000000005,2.1983654499053955,22.131413883633066,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Capitao_Eneas,2023-12-31T00:00:00,3.0,5.414309501647949,80.47698338826498,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Casa_Grande,2023-12-31T00:00:00,2.523076923076923,2.429572343826294,-3.7059741776163952,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Cataguases,2023-12-31T00:00:00,1.333333333333333,2.863553285598755,114.76649641990666,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Caxambu,2023-12-31T00:00:00,1.316326530612245,1.640349268913269,24.61568089418633,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Coimbra,2023-12-31T00:00:00,1.8000000000000005,2.1233503818511963,17.96391010284422,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Conselheiro_Pena,2023-12-31T00:00:00,1.320048602673147,1.8428514003753664,39.604814295740645,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Corrego_Novo,2023-12-31T00:00:00,1.8000000000000005,2.4426090717315674,35.70050398508705,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Cruzilia,2023-12-31T00:00:00,1.5,1.7604546546936035,17.363643646240234,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Divisopolis,2023-12-31T00:00:00,1.616883116883117,1.486994743347168,-8.033256837163114,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Esmeraldas,2023-12-31T00:00:00,2.222222222222222,2.4208431243896484,8.937940597534197,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Espirito_Santo_do_Dourado,2023-12-31T00:00:00,1.5,1.5549705028533936,3.664700190226237,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Eugenopolis,2023-12-31T00:00:00,1.68,2.130699872970581,26.82737339110602,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Felicio_dos_Santos,2023-12-31T00:00:00,3.542087542087541,6.399607181549072,80.67332061977896,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Formiga,2023-12-31T00:00:00,2.021543985637344,2.3387773036956787,15.692625058480692,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Guaraciaba,2023-12-31T00:00:00,1.5,2.7963955402374268,86.42636934916177,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Guiricema,2023-12-31T00:00:00,1.5,2.866825580596924,91.12170537312826,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Iapu,2023-12-31T00:00:00,1.559210526315789,1.907633900642395,22.34614046314099,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Ijaci,2023-12-31T00:00:00,1.971428571428572,1.814408540725708,-7.9647841660873,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Imbe_de_Minas,2023-12-31T00:00:00,1.3799999999999997,1.664245367050171,20.59749036595444,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Inhapim,2023-12-31T00:00:00,2.7000000000000006,2.032400608062744,-24.725903405083567,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Irai_de_Minas,2023-12-31T00:00:00,2.18825561312608,3.2805051803588867,49.91416727922612,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Itamarati_de_Minas,2023-12-31T00:00:00,1.2,1.4259822368621826,18.83185307184856,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Jequeri,2023-12-31T00:00:00,1.5,2.199091911315918,46.6061274210612,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Lamim,2023-12-31T00:00:00,1.8000000000000005,3.147761106491089,74.87561702728269,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Mar_de_Espanha,2023-12-31T00:00:00,1.5625,2.753582239151001,76.22926330566406,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Mata_Verde,2023-12-31T00:00:00,1.739700374531835,2.368791103363037,36.160866436583646,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Monte_Alegre_de_Minas,2023-12-31T00:00:00,2.338983050847458,3.8697476387023926,65.44573237930516,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Nova_Era,2023-12-31T00:00:00,2.636363636363636,1.654381275177002,-37.247606803630944,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Nova_Ponte,2023-12-31T00:00:00,2.6142857142857143,2.7766213417053223,6.209559518782817,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Paula_Candido,2023-12-31T00:00:00,1.6197080291970802,1.748429298400879,7.947189671437774,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Pecanha,2023-12-31T00:00:00,2.30379746835443,2.743497848510742,19.08589562216961,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Pedra_Bonita,2023-12-31T00:00:00,1.08,1.967366099357605,82.16352771829675,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Pedra_Dourada,2023-12-31T00:00:00,1.2,1.625555396080017,35.46294967333476,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Pedra_do_Anta,2023-12-31T00:00:00,1.5,1.6963844299316406,13.09229532877604,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Piedade_de_Caratinga,2023-12-31T00:00:00,2.4,1.929492235183716,-19.604490200678505,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Pocrane,2023-12-31T00:00:00,1.377952755905512,1.5018205642700195,8.989263807024257,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Presidente_Bernardes,2023-12-31T00:00:00,1.320588235294118,1.7385210990905762,31.647477436702832,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sabinopolis,2023-12-31T00:00:00,1.2,1.456181287765503,21.34844064712525,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Santa_Barbara,2023-12-31T00:00:00,1.3,1.235838532447815,-4.935497504014238,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Santo_Antonio_do_Grama,2023-12-31T00:00:00,1.521739130434783,3.4552509784698486,127.05935001373284,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Domingos_do_Prata,2023-12-31T00:00:00,1.2,1.2553048133850098,4.608734448750818,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Geraldo,2023-12-31T00:00:00,1.5,2.500072479248047,66.67149861653647,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Jose_da_Barra,2023-12-31T00:00:00,2.2413698630136984,2.6123950481414795,16.553501108866897,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Jose_do_Alegre,2023-12-31T00:00:00,1.592307692307692,1.8706982135772705,17.48346268842764,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Miguel_do_Anta,2023-12-31T00:00:00,1.5598870056497178,1.6646628379821775,6.716886027832452,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Sebastiao_da_Vargem_Alegre,2023-12-31T00:00:00,1.5,1.9416823387146,29.445489247639973,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Sebastiao_do_Anta,2023-12-31T00:00:00,1.7998212689901698,1.9639265537261963,9.117865621629278,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Senhora_dos_Remedios,2023-12-31T00:00:00,1.5,1.9691814184188845,31.278761227925617,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Teixeiras,2023-12-31T00:00:00,1.5007092198581562,1.815898895263672,21.00271466549041,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Visconde_do_Rio_Branco,2023-12-31T00:00:00,1.333333333333333,2.1761012077331543,63.20759057998661,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Abre_Campo,2024-12-31T00:00:00,1.32,2.128620147705078,61.25910209886955,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Aimores,2024-12-31T00:00:00,0.9455882352941176,2.3692662715911865,150.56004116360916,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Alvarenga,2024-12-31T00:00:00,1.25,1.902926206588745,52.2340965270996,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Andrelandia,2024-12-31T00:00:00,1.5,2.1695544719696045,44.63696479797363,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Antonio_Dias,2024-12-31T00:00:00,1.5,2.34206771850586,56.13784790039063,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Antonio_Prado_de_Minas,2024-12-31T00:00:00,1.933333333333333,2.073113441467285,7.230005593135464,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Bocaiuva,2024-12-31T00:00:00,2.0989010989010994,4.284396648406982,104.12570419111796,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Bom_Jesus_do_Amparo,2024-12-31T00:00:00,0.75,2.379457712173462,217.2610282897949,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Campo_Belo,2024-12-31T00:00:00,1.2,2.0361790657043457,69.68158880869548,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Capela_Nova,2024-12-31T00:00:00,2.101234567901236,2.283943653106689,8.695320741270123,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Capitao_Eneas,2024-12-31T00:00:00,3.0,5.958110809326172,98.60369364420572,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Casa_Grande,2024-12-31T00:00:00,2.522388059701492,3.423306941986084,35.71690243376786,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Cataguases,2024-12-31T00:00:00,1.0,1.9497350454330444,94.97350454330444,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Caxambu,2024-12-31T00:00:00,1.795918367346939,2.0060088634490967,11.698220805688324,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Coimbra,2024-12-31T00:00:00,1.5012658227848097,2.1276891231536865,41.726341255599735,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Conselheiro_Pena,2024-12-31T00:00:00,1.2,1.801122546195984,50.09354551633199,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Corrego_Novo,2024-12-31T00:00:00,1.2,2.986903667449951,148.9086389541626,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Cruzilia,2024-12-31T00:00:00,1.502793296089385,1.863304018974304,23.9893752402976,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Divisopolis,2024-12-31T00:00:00,1.4902200488997548,1.7594327926635742,18.065301427301428,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Esmeraldas,2024-12-31T00:00:00,3.0,2.5594499111175537,-14.685002962748207,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Espirito_Santo_do_Dourado,2024-12-31T00:00:00,1.4391752577319588,1.9940468072891235,38.55482830017549,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Eugenopolis,2024-12-31T00:00:00,1.68,2.4912667274475098,48.28968615758987,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Felicio_dos_Santos,2024-12-31T00:00:00,2.663299663299664,7.729091167449951,190.2073421912307,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Formiga,2024-12-31T00:00:00,1.9475763016157988,2.66152572631836,36.65835449477565,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Guaraciaba,2024-12-31T00:00:00,1.8000000000000005,2.787186622619629,54.84370125664603,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Guiricema,2024-12-31T00:00:00,1.56,3.208001136779785,105.64109851152467,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Iapu,2024-12-31T00:00:00,1.355263157894737,2.120033502578736,56.42965650095522,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Ijaci,2024-12-31T00:00:00,2.19,2.7056684494018555,23.54650453889752,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Imbe_de_Minas,2024-12-31T00:00:00,1.26,1.853386759757996,47.0941872823806,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Inhapim,2024-12-31T00:00:00,1.2,3.1936824321746826,166.14020268122357,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Irai_de_Minas,2024-12-31T00:00:00,2.607944732297064,4.126301288604736,58.22042689418162,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Itamarati_de_Minas,2024-12-31T00:00:00,1.196969696969697,1.411865234375,17.953298061708857,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Jequeri,2024-12-31T00:00:00,1.8000000000000005,2.424600839614868,34.70004664527043,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Lamim,2024-12-31T00:00:00,1.777777777777778,3.490915536880493,96.36399894952773,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Mar_de_Espanha,2024-12-31T00:00:00,1.2625,2.4240856170654297,92.006781549737,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Mata_Verde,2024-12-31T00:00:00,1.5,2.0759663581848145,38.39775721232097,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Monte_Alegre_de_Minas,2024-12-31T00:00:00,2.378787878787879,3.950596332550049,66.07602417089376,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Nova_Era,2024-12-31T00:00:00,1.5,2.861854553222656,90.79030354817708,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Nova_Ponte,2024-12-31T00:00:00,2.306557377049181,3.551215410232544,53.96171998875986,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Paula_Candido,2024-12-31T00:00:00,1.31970802919708,1.8582295179367063,40.80610838347835,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Pecanha,2024-12-31T00:00:00,1.8855421686746991,3.1277048587799072,65.87827685541997,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Pedra_Bonita,2024-12-31T00:00:00,1.2,2.3453474044799805,95.44561703999838,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Pedra_Dourada,2024-12-31T00:00:00,1.2800000000000002,1.6365742683410645,27.85736471414564,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Pedra_do_Anta,2024-12-31T00:00:00,1.379166666666667,2.0341005325317383,47.48765190562448,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Piedade_de_Caratinga,2024-12-31T00:00:00,1.68,2.89681339263916,72.42936860947383,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Pocrane,2024-12-31T00:00:00,1.7968750000000002,1.4909288883209229,-17.026566215183433,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Presidente_Bernardes,2024-12-31T00:00:00,1.110144927536232,1.7743754386901855,59.832774503424005,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sabinopolis,2024-12-31T00:00:00,1.2,1.4831348657608032,23.594572146733604,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Santa_Barbara,2024-12-31T00:00:00,1.333333333333333,1.432478904724121,7.435917854309106,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Santo_Antonio_do_Grama,2024-12-31T00:00:00,1.565217391304348,2.363150119781494,50.979035430484345,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Domingos_do_Prata,2024-12-31T00:00:00,1.05,1.583101511001587,50.77157247634161,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Geraldo,2024-12-31T00:00:00,1.3189189189189188,2.523301362991333,91.3158820300806,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Jose_da_Barra,2024-12-31T00:00:00,1.709523809523809,2.819791316986084,64.94601018581555,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Jose_do_Alegre,2024-12-31T00:00:00,1.8000000000000005,2.0377469062805176,13.20816146002874,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Miguel_do_Anta,2024-12-31T00:00:00,1.55974025974026,1.7646284103393557,13.136042960974471,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Sebastiao_da_Vargem_Alegre,2024-12-31T00:00:00,1.2800000000000002,2.2718634605407715,77.48933285474774,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Sao_Sebastiao_do_Anta,2024-12-31T00:00:00,1.8000000000000005,2.0413079261779785,13.405995898776569,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Senhora_dos_Remedios,2024-12-31T00:00:00,1.8000000000000005,2.0790722370147705,15.504013167487232,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Teixeiras,2024-12-31T00:00:00,1.5,1.993991494178772,32.93276627858479,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_2_2024,Visconde_do_Rio_Branco,2024-12-31T00:00:00,1.333333333333333,2.395411491394043,79.65586185455327,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:04
V43_cluster_3_2024,Aiuruoca,2023-12-31T00:00:00,1.6000000000000003,1.4779052734375,-7.630920410156268,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Albertina,2023-12-31T00:00:00,1.5,1.5402250289916992,2.6816685994466143,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Baependi,2023-12-31T00:00:00,1.439779005524862,1.3213311433792114,-8.226808537360998,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Bandeira_do_Sul,2023-12-31T00:00:00,1.5,1.441216230392456,-3.918917973836263,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Borda_da_Mata,2023-12-31T00:00:00,1.290476190476191,1.4001191854476929,8.496320643548112,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Brazopolis,2023-12-31T00:00:00,1.440389294403893,1.0601603984832764,-26.397648010704973,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Bueno_Brandao,2023-12-31T00:00:00,1.379901960784314,1.3646841049194336,-1.1028215262648626,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Cachoeira_de_Minas,2023-12-31T00:00:00,1.6204081632653062,1.694108963012695,4.548286130506378,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Caldas,2023-12-31T00:00:00,1.56,1.4112203121185305,-9.537159479581396,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Cambuquira,2023-12-31T00:00:00,1.56,1.4940264225006104,-4.229075480730109,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Campanha,2023-12-31T00:00:00,1.327075098814229,1.4707636833190918,10.82746444668065,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Careacu,2023-12-31T00:00:00,1.5,1.237083077430725,-17.52779483795166,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Carmo_da_Cachoeira,2023-12-31T00:00:00,1.32,1.4512988328933716,9.946881279800872,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Carmo_de_Minas,2023-12-31T00:00:00,1.5,1.3797800540924072,-8.014663060506184,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Carrancas,2023-12-31T00:00:00,1.214285714285714,1.487151026725769,22.47126102447513,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Carvalhopolis,2023-12-31T00:00:00,1.560106382978723,1.3777563571929932,-11.68830714207883,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Conceicao_das_Pedras,2023-12-31T00:00:00,1.5598885793871868,1.4825783967971802,-4.9561349196093545,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Conceicao_do_Rio_Verde,2023-12-31T00:00:00,1.44,1.705808401107788,18.4589167435964,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Conceicao_dos_Ouros,2023-12-31T00:00:00,1.422222222222222,1.3543457984924316,-4.77256104350089,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Congonhal,2023-12-31T00:00:00,1.2,1.442725658416748,20.227138201395675,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Cordislandia,2023-12-31T00:00:00,1.14,1.4628703594207764,28.32196135269969,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Cristina,2023-12-31T00:00:00,1.68,1.5005922317504885,-10.679033824375692,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Datas,2023-12-31T00:00:00,0.6666666666666667,1.0922472476959229,63.837087154388406,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Dom_Vicoso,2023-12-31T00:00:00,1.32,1.2917282581329346,-2.1417986262928403,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Fama,2023-12-31T00:00:00,1.559677419354839,1.4155030250549316,-9.243859820676583,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Fortaleza_de_Minas,2023-12-31T00:00:00,1.5,1.3731632232666016,-8.455785115559895,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Heliodora,2023-12-31T00:00:00,1.439872408293461,1.3233449459075928,-8.092901962332679,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Ibitiura_de_Minas,2023-12-31T00:00:00,1.150344827586207,1.4407572746276855,25.24568634353381,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Inconfidentes,2023-12-31T00:00:00,1.7401360544217692,1.64016592502594,-5.74496052431075,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Ingai,2023-12-31T00:00:00,1.6197718631178712,1.465270757675171,-9.538448528504736,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Itajuba,2023-12-31T00:00:00,1.5862068965517242,1.4024897813796997,-11.582165956497196,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Itutinga,2023-12-31T00:00:00,1.5,1.3851065635681152,-7.659562428792317,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Jesuania,2023-12-31T00:00:00,1.26,1.3322759866714478,5.736189418368869,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Lambari,2023-12-31T00:00:00,1.56,1.3426365852355957,-13.93355222848746,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Luminarias,2023-12-31T00:00:00,1.260224719101124,1.597804307937622,26.78725339376633,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Maria_da_Fe,2023-12-31T00:00:00,1.422222222222222,1.3962432146072388,-1.8266489729285125,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Monsenhor_Paulo,2023-12-31T00:00:00,1.389931972789116,1.4915707111358645,7.312497326239232,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Monte_Siao,2023-12-31T00:00:00,1.5,1.386867880821228,-7.542141278584798,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Natercia,2023-12-31T00:00:00,1.5,1.4497939348220823,-3.347071011861165,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Olimpio_Noronha,2023-12-31T00:00:00,1.2,1.2783849239349363,6.532076994578048,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Ouro_Fino,2023-12-31T00:00:00,1.68,1.3627573251724243,-18.883492549260456,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Paraisopolis,2023-12-31T00:00:00,1.2,1.4091796875,17.431640625000007,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Pedralva,2023-12-31T00:00:00,1.67998417721519,1.4454989433288574,-13.9575858550659,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Pirangucu,2023-12-31T00:00:00,1.333333333333333,1.2151038646697998,-8.867210149764993,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Piranguinho,2023-12-31T00:00:00,1.460887949260042,1.41228449344635,-3.3269804051919323,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Poco_Fundo,2023-12-31T00:00:00,1.380160799652325,1.1455546617507937,-16.998464089157654,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Pocos_de_Caldas,2023-12-31T00:00:00,1.5,1.356615662574768,-9.558955828348797,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Pouso_Alegre,2023-12-31T00:00:00,1.566666666666667,1.3873435258865356,-11.446157922136049,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Pouso_Alto,2023-12-31T00:00:00,1.8000000000000005,1.5196044445037842,-15.577530860900891,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Santa_Rita_de_Caldas,2023-12-31T00:00:00,1.68,1.7891464233398438,6.496810913085942,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Santa_Rita_do_Sapucai,2023-12-31T00:00:00,1.3799999999999997,1.4329357147216797,3.83592135664348,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Bento_Abade,2023-12-31T00:00:00,1.5,1.5306230783462524,2.041538556416829,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Goncalo_do_Sapucai,2023-12-31T00:00:00,1.2,1.5662727355957031,30.5227279663086,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Joao_da_Mata,2023-12-31T00:00:00,1.08,1.135190486907959,5.110230269255454,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Joao_del_Rei,2023-12-31T00:00:00,1.799568965517241,1.5891273021697998,-11.694003807570391,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Lourenco,2023-12-31T00:00:00,1.5,1.7657294273376465,17.7152951558431,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Sebastiao_da_Bela_Vista,2023-12-31T00:00:00,1.5,1.356757402420044,-9.549506505330402,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Tome_das_Letras,2023-12-31T00:00:00,1.09812734082397,1.3727450370788574,25.00781886086457,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Senador_Jose_Bento,2023-12-31T00:00:00,1.2,1.2543768882751465,4.531407356262212,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Serrania,2023-12-31T00:00:00,0.9,1.3130161762237549,45.89068624708387,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Silvianopolis,2023-12-31T00:00:00,1.13974358974359,1.026565670967102,-9.93012110749837,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Soledade_de_Minas,2023-12-31T00:00:00,1.5,1.7748050689697266,18.320337931315105,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Tocos_do_Moji,2023-12-31T00:00:00,1.5,1.3900240659713743,-7.331728935241699,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Tres_Coracoes,2023-12-31T00:00:00,1.44,1.569016456604004,8.959476153055832,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Turvolandia,2023-12-31T00:00:00,1.259748427672956,1.5956155061721802,26.661440579818592,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Virginia,2023-12-31T00:00:00,1.5,1.460351586341858,-2.6432275772094727,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Aiuruoca,2024-12-31T00:00:00,1.8000000000000005,1.5279316902160645,-15.11490609910754,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Albertina,2024-12-31T00:00:00,1.56,1.5183894634246826,-2.667342088161374,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Baependi,2024-12-31T00:00:00,1.439779005524862,1.257557034492493,-12.656245877536012,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Bandeira_do_Sul,2024-12-31T00:00:00,1.5,1.440232753753662,-3.984483083089193,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Borda_da_Mata,2024-12-31T00:00:00,1.5,1.3758889436721802,-8.274070421854656,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Brazopolis,2024-12-31T00:00:00,1.501216545012166,1.3393332958221436,-10.783470894181391,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Bueno_Brandao,2024-12-31T00:00:00,1.8000000000000005,1.41705322265625,-21.27482096354168,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Cachoeira_de_Minas,2024-12-31T00:00:00,1.73984375,1.649325609207153,-5.202659192404294,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Caldas,2024-12-31T00:00:00,1.68,1.412098050117493,-15.946544635863528,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Cambuquira,2024-12-31T00:00:00,1.7400000000000002,1.4410046339035034,-17.18364172968372,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Campanha,2024-12-31T00:00:00,1.5689448441247,1.3947575092315674,-11.102196201824428,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Careacu,2024-12-31T00:00:00,1.560169491525424,1.2705326080322266,-18.56444989255693,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Carmo_da_Cachoeira,2024-12-31T00:00:00,1.44,1.4759948253631592,2.4996406502193915,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Carmo_de_Minas,2024-12-31T00:00:00,1.56,1.3743948936462402,-11.897763227805116,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Carrancas,2024-12-31T00:00:00,1.6428571428571432,1.4361670017242432,-12.581139025480873,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Carvalhopolis,2024-12-31T00:00:00,1.62,1.5035192966461182,-7.190166873696416,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Conceicao_das_Pedras,2024-12-31T00:00:00,1.5598885793871868,1.5197607278823853,-2.5724819089685296,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Conceicao_do_Rio_Verde,2024-12-31T00:00:00,1.5,1.5443964004516602,2.959760030110677,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Conceicao_dos_Ouros,2024-12-31T00:00:00,1.8000000000000005,1.3639332056045532,-24.22593302196928,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Congonhal,2024-12-31T00:00:00,1.8000000000000005,1.3804227113723757,-23.309849368201373,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Cordislandia,2024-12-31T00:00:00,1.439887640449438,1.3717032670974731,-4.735395418123199,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Cristina,2024-12-31T00:00:00,1.619736842105263,1.5533115863800049,-4.100990605296191,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Datas,2024-12-31T00:00:00,1.0,1.0963891744613647,9.638917446136476,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Dom_Vicoso,2024-12-31T00:00:00,1.2,1.3303029537200928,10.858579476674402,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Fama,2024-12-31T00:00:00,1.679838709677419,1.5335067510604858,-8.711071948391606,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Fortaleza_de_Minas,2024-12-31T00:00:00,1.5598425196850392,1.4489080905914309,-7.111899290705846,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Heliodora,2024-12-31T00:00:00,1.5601255886970171,1.3471800088882446,-13.64925883861824,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Ibitiura_de_Minas,2024-12-31T00:00:00,1.360264900662252,1.397220253944397,2.7167762149970227,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Inconfidentes,2024-12-31T00:00:00,1.8000000000000005,1.7308204174041748,-3.843310144212525,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Ingai,2024-12-31T00:00:00,1.621004566210046,1.496058464050293,-7.707942640277725,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Itajuba,2024-12-31T00:00:00,1.068965517241379,1.3251721858978271,23.967720616248386,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Itutinga,2024-12-31T00:00:00,1.8000000000000005,1.4786503314971924,-17.8527593612671,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Jesuania,2024-12-31T00:00:00,1.5,1.2925596237182615,-13.829358418782553,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Lambari,2024-12-31T00:00:00,1.56,1.3783934116363523,-11.641447972028686,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Luminarias,2024-12-31T00:00:00,1.380229885057471,1.4713482856750488,6.601682922825843,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Maria_da_Fe,2024-12-31T00:00:00,1.477777777777778,1.378957748413086,-6.687069656257362,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Monsenhor_Paulo,2024-12-31T00:00:00,1.5899728997289972,1.468313217163086,-7.651682779413887,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Monte_Siao,2024-12-31T00:00:00,1.5,1.4534865617752075,-3.100895881652832,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Natercia,2024-12-31T00:00:00,1.8000000000000005,1.4565640687942505,-19.079773955874984,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Olimpio_Noronha,2024-12-31T00:00:00,1.5,1.2717019319534302,-15.219871203104654,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Ouro_Fino,2024-12-31T00:00:00,1.5,1.425455927848816,-4.969604810078939,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Paraisopolis,2024-12-31T00:00:00,1.5066666666666668,1.339014768600464,-11.12733836722586,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Pedralva,2024-12-31T00:00:00,1.5600790513833993,1.5020456314086914,-3.719902521814314,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Pirangucu,2024-12-31T00:00:00,1.333333333333333,1.2436027526855469,-6.729793548583964,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Piranguinho,2024-12-31T00:00:00,1.6807610993657498,1.418030858039856,-15.63162316316325,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Poco_Fundo,2024-12-31T00:00:00,1.380192991366176,1.337887406349182,-3.065193439007239,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Pocos_de_Caldas,2024-12-31T00:00:00,1.7400000000000002,1.4597090482711792,-16.10867538671385,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Pouso_Alegre,2024-12-31T00:00:00,1.7878787878787883,1.4609556198120115,-18.285533129158686,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Pouso_Alto,2024-12-31T00:00:00,1.53,1.5585882663726809,1.8685141420052704,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Santa_Rita_de_Caldas,2024-12-31T00:00:00,1.8000000000000005,1.7458356618881226,-3.0091298951043166,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Santa_Rita_do_Sapucai,2024-12-31T00:00:00,1.5,1.4254119396209717,-4.972537358601889,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Bento_Abade,2024-12-31T00:00:00,1.5,1.4310578107833862,-4.596145947774252,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Goncalo_do_Sapucai,2024-12-31T00:00:00,1.5,1.4633971452713013,-2.440190315246582,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Joao_da_Mata,2024-12-31T00:00:00,1.32,1.168182611465454,-11.501317313223176,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Joao_del_Rei,2024-12-31T00:00:00,1.80168776371308,1.6539394855499268,-8.200548460109427,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Lourenco,2024-12-31T00:00:00,1.3799999999999997,1.602804183959961,16.14523072173633,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Sebastiao_da_Bela_Vista,2024-12-31T00:00:00,1.44,1.3958539962768557,-3.0656947029961445,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Sao_Tome_das_Letras,2024-12-31T00:00:00,2.1,1.262708306312561,-39.87103303273519,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Senador_Jose_Bento,2024-12-31T00:00:00,0.9,1.2981295585632324,44.23661761813693,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Serrania,2024-12-31T00:00:00,1.32,1.3808273077011108,4.60812937129627,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Silvianopolis,2024-12-31T00:00:00,1.56025641025641,1.0927557945251465,-29.96306329255428,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Soledade_de_Minas,2024-12-31T00:00:00,1.5,1.613539695739746,7.569313049316406,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Tocos_do_Moji,2024-12-31T00:00:00,1.5,1.402395725250244,-6.506951649983724,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Tres_Coracoes,2024-12-31T00:00:00,1.56,1.436660647392273,-7.906368756905584,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Turvolandia,2024-12-31T00:00:00,1.44,1.593456506729126,10.656701856189308,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_3_2024,Virginia,2024-12-31T00:00:00,1.6599999999999997,1.490109920501709,-10.23434213845125,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:05:38
V43_cluster_4_2024,Abadia_dos_Dourados,2023-12-31T00:00:00,2.103030303030303,1.9804368019104004,-5.829373972560211,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Acucena,2023-12-31T00:00:00,1.6666666666666672,0.9351407885551452,-43.891552686691305,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Agua_Boa,2023-12-31T00:00:00,1.213636363636364,1.016255259513855,-16.263611575637444,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Aguas_Vermelhas,2023-12-31T00:00:00,3.0,3.0861403942108154,2.871346473693848,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Angelandia,2023-12-31T00:00:00,2.095663265306122,1.6859548091888428,-19.55030003627188,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Aricanduva,2023-12-31T00:00:00,1.2,1.0515810251235962,-12.36824790636698,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Ataleia,2023-12-31T00:00:00,0.6833333333333333,0.8291003704071045,21.3317615229909,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Bandeira,2023-12-31T00:00:00,0.95,1.1199733018875122,17.89192651447496,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Berilo,2023-12-31T00:00:00,1.7988826815642458,1.339508295059204,-25.536650678385858,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Berizal,2023-12-31T00:00:00,3.570967741935484,2.9192028045654297,-18.251773313885884,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Bonfinopolis_de_Minas,2023-12-31T00:00:00,3.0,2.986006021499634,-0.466465950012207,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Buritis,2023-12-31T00:00:00,3.0,2.9925026893615723,-0.2499103546142578,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Buritizeiro,2023-12-31T00:00:00,3.0,2.752472162246704,-8.250927925109863,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Capelinha,2023-12-31T00:00:00,1.541750580945004,1.423071026802063,-7.697714248318775,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Carai,2023-12-31T00:00:00,1.2,1.2676186561584473,5.634888013203943,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Caranaiba,2023-12-31T00:00:00,1.45,2.039522171020508,40.6567014496902,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Catuji,2023-12-31T00:00:00,1.384615384615385,1.2263087034225464,-11.433260308371676,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Congonhas_do_Norte,2023-12-31T00:00:00,1.111111111111111,0.9019574522972108,-18.823829293251023,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Coroaci,2023-12-31T00:00:00,2.4,1.753332257270813,-26.94448928038279,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Cuparaque,2023-12-31T00:00:00,1.318367346938776,1.1489360332489014,-12.85160119319482,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Diamantina,2023-12-31T00:00:00,2.965183752417796,2.4558136463165283,-17.178365613460862,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Formoso,2023-12-31T00:00:00,3.3803921568627446,3.074944257736206,-9.035871725901083,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Franciscopolis,2023-12-31T00:00:00,1.2,1.461043357849121,21.75361315409343,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Frei_Gaspar,2023-12-31T00:00:00,1.2,1.1730130910873413,-2.2489090760548875,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Grao_Mogol,2023-12-31T00:00:00,1.155555555555555,1.197149395942688,3.599466956578818,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Indaiabira,2023-12-31T00:00:00,1.9320754716981128,2.4984521865844727,29.31441981345418,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Itabirinha,2023-12-31T00:00:00,1.027027027027027,0.913703203201294,-11.034161793558216,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Itacambira,2023-12-31T00:00:00,0.75,0.789989709854126,5.331961313883463,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Itaipe,2023-12-31T00:00:00,0.9598214285714286,0.8979977369308472,-6.441166012786159,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Itamarandiba,2023-12-31T00:00:00,2.4,1.7296727895736694,-27.93030043443044,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Itambacuri,2023-12-31T00:00:00,0.8987341772151899,0.9814310669898988,9.20148491859436,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Jequitinhonha,2023-12-31T00:00:00,2.7000000000000006,2.178070306777954,-19.33072937859431,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Joao_Pinheiro,2023-12-31T00:00:00,3.3,2.4321603775024414,-26.29817037871389,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Jose_Goncalves_de_Minas,2023-12-31T00:00:00,1.3210526315789468,1.4469780921936035,9.53220618198597,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Juiz_de_Fora,2023-12-31T00:00:00,0.7142857142857143,1.239362359046936,73.51073026657104,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Ladainha,2023-12-31T00:00:00,1.081818181818182,0.8685832023620605,-19.710796420313745,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Malacacheta,2023-12-31T00:00:00,1.619230769230769,1.6601781845092771,2.5288189958223666,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Mantena,2023-12-31T00:00:00,1.2,0.6964080333709717,-41.96599721908569,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Minas_Novas,2023-12-31T00:00:00,1.26,1.4567291736602783,15.613426480974468,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Monte_Formoso,2023-12-31T00:00:00,0.6000000000000001,0.8790823817253113,46.51373028755186,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Ninheira,2023-12-31T00:00:00,3.0,2.706968307495117,-9.767723083496094,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Nova_Belem,2023-12-31T00:00:00,0.96,1.0032292604446411,4.503047962983466,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Novo_Cruzeiro,2023-12-31T00:00:00,1.209891435464415,1.1704177856445312,-3.262577836558688,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Novorizonte,2023-12-31T00:00:00,1.333333333333333,1.3508179187774658,1.3113439083099592,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Ouro_Verde_de_Minas,2023-12-31T00:00:00,2.5,1.706202507019043,-31.75189971923828,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Padre_Paraiso,2023-12-31T00:00:00,0.7212121212121212,0.6059606671333313,-15.980243632773387,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Paracatu,2023-12-31T00:00:00,2.4,2.558174133300781,6.590588887532556,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Pedra_Azul,2023-12-31T00:00:00,1.166666666666667,1.294284462928772,10.93866825103757,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Pirapora,2023-12-31T00:00:00,3.6000000000000005,2.979663372039795,-17.2315729988946,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Pote,2023-12-31T00:00:00,1.125,0.8088435530662537,-28.10279528299968,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Rio_Pardo_de_Minas,2023-12-31T00:00:00,2.568224299065421,2.7323336601257324,6.389993316394942,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Santa_Barbara_do_Monte_Verde,2023-12-31T00:00:00,1.4,1.2318134307861328,-12.01332637241908,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Santa_Maria_do_Suacui,2023-12-31T00:00:00,0.6666666666666667,0.8550801277160645,28.26201915740965,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Santo_Antonio_do_Retiro,2023-12-31T00:00:00,1.02,1.264288306236267,23.949833944732067,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Sao_Goncalo_do_Rio_Preto,2023-12-31T00:00:00,2.868421052631579,2.915287494659424,1.6338759606037572,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Sao_Joao_do_Manteninha,2023-12-31T00:00:00,1.2,0.9301419258117676,-22.488172849019367,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Sao_Joao_do_Paraiso,2023-12-31T00:00:00,3.601190476190476,2.822765827178955,-21.61575884858438,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Sao_Sebastiao_do_Maranhao,2023-12-31T00:00:00,1.2,0.9745771884918212,-18.785234292348225,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Senador_Modestino_Goncalves,2023-12-31T00:00:00,2.7000000000000006,2.523620128631592,-6.532587828459585,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Setubinha,2023-12-31T00:00:00,1.2,0.9817134737968444,-18.19054385026296,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Taiobeiras,2023-12-31T00:00:00,3.0,3.0107192993164062,0.3573099772135416,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Teofilo_Otoni,2023-12-31T00:00:00,1.2,0.850148618221283,-29.15428181489309,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Turmalina,2023-12-31T00:00:00,1.360606060606061,1.25626540184021,-7.66868984247903,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Urucuia,2023-12-31T00:00:00,2.0994575045207946,2.103930950164795,0.2130762653860617,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Vargem_Grande_do_Rio_Pardo,2023-12-31T00:00:00,2.1,1.7715234756469729,-15.641739254906067,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Varzea_da_Palma,2023-12-31T00:00:00,3.3,2.791766405105591,-15.401018027103303,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Abadia_dos_Dourados,2024-12-31T00:00:00,2.6116071428571423,2.329615354537964,-10.797634287777091,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Acucena,2024-12-31T00:00:00,1.6666666666666672,1.293596267700195,-22.384223937988303,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Agua_Boa,2024-12-31T00:00:00,1.7064935064935067,1.1520546674728394,-32.48994718766468,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Aguas_Vermelhas,2024-12-31T00:00:00,3.0,3.212400197982788,7.0800065994262695,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Angelandia,2024-12-31T00:00:00,1.870967741935484,2.058422565460205,10.019137119424748,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Aricanduva,2024-12-31T00:00:00,1.320245398773006,1.1885579824447632,-9.974465084341816,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Ataleia,2024-12-31T00:00:00,0.7529411764705883,0.9004834890365601,19.595463387668115,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Bandeira,2024-12-31T00:00:00,1.15,1.19036602973938,3.5100895425547805,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Berilo,2024-12-31T00:00:00,1.681818181818182,1.80792236328125,7.4980864653716175,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Berizal,2024-12-31T00:00:00,3.5516129032258075,4.036036491394043,13.639537904827698,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Bonfinopolis_de_Minas,2024-12-31T00:00:00,2.1,3.236259937286377,54.10761606125604,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Buritis,2024-12-31T00:00:00,2.69967707212056,3.1209259033203125,15.603674807997209,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Buritizeiro,2024-12-31T00:00:00,2.7000000000000006,3.091662168502808,14.506006240844702,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Capelinha,2024-12-31T00:00:00,1.62007678089009,1.6353332996368408,0.9417157832710068,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Carai,2024-12-31T00:00:00,1.2,1.3389452695846558,11.578772465387985,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Caranaiba,2024-12-31T00:00:00,1.5,2.541422128677368,69.42814191182455,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Catuji,2024-12-31T00:00:00,1.138461538461538,1.411740779876709,24.00425769187314,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Congonhas_do_Norte,2024-12-31T00:00:00,1.2,1.0293289422988892,-14.222588141759235,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Coroaci,2024-12-31T00:00:00,2.1,2.169696807861328,3.318895612444192,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Cuparaque,2024-12-31T00:00:00,1.020408163265306,1.2938621044158936,26.7984862327576,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Diamantina,2024-12-31T00:00:00,2.967637540453075,2.966256618499756,-0.0465327026800029,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Formoso,2024-12-31T00:00:00,3.6000000000000005,3.2660470008850098,-9.27647219763863,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Franciscopolis,2024-12-31T00:00:00,0.9,1.858741998672485,106.52688874138724,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Frei_Gaspar,2024-12-31T00:00:00,1.2,1.2839306592941284,6.99422160784404,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Grao_Mogol,2024-12-31T00:00:00,2.0333333333333337,1.145606279373169,-43.65870757181137,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Indaiabira,2024-12-31T00:00:00,2.511111111111111,2.5113799571990967,0.0107062601410197,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Itabirinha,2024-12-31T00:00:00,0.8918918918918919,1.0024961233139038,12.401080492771037,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Itacambira,2024-12-31T00:00:00,0.5,0.7361391186714172,47.22782373428345,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Itaipe,2024-12-31T00:00:00,0.9,0.9637978076934814,7.088645299275713,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Itamarandiba,2024-12-31T00:00:00,2.1352380952380954,2.1229898929595947,-0.5736223190198788,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Itambacuri,2024-12-31T00:00:00,1.084388185654009,1.0321903228759766,-4.813577228946954,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Jequitinhonha,2024-12-31T00:00:00,2.4,2.546395778656006,6.099824110666915,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Joao_Pinheiro,2024-12-31T00:00:00,3.0,2.8500802516937256,-4.9973249435424805,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Jose_Goncalves_de_Minas,2024-12-31T00:00:00,1.5,1.5143762826919556,0.9584188461303712,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Juiz_de_Fora,2024-12-31T00:00:00,1.166666666666667,1.204776644706726,3.26656954629078,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Ladainha,2024-12-31T00:00:00,1.12,1.0972137451171875,-2.034487043108268,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Malacacheta,2024-12-31T00:00:00,1.5,1.7254191637039185,15.027944246927897,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Mantena,2024-12-31T00:00:00,1.2,0.9906442165374756,-17.446315288543698,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Minas_Novas,2024-12-31T00:00:00,1.6204545454545451,1.672067165374756,3.1850705140101985,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Monte_Formoso,2024-12-31T00:00:00,0.6800000000000002,0.8752477765083313,28.71290831004869,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Ninheira,2024-12-31T00:00:00,2.819758276405675,2.9677250385284424,5.247498105099261,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Nova_Belem,2024-12-31T00:00:00,0.9,1.0581648349761963,17.573870552910694,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Novo_Cruzeiro,2024-12-31T00:00:00,1.7997542997542997,1.2180840969085691,-32.319422874841266,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Novorizonte,2024-12-31T00:00:00,1.333333333333333,1.4588059186935425,9.410443902015713,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Ouro_Verde_de_Minas,2024-12-31T00:00:00,2.5,2.254493236541748,-9.820270538330078,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Padre_Paraiso,2024-12-31T00:00:00,0.7212121212121212,0.6785712242126465,-5.912393281439771,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Paracatu,2024-12-31T00:00:00,2.7003236245954687,2.618313789367676,-3.0370372825249303,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Pedra_Azul,2024-12-31T00:00:00,0.9,1.3393261432647705,48.81401591830783,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Pirapora,2024-12-31T00:00:00,2.7000000000000006,3.500294685363769,29.64054390236181,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Pote,2024-12-31T00:00:00,1.125,1.0291668176651,-8.518505096435547,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Rio_Pardo_de_Minas,2024-12-31T00:00:00,3.064285714285715,2.8785226345062256,-6.062198407722262,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Santa_Barbara_do_Monte_Verde,2024-12-31T00:00:00,1.3,1.5044782161712646,15.72909355163574,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Santa_Maria_do_Suacui,2024-12-31T00:00:00,1.333333333333333,0.862877607345581,-35.28417944908141,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Santo_Antonio_do_Retiro,2024-12-31T00:00:00,1.9666666666666672,1.3875272274017334,-29.447768098216965,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Sao_Goncalo_do_Rio_Preto,2024-12-31T00:00:00,2.5238095238095246,3.328935384750366,31.90121335803334,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Sao_Joao_do_Manteninha,2024-12-31T00:00:00,0.9,1.1470117568969729,27.44575076633029,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Sao_Joao_do_Paraiso,2024-12-31T00:00:00,3.5396226415094336,3.4603450298309326,-2.239719306482171,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Sao_Sebastiao_do_Maranhao,2024-12-31T00:00:00,1.380952380952381,1.1371835470199585,-17.65222590545128,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Senador_Modestino_Goncalves,2024-12-31T00:00:00,2.706666666666667,2.9383299350738525,8.558987749033948,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Setubinha,2024-12-31T00:00:00,1.020238095238095,1.1644879579544067,14.138843020035234,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Taiobeiras,2024-12-31T00:00:00,3.1206349206349207,3.2907280921936035,5.4505950194288,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Teofilo_Otoni,2024-12-31T00:00:00,1.05,1.0177096128463743,-3.0752749670119552,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Turmalina,2024-12-31T00:00:00,1.8507692307692305,1.4326447248458862,-22.591930910238887,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Urucuia,2024-12-31T00:00:00,1.920433996383363,2.2299225330352783,16.115551861441546,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Vargem_Grande_do_Rio_Pardo,2024-12-31T00:00:00,1.8000000000000005,1.9587759971618648,8.820888731214719,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_4_2024,Varzea_da_Palma,2024-12-31T00:00:00,3.0,3.230691909790039,7.689730326334636,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2024_(2024)
    Modelo LSTM treinado com dados de 2012 a 2022, validado com os dados de 2023 e testado com os dados de 2024.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:13
V43_cluster_0_2025,Aguanil,2024-12-31T00:00:00,2.025039123630673,1.6228599548339844,-19.86031598617341,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Alfenas,2024-12-31T00:00:00,1.635197497066875,1.3627161979675293,-16.66351004010875,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Alto_Caparao,2024-12-31T00:00:00,1.14,1.3026200532913208,14.264916955379029,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Alto_Jequitiba,2024-12-31T00:00:00,1.02,1.0198010206222534,-0.0195077821320195,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Amparo_do_Serra,2024-12-31T00:00:00,1.680555555555556,1.264939546585083,-24.73086995526781,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Araponga,2024-12-31T00:00:00,1.5,1.157994031906128,-22.800397872924805,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Astolfo_Dutra,2024-12-31T00:00:00,0.8749999999999999,0.722527265548706,-17.425455365862156,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Bambui,2024-12-31T00:00:00,1.8000000000000005,1.3743209838867188,-23.64883422851564,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Boa_Esperanca,2024-12-31T00:00:00,1.083893395133256,1.1572731733322144,6.770018022845944,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Bom_Jesus_do_Galho,2024-12-31T00:00:00,0.9,0.9579593539237976,6.439928213755287,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Bom_Sucesso,2024-12-31T00:00:00,1.6799426934097417,1.399526596069336,-16.69200374753567,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Caete,2024-12-31T00:00:00,1.8000000000000005,1.1821032762527466,-34.32759576373631,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Caiana,2024-12-31T00:00:00,1.14,0.9835714101791382,-13.721806124636991,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Cajuri,2024-12-31T00:00:00,1.32,1.001296043395996,-24.144239136666968,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Camacho,2024-12-31T00:00:00,1.5,1.444031000137329,-3.731266657511393,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Campo_do_Meio,2024-12-31T00:00:00,1.372340425531915,1.159602403640747,-15.501840354860294,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Campos_Altos,2024-12-31T00:00:00,1.5,1.2527583837509155,-16.48277441660563,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Campos_Gerais,2024-12-31T00:00:00,1.611315789473684,1.4891395568847656,-7.582389087667647,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Cana_Verde,2024-12-31T00:00:00,1.2,1.144252061843872,-4.645661513010657,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Canaa,2024-12-31T00:00:00,1.319791666666667,1.2890552282333374,-2.32888562715046,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Candeias,2024-12-31T00:00:00,1.14003294892916,1.0688377618789673,-6.245011349633961,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Caparao,2024-12-31T00:00:00,1.6799283154121862,1.365990400314331,-18.687578048282823,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Capitolio,2024-12-31T00:00:00,1.32,1.147857427597046,-13.04110396992077,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Caputira,2024-12-31T00:00:00,1.38008658008658,1.2503474950790403,-9.40079317338194,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Carangola,2024-12-31T00:00:00,1.44,1.0662944316864014,-25.95177557733324,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Caratinga,2024-12-31T00:00:00,1.6200335289186922,1.2088894844055176,-25.37873674673862,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Carmo_da_Mata,2024-12-31T00:00:00,1.62,1.1959336996078491,-26.17693212297228,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Carmo_do_Rio_Claro,2024-12-31T00:00:00,1.7634782608695652,1.6162443161010742,-8.349064915373008,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Carmopolis_de_Minas,2024-12-31T00:00:00,1.98,1.5867364406585691,-19.86179592633487,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Cassia,2024-12-31T00:00:00,1.7162790697674415,1.391035556793213,-18.95050278847133,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Catas_Altas_da_Noruega,2024-12-31T00:00:00,0.9,0.9781399369239808,8.682215213775631,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Chale,2024-12-31T00:00:00,1.320168067226891,1.257115364074707,-4.776111823749131,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Claudio,2024-12-31T00:00:00,2.699367088607595,1.378864049911499,-48.91898713106288,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Conceicao_da_Barra_de_Minas,2024-12-31T00:00:00,1.8000000000000005,1.4794265031814575,-17.80963871214126,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Conceicao_de_Ipanema,2024-12-31T00:00:00,1.2901734104046243,1.2983155250549316,0.6310868434153988,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Coqueiral,2024-12-31T00:00:00,0.9,1.2879462242126465,43.10513602362738,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Corrego_Danta,2024-12-31T00:00:00,1.5,1.2664332389831543,-15.571117401123049,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Cristais,2024-12-31T00:00:00,1.439664804469274,1.254984736442566,-12.8279907554446,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Desterro_de_Entre_Rios,2024-12-31T00:00:00,1.3780487804878048,1.580680012702942,14.704213311186942,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Divinesia,2024-12-31T00:00:00,1.316666666666667,1.8917180299758911,43.67478708677647,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Divino,2024-12-31T00:00:00,1.2,1.0452094078063965,-12.899216016133623,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Doresopolis,2024-12-31T00:00:00,1.5615384615384622,1.3140547275543213,-15.848712028541035,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Durande,2024-12-31T00:00:00,1.380095693779904,1.2899553775787354,-6.53145405839837,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Eloi_Mendes,2024-12-31T00:00:00,1.421623345558922,1.182523488998413,-16.818790807526096,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Entre_Folhas,2024-12-31T00:00:00,1.2,0.9720619320869446,-18.994838992754616,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Entre_Rios_de_Minas,2024-12-31T00:00:00,1.88,1.6665799617767334,-11.352129692726942,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ervalia,2024-12-31T00:00:00,1.32,1.1840975284576416,-10.295641783512004,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Espera_Feliz,2024-12-31T00:00:00,1.44,1.0225659608840942,-28.988474938604565,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Faria_Lemos,2024-12-31T00:00:00,1.37956204379562,0.9745198488235474,-29.36020143448357,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ferros,2024-12-31T00:00:00,1.205128205128205,0.9936575293540956,-17.5475667131708,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Fervedouro,2024-12-31T00:00:00,1.56,1.1635783910751345,-25.411641597747803,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Guape,2024-12-31T00:00:00,1.7459340659340663,1.3519692420959473,-22.56470227169488,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ibituruna,2024-12-31T00:00:00,1.8000000000000005,1.4322006702423096,-20.43329609764948,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ilicinea,2024-12-31T00:00:00,1.5,1.308824062347412,-12.745062510172524,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Itapecerica,2024-12-31T00:00:00,1.615189873417721,0.9672812223434448,-40.11346664174595,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ituiutaba,2024-12-31T00:00:00,1.0,0.6800475120544434,-31.995248794555664,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Itumirim,2024-12-31T00:00:00,1.62116991643454,1.309504508972168,-19.224721869242536,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Lajinha,2024-12-31T00:00:00,1.564997053624043,1.204615592956543,-23.027612725082736,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Lavras,2024-12-31T00:00:00,1.55996015936255,1.2993725538253784,-16.704760308984824,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Luisburgo,2024-12-31T00:00:00,1.2,1.4369460344314575,19.74550286928813,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Machado,2024-12-31T00:00:00,1.3347736360118658,1.2353734970092771,-7.446966011374294,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Manhuacu,2024-12-31T00:00:00,1.5,1.0656123161315918,-28.959178924560547,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Manhumirim,2024-12-31T00:00:00,1.56,1.2786076068878174,-18.037973917447605,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Martins_Soares,2024-12-31T00:00:00,1.2,1.2617883682250977,5.149030685424809,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Matipo,2024-12-31T00:00:00,1.2,1.1783937215805054,-1.8005232016245487,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Medeiros,2024-12-31T00:00:00,1.8600609756097564,1.3985991477966309,-24.80896238693741,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Miradouro,2024-12-31T00:00:00,1.13996383363472,1.0699198246002195,-6.144406249377956,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Mirai,2024-12-31T00:00:00,1.2,1.0634386539459229,-11.380112171173092,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Moeda,2024-12-31T00:00:00,1.5,1.0818556547164917,-27.87628968556722,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Muriae,2024-12-31T00:00:00,1.170285714285714,0.9148332476615906,-21.8282137007918,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Mutum,2024-12-31T00:00:00,1.15997150997151,1.188676834106445,2.4746576866909726,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Nazareno,2024-12-31T00:00:00,1.619811320754717,1.4390130043029783,-11.161689891604118,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Nepomuceno,2024-12-31T00:00:00,1.3800383877159308,1.1725585460662842,-15.034352920648942,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Oliveira,2024-12-31T00:00:00,1.8240227434257288,1.5367546081542969,-15.749153145530888,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Orizania,2024-12-31T00:00:00,1.5,1.2329381704330444,-17.80412197113037,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Paraguacu,2024-12-31T00:00:00,1.323316582914573,1.1384648084640503,-13.968824757216533,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Passa_Tempo,2024-12-31T00:00:00,1.5,1.4889647960662842,-0.7356802622477214,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Perdoes,2024-12-31T00:00:00,1.6799401197604789,1.4074264764785769,-16.221628382847147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Pimenta,2024-12-31T00:00:00,1.715219421101774,1.2566217184066772,-26.736970037367914,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Piranga,2024-12-31T00:00:00,1.8000000000000005,1.984251856803894,10.236214266882984,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Piumhi,2024-12-31T00:00:00,1.3800316957210783,1.3399319648742676,-2.90571085947836,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ponte_Nova,2024-12-31T00:00:00,2.0,1.2067012786865234,-39.66493606567381,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Porto_Firme,2024-12-31T00:00:00,1.3810526315789473,1.1717249155044556,-15.157113587710914,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Raul_Soares,2024-12-31T00:00:00,1.5,1.0542713403701782,-29.715243975321453,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Reduto,2024-12-31T00:00:00,1.2,1.0746139287948608,-10.448839267094929,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ribeirao_Vermelho,2024-12-31T00:00:00,1.43859649122807,1.3239401578903198,-7.970013414941171,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ritapolis,2024-12-31T00:00:00,1.8000000000000005,1.7745826244354248,-1.4120764202541922,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Rosario_da_Limeira,2024-12-31T00:00:00,1.259493670886076,0.9838405251502992,-21.886028656408417,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santa_Barbara_do_Leste,2024-12-31T00:00:00,1.4101226993865028,1.0897016525268557,-22.72291957281816,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santa_Margarida,2024-12-31T00:00:00,1.5,1.1272668838500977,-24.84887440999349,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santa_Rita_de_Minas,2024-12-31T00:00:00,1.200173310225303,1.0747984647750854,-10.446395064949533,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santa_Rita_do_Itueto,2024-12-31T00:00:00,1.365238095238095,1.2760851383209229,-6.530213098223278,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santana_da_Vargem,2024-12-31T00:00:00,1.44,1.2635939121246338,-12.25042276912265,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santana_do_Jacare,2024-12-31T00:00:00,1.2,1.0374585390090942,-13.545121749242146,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santana_do_Manhuacu,2024-12-31T00:00:00,1.08,1.293125867843628,19.733876652187764,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Domingos_das_Dores,2024-12-31T00:00:00,1.41,1.1814253330230713,-16.21096928914389,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Francisco_de_Paula,2024-12-31T00:00:00,1.62,1.4549627304077148,-10.18748577730156,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Francisco_do_Gloria,2024-12-31T00:00:00,1.25,0.9001010060310364,-27.99191951751709,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Joao_do_Manhuacu,2024-12-31T00:00:00,1.32,1.087680101394653,-17.599992318586875,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Jose_do_Mantimento,2024-12-31T00:00:00,1.44,1.44862163066864,0.5987243519889022,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Roque_de_Minas,2024-12-31T00:00:00,1.58,1.3100489377975464,-17.08551026597808,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Tiago,2024-12-31T00:00:00,1.621052631578947,1.4700090885162354,-9.317621162959492,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Tomas_de_Aquino,2024-12-31T00:00:00,1.619975932611312,1.2140129804611206,-25.05981378969016,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Senador_Firmino,2024-12-31T00:00:00,1.804347826086957,1.3744679689407349,-23.82466678159785,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Senhora_de_Oliveira,2024-12-31T00:00:00,1.8000000000000005,1.4213379621505735,-21.03677988052369,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sericita,2024-12-31T00:00:00,1.3799999999999997,1.002985596656799,-27.31988430023192,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Simonesia,2024-12-31T00:00:00,1.2,1.236523151397705,3.0435959498087604,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Tapirai,2024-12-31T00:00:00,1.9163050216986977,1.395897388458252,-27.156826671525053,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Tombos,2024-12-31T00:00:00,1.5,0.9805126786231996,-34.6324880917867,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Tres_Pontas,2024-12-31T00:00:00,1.387228956803825,1.273818016052246,-8.17535852285535,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ubaporanga,2024-12-31T00:00:00,1.440056417489422,1.2904211282730105,-10.390932424528486,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Vargem_Bonita,2024-12-31T00:00:00,2.187804878048781,1.3200488090515137,-39.663320879473766,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Vermelho_Novo,2024-12-31T00:00:00,1.8000000000000005,1.039003849029541,-42.27756394280328,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Vicosa,2024-12-31T00:00:00,1.32,0.9645558595657348,-26.92758639653524,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Vieiras,2024-12-31T00:00:00,1.44,1.065856695175171,-25.98217394616869,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Aguanil,2025-12-31T00:00:00,0.0,1.6243727207183838,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Alfenas,2025-12-31T00:00:00,0.0,1.220497488975525,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Alto_Caparao,2025-12-31T00:00:00,0.0,1.2942723035812378,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Alto_Jequitiba,2025-12-31T00:00:00,0.0,0.9489879608154296,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Amparo_do_Serra,2025-12-31T00:00:00,0.0,1.30638325214386,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Araponga,2025-12-31T00:00:00,0.0,1.1538411378860474,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Astolfo_Dutra,2025-12-31T00:00:00,0.0,0.5248205661773682,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Bambui,2025-12-31T00:00:00,0.0,1.3352553844451904,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Boa_Esperanca,2025-12-31T00:00:00,0.0,0.9268197417259216,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Bom_Jesus_do_Galho,2025-12-31T00:00:00,0.0,0.77126145362854,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Bom_Sucesso,2025-12-31T00:00:00,0.0,1.4072712659835815,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Caete,2025-12-31T00:00:00,0.0,1.1747969388961792,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Caiana,2025-12-31T00:00:00,0.0,0.9140902757644652,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Cajuri,2025-12-31T00:00:00,0.0,0.9241864085197448,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Camacho,2025-12-31T00:00:00,0.0,1.398670673370361,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Campo_do_Meio,2025-12-31T00:00:00,0.0,0.9757663607597352,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Campos_Altos,2025-12-31T00:00:00,0.0,1.168701410293579,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Campos_Gerais,2025-12-31T00:00:00,0.0,1.3174086809158323,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Cana_Verde,2025-12-31T00:00:00,0.0,1.1122545003890991,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Canaa,2025-12-31T00:00:00,0.0,1.2089484930038452,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Candeias,2025-12-31T00:00:00,0.0,0.9717091917991638,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Caparao,2025-12-31T00:00:00,0.0,1.3330715894699097,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Capitolio,2025-12-31T00:00:00,0.0,1.043427348136902,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Caputira,2025-12-31T00:00:00,0.0,1.2914975881576538,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Carangola,2025-12-31T00:00:00,0.0,1.0022828578948977,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Caratinga,2025-12-31T00:00:00,0.0,1.0111854076385498,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Carmo_da_Mata,2025-12-31T00:00:00,0.0,1.2582703828811646,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Carmo_do_Rio_Claro,2025-12-31T00:00:00,0.0,1.515702724456787,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Carmopolis_de_Minas,2025-12-31T00:00:00,0.0,1.588181495666504,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Cassia,2025-12-31T00:00:00,0.0,1.3295700550079346,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Catas_Altas_da_Noruega,2025-12-31T00:00:00,0.0,0.8744154572486877,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Chale,2025-12-31T00:00:00,0.0,1.179407238960266,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Claudio,2025-12-31T00:00:00,0.0,1.5003974437713623,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Conceicao_da_Barra_de_Minas,2025-12-31T00:00:00,0.0,1.477027416229248,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Conceicao_de_Ipanema,2025-12-31T00:00:00,0.0,1.2097690105438232,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Coqueiral,2025-12-31T00:00:00,0.0,0.976137399673462,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Corrego_Danta,2025-12-31T00:00:00,0.0,1.1989482641220093,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Cristais,2025-12-31T00:00:00,0.0,1.1523141860961914,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Desterro_de_Entre_Rios,2025-12-31T00:00:00,0.0,1.3228139877319336,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Divinesia,2025-12-31T00:00:00,0.0,1.5347375869750977,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Divino,2025-12-31T00:00:00,0.0,0.9773637056350708,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Doresopolis,2025-12-31T00:00:00,0.0,1.258535623550415,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Durande,2025-12-31T00:00:00,0.0,1.0794601440429688,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Eloi_Mendes,2025-12-31T00:00:00,0.0,1.1112611293792725,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Entre_Folhas,2025-12-31T00:00:00,0.0,0.9800617098808287,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Entre_Rios_de_Minas,2025-12-31T00:00:00,0.0,1.6568750143051147,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ervalia,2025-12-31T00:00:00,0.0,1.0800970792770386,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Espera_Feliz,2025-12-31T00:00:00,0.0,0.9861940741539,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Faria_Lemos,2025-12-31T00:00:00,0.0,0.8954946994781494,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ferros,2025-12-31T00:00:00,0.0,0.9939761757850648,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Fervedouro,2025-12-31T00:00:00,0.0,1.1266131401062012,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Guape,2025-12-31T00:00:00,0.0,1.3541998863220217,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ibituruna,2025-12-31T00:00:00,0.0,1.4666097164154053,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ilicinea,2025-12-31T00:00:00,0.0,1.247876763343811,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Itapecerica,2025-12-31T00:00:00,0.0,0.9638083577156068,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ituiutaba,2025-12-31T00:00:00,0.0,0.7024881839752197,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Itumirim,2025-12-31T00:00:00,0.0,1.2595250606536863,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Lajinha,2025-12-31T00:00:00,0.0,1.1076724529266355,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Lavras,2025-12-31T00:00:00,0.0,1.2758808135986328,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Luisburgo,2025-12-31T00:00:00,0.0,1.3038504123687744,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Machado,2025-12-31T00:00:00,0.0,1.2309093475341797,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Manhuacu,2025-12-31T00:00:00,0.0,1.127718806266785,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Manhumirim,2025-12-31T00:00:00,0.0,1.3586790561676023,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Martins_Soares,2025-12-31T00:00:00,0.0,1.167593002319336,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Matipo,2025-12-31T00:00:00,0.0,1.1633856296539309,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Medeiros,2025-12-31T00:00:00,0.0,1.3409253358840942,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Miradouro,2025-12-31T00:00:00,0.0,0.9756326079368592,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Mirai,2025-12-31T00:00:00,0.0,0.9987612366676332,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Moeda,2025-12-31T00:00:00,0.0,0.9876403212547302,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Muriae,2025-12-31T00:00:00,0.0,0.8694452047348022,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Mutum,2025-12-31T00:00:00,0.0,1.031098246574402,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Nazareno,2025-12-31T00:00:00,0.0,1.376752853393555,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Nepomuceno,2025-12-31T00:00:00,0.0,1.0845332145690918,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Oliveira,2025-12-31T00:00:00,0.0,1.6347256898880005,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Orizania,2025-12-31T00:00:00,0.0,1.2616792917251587,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Paraguacu,2025-12-31T00:00:00,0.0,1.0073951482772827,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Passa_Tempo,2025-12-31T00:00:00,0.0,1.4941248893737793,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Perdoes,2025-12-31T00:00:00,0.0,1.3913583755493164,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Pimenta,2025-12-31T00:00:00,0.0,1.3755016326904297,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Piranga,2025-12-31T00:00:00,0.0,1.8031848669052124,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Piumhi,2025-12-31T00:00:00,0.0,1.2804054021835327,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ponte_Nova,2025-12-31T00:00:00,0.0,1.13800311088562,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Porto_Firme,2025-12-31T00:00:00,0.0,1.1555882692337036,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Raul_Soares,2025-12-31T00:00:00,0.0,0.9629099369049072,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Reduto,2025-12-31T00:00:00,0.0,1.0235108137130735,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ribeirao_Vermelho,2025-12-31T00:00:00,0.0,1.2398821115493774,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ritapolis,2025-12-31T00:00:00,0.0,1.6970009803771973,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Rosario_da_Limeira,2025-12-31T00:00:00,0.0,0.9448084831237792,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santa_Barbara_do_Leste,2025-12-31T00:00:00,0.0,1.0581830739974976,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santa_Margarida,2025-12-31T00:00:00,0.0,1.173424243927002,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santa_Rita_de_Minas,2025-12-31T00:00:00,0.0,0.9605507254600524,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santa_Rita_do_Itueto,2025-12-31T00:00:00,0.0,1.2149698734283447,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santana_da_Vargem,2025-12-31T00:00:00,0.0,1.1380131244659424,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santana_do_Jacare,2025-12-31T00:00:00,0.0,1.0179270505905151,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Santana_do_Manhuacu,2025-12-31T00:00:00,0.0,1.0753475427627563,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Domingos_das_Dores,2025-12-31T00:00:00,0.0,1.152345895767212,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Francisco_de_Paula,2025-12-31T00:00:00,0.0,1.5113232135772705,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Francisco_do_Gloria,2025-12-31T00:00:00,0.0,0.7653729915618896,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Joao_do_Manhuacu,2025-12-31T00:00:00,0.0,1.0873587131500244,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Jose_do_Mantimento,2025-12-31T00:00:00,0.0,1.3825178146362305,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Roque_de_Minas,2025-12-31T00:00:00,0.0,1.2594913244247437,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Tiago,2025-12-31T00:00:00,0.0,1.319756269454956,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sao_Tomas_de_Aquino,2025-12-31T00:00:00,0.0,1.112534761428833,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Senador_Firmino,2025-12-31T00:00:00,0.0,1.396600604057312,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Senhora_de_Oliveira,2025-12-31T00:00:00,0.0,1.3682165145874023,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Sericita,2025-12-31T00:00:00,0.0,0.938172459602356,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Simonesia,2025-12-31T00:00:00,0.0,1.184540867805481,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Tapirai,2025-12-31T00:00:00,0.0,1.3596279621124268,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Tombos,2025-12-31T00:00:00,0.0,0.9319623708724976,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Tres_Pontas,2025-12-31T00:00:00,0.0,1.0881433486938477,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Ubaporanga,2025-12-31T00:00:00,0.0,1.2086756229400637,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Vargem_Bonita,2025-12-31T00:00:00,0.0,1.3177785873413086,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Vermelho_Novo,2025-12-31T00:00:00,0.0,1.075804352760315,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Vicosa,2025-12-31T00:00:00,0.0,0.9764118194580078,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_0_2025,Vieiras,2025-12-31T00:00:00,0.0,0.880872905254364,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_0_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:06:47
V43_cluster_1_2025,Almenara,2024-12-31T00:00:00,0.78,1.025124430656433,31.426209058517063,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Alpinopolis,2024-12-31T00:00:00,2.08,1.7285380363464355,-16.897209791036754,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Alterosa,2024-12-31T00:00:00,1.110028116213683,1.5524029731750488,39.85258125445606,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Andradas,2024-12-31T00:00:00,1.26,0.9902824759483336,-21.4061527025132,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Araguari,2024-12-31T00:00:00,1.500037950664137,2.3234987258911133,54.89599612212422,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Arapua,2024-12-31T00:00:00,1.0805194805194802,1.1275391578674316,4.351580716096468,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Araxa,2024-12-31T00:00:00,1.412283279459301,1.43025803565979,1.272744389310533,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Arceburgo,2024-12-31T00:00:00,1.7586206896551722,1.4386818408966064,-18.192601203918446,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Areado,2024-12-31T00:00:00,1.162105263157895,1.76476788520813,51.85955533946767,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Bom_Jesus_da_Penha,2024-12-31T00:00:00,1.56,1.4430322647094729,-7.497931749392782,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Botelhos,2024-12-31T00:00:00,1.08,0.8917863965034485,-17.42718550893996,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Botumirim,2024-12-31T00:00:00,0.7250000000000001,0.6256659030914307,-13.701254746009576,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Cabo_Verde,2024-12-31T00:00:00,1.32,1.292111039161682,-2.112800063508934,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Campestre,2024-12-31T00:00:00,1.320032051282051,1.146374225616455,-13.155576449597165,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Capetinga,2024-12-31T00:00:00,1.437691001697793,1.7581679821014404,22.291088977060493,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Carmo_do_Paranaiba,2024-12-31T00:00:00,2.103206239168111,1.687961220741272,-19.7434284234095,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Cascalho_Rico,2024-12-31T00:00:00,1.8000000000000005,2.41664457321167,34.25803184509275,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Claraval,2024-12-31T00:00:00,1.92,2.12115216255188,10.476675132910415,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Conceicao_da_Aparecida,2024-12-31T00:00:00,1.5,1.829556941986084,21.970462799072266,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Coromandel,2024-12-31T00:00:00,1.6144686299615878,1.7255332469940186,6.87932951878249,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Corrego_Fundo,2024-12-31T00:00:00,1.501960784313725,1.303364872932434,-13.222443185960628,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Cruzeiro_da_Fortaleza,2024-12-31T00:00:00,2.22,1.6748125553131104,-24.55799300391394,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Delfinopolis,2024-12-31T00:00:00,1.5,1.5286881923675537,1.912546157836914,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Divisa_Nova,2024-12-31T00:00:00,1.679831932773109,1.4495720863342283,-13.70731452037358,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Dom_Cavati,2024-12-31T00:00:00,0.6000000000000001,0.7665835022926331,27.76391704877216,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Dores_do_Turvo,2024-12-31T00:00:00,1.2,1.1953396797180176,-0.3883600234985315,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Estrela_do_Indaia,2024-12-31T00:00:00,1.56,1.7487471103668213,12.0991737414629,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Estrela_do_Sul,2024-12-31T00:00:00,1.7099999999999995,1.7581689357757568,2.816896828991643,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Guaranesia,2024-12-31T00:00:00,1.205714285714286,1.1616618633270264,-3.6536369278532814,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Guarani,2024-12-31T00:00:00,0.9655172413793104,0.9557867050170898,-1.0078055518014133,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Guarda-Mor,2024-12-31T00:00:00,1.740112994350282,1.9497873783111568,12.04946946788147,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Guaxupe,2024-12-31T00:00:00,1.32,1.0769954919815063,-18.409432425643462,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Guimarania,2024-12-31T00:00:00,1.8219512195121947,1.5767583847045898,-13.457705792653016,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Ibia,2024-12-31T00:00:00,1.681621621621622,1.541074514389038,-8.357831834788819,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Ibiraci,2024-12-31T00:00:00,1.978101265822785,1.9024704694747925,-3.823403667685038,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Indianopolis,2024-12-31T00:00:00,1.8000000000000005,2.228257656097412,23.792092005411767,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Itamogi,2024-12-31T00:00:00,1.44,1.7759602069854736,23.330569929546783,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Itanhomi,2024-12-31T00:00:00,1.02089552238806,1.2159334421157837,19.10459155227702,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Jacui,2024-12-31T00:00:00,1.3799999999999997,1.240060329437256,-10.140555837879988,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Jacutinga,2024-12-31T00:00:00,1.319874804381847,1.0796905755996704,-18.19750085271648,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Juruaia,2024-12-31T00:00:00,1.68,1.4936189651489258,-11.094109217325842,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Lagoa_Dourada,2024-12-31T00:00:00,1.5,1.5289902687072754,1.932684580485026,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Lagoa_Formosa,2024-12-31T00:00:00,1.8142857142857145,1.932128667831421,6.495280904094053,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Lagoa_Grande,2024-12-31T00:00:00,2.4,1.290700078010559,-46.22083008289337,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Matutina,2024-12-31T00:00:00,1.380566801619433,1.6250512599945068,17.708991559719426,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Monte_Belo,2024-12-31T00:00:00,1.5,1.2868685722351074,-14.208761850992838,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Monte_Carmelo,2024-12-31T00:00:00,1.56,2.079200267791748,33.28206844818897,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Monte_Santo_de_Minas,2024-12-31T00:00:00,1.5,1.6039336919784546,6.92891279856364,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Muzambinho,2024-12-31T00:00:00,1.26,1.318556785583496,4.6473639351981015,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Nova_Resende,2024-12-31T00:00:00,1.32,1.48278546333313,12.332232070691653,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Passos,2024-12-31T00:00:00,1.95459940652819,1.331739902496338,-31.86635082112253,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Patis,2024-12-31T00:00:00,0.9,1.5413018465042114,71.25576072269016,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Patos_de_Minas,2024-12-31T00:00:00,1.6624523160762943,1.880125641822815,13.093507924502244,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Patrocinio,2024-12-31T00:00:00,1.4995330375904743,1.3468594551086426,-10.18140838878451,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Pedrinopolis,2024-12-31T00:00:00,1.8511627906976744,2.0383899211883545,10.114028405903584,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Perdizes,2024-12-31T00:00:00,1.142806076854334,1.799598217010498,57.47188026546354,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Piracema,2024-12-31T00:00:00,0.8,1.1074835062026978,38.43543827533721,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Ponto_dos_Volantes,2024-12-31T00:00:00,0.5,0.606163501739502,21.23270034790039,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Pratapolis,2024-12-31T00:00:00,1.1988636363636362,1.7082995176315308,42.4932299067059,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Pratinha,2024-12-31T00:00:00,1.849285714285714,1.8044055700302124,-2.426890767002789,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Presidente_Kubitschek,2024-12-31T00:00:00,0.7368421052631579,1.1535983085632324,56.55977044786727,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Presidente_Olegario,2024-12-31T00:00:00,1.9199630314232905,1.780956506729126,-7.240062564700383,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Quartel_Geral,2024-12-31T00:00:00,3.0,2.963266372680664,-1.2244542439778647,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Rio_Paranaiba,2024-12-31T00:00:00,1.680014776505357,1.360451340675354,-19.02146578107696,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Rio_Vermelho,2024-12-31T00:00:00,0.9230769230769232,0.918386459350586,-0.5081335703531956,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Romaria,2024-12-31T00:00:00,2.052631578947369,2.152120590209961,4.846900548690374,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sacramento,2024-12-31T00:00:00,1.737021276595745,1.4711883068084717,-15.303955879473092,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Santa_Rosa_da_Serra,2024-12-31T00:00:00,1.92,1.8391679525375368,-4.210002472003298,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Santo_Antonio_do_Amparo,2024-12-31T00:00:00,1.68,1.544580340385437,-8.060694024676366,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sao_Goncalo_do_Abaete,2024-12-31T00:00:00,1.5,1.5987870693206787,6.585804621378581,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sao_Gotardo,2024-12-31T00:00:00,1.668148148148148,1.3921607732772827,-16.5445362378183,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sao_Joao_Batista_do_Gloria,2024-12-31T00:00:00,1.548387096774194,1.3555525541305542,-12.453897545735064,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sao_Pedro_da_Uniao,2024-12-31T00:00:00,2.04,1.4728127717971802,-27.803295500138223,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sao_Sebastiao_do_Paraiso,2024-12-31T00:00:00,1.26,1.5178968906402588,20.46800719367133,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Serra_do_Salitre,2024-12-31T00:00:00,1.5168750000000002,1.4448449611663818,-4.748581052072079,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Tapira,2024-12-31T00:00:00,1.98,1.624090552330017,-17.975224629797108,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Tiros,2024-12-31T00:00:00,1.95,1.6046669483184814,-17.709387265718888,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Tupaciguara,2024-12-31T00:00:00,2.8219895287958106,2.1594252586364746,-23.47862256037721,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Uberaba,2024-12-31T00:00:00,2.102941176470588,2.2916386127471924,8.973024941824551,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Uberlandia,2024-12-31T00:00:00,1.919565217391304,1.9016056060791016,-0.9356082903299024,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Unai,2024-12-31T00:00:00,2.2801061007957566,2.715956687927246,19.115364279731445,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Varginha,2024-12-31T00:00:00,1.3799999999999997,1.485143542289734,7.619097267372046,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Varjao_de_Minas,2024-12-31T00:00:00,2.6876337184424486,2.3753578662872314,-11.618988480922498,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Virginopolis,2024-12-31T00:00:00,1.325,1.4028021097183228,5.871857337231909,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Almenara,2025-12-31T00:00:00,0.0,0.7817513346672058,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Alpinopolis,2025-12-31T00:00:00,0.0,1.306617021560669,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Alterosa,2025-12-31T00:00:00,0.0,1.145998477935791,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Andradas,2025-12-31T00:00:00,0.0,1.0148321390151978,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Araguari,2025-12-31T00:00:00,0.0,1.6117730140686035,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Arapua,2025-12-31T00:00:00,0.0,0.9143986701965332,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Araxa,2025-12-31T00:00:00,0.0,1.2237231731414795,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Arceburgo,2025-12-31T00:00:00,0.0,1.385714411735535,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Areado,2025-12-31T00:00:00,0.0,1.311486840248108,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Bom_Jesus_da_Penha,2025-12-31T00:00:00,0.0,1.1240404844284058,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Botelhos,2025-12-31T00:00:00,0.0,0.8914293050765991,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Botumirim,2025-12-31T00:00:00,0.0,0.67330002784729,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Cabo_Verde,2025-12-31T00:00:00,0.0,1.1832716464996338,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Campestre,2025-12-31T00:00:00,0.0,1.2902798652648926,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Capetinga,2025-12-31T00:00:00,0.0,1.13915753364563,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Carmo_do_Paranaiba,2025-12-31T00:00:00,0.0,1.5760058164596558,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Cascalho_Rico,2025-12-31T00:00:00,0.0,2.0028843879699707,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Claraval,2025-12-31T00:00:00,0.0,0.921613872051239,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Conceicao_da_Aparecida,2025-12-31T00:00:00,0.0,1.5138218402862549,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Coromandel,2025-12-31T00:00:00,0.0,1.523717164993286,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Corrego_Fundo,2025-12-31T00:00:00,0.0,1.2582204341888428,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Cruzeiro_da_Fortaleza,2025-12-31T00:00:00,0.0,1.641589641571045,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Delfinopolis,2025-12-31T00:00:00,0.0,1.0213688611984253,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Divisa_Nova,2025-12-31T00:00:00,0.0,1.510298490524292,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Dom_Cavati,2025-12-31T00:00:00,0.0,0.5261939167976379,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Dores_do_Turvo,2025-12-31T00:00:00,0.0,1.1831908226013184,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Estrela_do_Indaia,2025-12-31T00:00:00,0.0,1.5821672677993774,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Estrela_do_Sul,2025-12-31T00:00:00,0.0,1.5880537033081057,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Guaranesia,2025-12-31T00:00:00,0.0,1.0720760822296145,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Guarani,2025-12-31T00:00:00,0.0,0.7981945276260376,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Guarda-Mor,2025-12-31T00:00:00,0.0,1.7770212888717651,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Guaxupe,2025-12-31T00:00:00,0.0,1.0725641250610352,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Guimarania,2025-12-31T00:00:00,0.0,1.4803184270858765,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Ibia,2025-12-31T00:00:00,0.0,1.1905499696731567,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Ibiraci,2025-12-31T00:00:00,0.0,1.1236162185668943,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Indianopolis,2025-12-31T00:00:00,0.0,1.6785173416137695,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Itamogi,2025-12-31T00:00:00,0.0,1.318355917930603,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Itanhomi,2025-12-31T00:00:00,0.0,0.9912230968475342,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Jacui,2025-12-31T00:00:00,0.0,0.9420792460441588,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Jacutinga,2025-12-31T00:00:00,0.0,1.1277401447296145,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Juruaia,2025-12-31T00:00:00,0.0,1.4689509868621826,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Lagoa_Dourada,2025-12-31T00:00:00,0.0,1.3167086839675903,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Lagoa_Formosa,2025-12-31T00:00:00,0.0,1.950100064277649,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Lagoa_Grande,2025-12-31T00:00:00,0.0,1.0022614002227783,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Matutina,2025-12-31T00:00:00,0.0,1.3261040449142456,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Monte_Belo,2025-12-31T00:00:00,0.0,1.194580078125,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Monte_Carmelo,2025-12-31T00:00:00,0.0,1.64471697807312,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Monte_Santo_de_Minas,2025-12-31T00:00:00,0.0,1.3639240264892578,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Muzambinho,2025-12-31T00:00:00,0.0,1.1181747913360596,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Nova_Resende,2025-12-31T00:00:00,0.0,1.1696888208389282,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Passos,2025-12-31T00:00:00,0.0,1.0757635831832886,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Patis,2025-12-31T00:00:00,0.0,1.3080425262451172,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Patos_de_Minas,2025-12-31T00:00:00,0.0,1.8162550926208496,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Patrocinio,2025-12-31T00:00:00,0.0,1.118337869644165,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Pedrinopolis,2025-12-31T00:00:00,0.0,1.590497612953186,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Perdizes,2025-12-31T00:00:00,0.0,1.0695030689239502,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Piracema,2025-12-31T00:00:00,0.0,0.9017519354820251,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Ponto_dos_Volantes,2025-12-31T00:00:00,0.0,0.604789137840271,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Pratapolis,2025-12-31T00:00:00,0.0,0.9075351357460022,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Pratinha,2025-12-31T00:00:00,0.0,1.6036972999572754,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Presidente_Kubitschek,2025-12-31T00:00:00,0.0,0.8281866908073425,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Presidente_Olegario,2025-12-31T00:00:00,0.0,1.7940123081207275,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Quartel_Geral,2025-12-31T00:00:00,0.0,2.5230278968811035,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Rio_Paranaiba,2025-12-31T00:00:00,0.0,1.1718318462371826,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Rio_Vermelho,2025-12-31T00:00:00,0.0,0.8720811009407043,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Romaria,2025-12-31T00:00:00,0.0,1.9711592197418213,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sacramento,2025-12-31T00:00:00,0.0,1.1057884693145752,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Santa_Rosa_da_Serra,2025-12-31T00:00:00,0.0,1.484671115875244,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Santo_Antonio_do_Amparo,2025-12-31T00:00:00,0.0,1.4174809455871582,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sao_Goncalo_do_Abaete,2025-12-31T00:00:00,0.0,1.3177335262298584,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sao_Gotardo,2025-12-31T00:00:00,0.0,1.3289425373077393,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sao_Joao_Batista_do_Gloria,2025-12-31T00:00:00,0.0,1.125954270362854,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sao_Pedro_da_Uniao,2025-12-31T00:00:00,0.0,1.442258358001709,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Sao_Sebastiao_do_Paraiso,2025-12-31T00:00:00,0.0,1.196291446685791,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Serra_do_Salitre,2025-12-31T00:00:00,0.0,1.4235162734985352,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Tapira,2025-12-31T00:00:00,0.0,1.0377594232559204,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Tiros,2025-12-31T00:00:00,0.0,1.3833922147750854,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Tupaciguara,2025-12-31T00:00:00,0.0,2.054840564727783,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Uberaba,2025-12-31T00:00:00,0.0,1.8754260540008545,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Uberlandia,2025-12-31T00:00:00,0.0,1.723975419998169,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Unai,2025-12-31T00:00:00,0.0,2.527804374694824,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Varginha,2025-12-31T00:00:00,0.0,1.2645766735076904,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Varjao_de_Minas,2025-12-31T00:00:00,0.0,2.3574442863464355,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_1_2025,Virginopolis,2025-12-31T00:00:00,0.0,1.2224602699279783,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_1_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:21
V43_cluster_2_2025,Abre_Campo,2024-12-31T00:00:00,1.32,1.7116034030914309,29.666924476623528,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Aimores,2024-12-31T00:00:00,0.9455882352941176,1.634592890739441,72.86518906731257,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Alvarenga,2024-12-31T00:00:00,1.25,1.1235907077789309,-10.112743377685549,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Andrelandia,2024-12-31T00:00:00,1.5,1.730084776878357,15.338985125223797,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Antonio_Dias,2024-12-31T00:00:00,1.5,1.6421507596969604,9.476717313130695,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Antonio_Prado_de_Minas,2024-12-31T00:00:00,1.933333333333333,1.3325281143188477,-31.07613201799062,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Bocaiuva,2024-12-31T00:00:00,2.0989010989010994,2.6773905754089355,27.56154050377648,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Bom_Jesus_do_Amparo,2024-12-31T00:00:00,0.75,1.7640573978424072,135.2076530456543,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Campo_Belo,2024-12-31T00:00:00,1.2,1.588958740234375,32.413228352864586,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Capela_Nova,2024-12-31T00:00:00,2.101234567901236,1.964870810508728,-6.489697032193368,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Capitao_Eneas,2024-12-31T00:00:00,3.0,3.0209765434265137,0.6992181142171223,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Casa_Grande,2024-12-31T00:00:00,2.522388059701492,2.0977976322174072,-16.832874935759577,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Cataguases,2024-12-31T00:00:00,1.0,1.1519063711166382,15.190637111663818,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Caxambu,2024-12-31T00:00:00,1.795918367346939,1.455527663230896,-18.95357329737057,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Coimbra,2024-12-31T00:00:00,1.5012658227848097,1.800788640975952,19.95135129603732,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Conselheiro_Pena,2024-12-31T00:00:00,1.2,1.4582914113998413,21.52428428332012,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Corrego_Novo,2024-12-31T00:00:00,1.2,1.9905468225479128,65.87890187899272,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Cruzilia,2024-12-31T00:00:00,1.502793296089385,1.5052450895309448,0.1631490803119697,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Divisopolis,2024-12-31T00:00:00,1.4902200488997548,1.5493851900100708,3.970228501086015,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Esmeraldas,2024-12-31T00:00:00,3.0,2.176935195922852,-27.43549346923828,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Espirito_Santo_do_Dourado,2024-12-31T00:00:00,1.4391752577319588,1.547067642211914,7.496820411572826,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Eugenopolis,2024-12-31T00:00:00,1.68,1.6092867851257324,-4.209119932992114,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Felicio_dos_Santos,2024-12-31T00:00:00,2.663299663299664,4.671039581298828,75.3854305493997,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Formiga,2024-12-31T00:00:00,1.9475763016157988,1.743937849998474,-10.455993505793678,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Guaraciaba,2024-12-31T00:00:00,1.8000000000000005,1.6296446323394775,-9.464187092251262,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Guiricema,2024-12-31T00:00:00,1.56,2.25573992729187,44.59871328794039,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Iapu,2024-12-31T00:00:00,1.355263157894737,1.6509957313537598,21.821044255228863,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Ijaci,2024-12-31T00:00:00,2.19,1.8541157245635984,-15.337181526776316,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Imbe_de_Minas,2024-12-31T00:00:00,1.26,1.4782028198242188,17.317684113033234,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Inhapim,2024-12-31T00:00:00,1.2,2.1449453830718994,78.74544858932497,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Irai_de_Minas,2024-12-31T00:00:00,2.607944732297064,2.6729087829589844,2.491005651208747,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Itamarati_de_Minas,2024-12-31T00:00:00,1.196969696969697,1.1501280069351196,-3.913356382635579,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Jequeri,2024-12-31T00:00:00,1.8000000000000005,1.8990401029586792,5.502227942148829,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Lamim,2024-12-31T00:00:00,1.777777777777778,2.1115496158599854,18.774665892124155,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Mar_de_Espanha,2024-12-31T00:00:00,1.2625,1.9253530502319336,52.5032118995591,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Mata_Verde,2024-12-31T00:00:00,1.5,1.7606916427612305,17.379442850748696,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Monte_Alegre_de_Minas,2024-12-31T00:00:00,2.378787878787879,2.824122428894043,18.72107025924001,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Nova_Era,2024-12-31T00:00:00,1.5,2.1897218227386475,45.98145484924317,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Nova_Ponte,2024-12-31T00:00:00,2.306557377049181,2.430446147918701,5.371154955963561,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Paula_Candido,2024-12-31T00:00:00,1.31970802919708,1.5975818634033203,21.05570535744189,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Pecanha,2024-12-31T00:00:00,1.8855421686746991,2.3485708236694336,24.55679128726068,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Pedra_Bonita,2024-12-31T00:00:00,1.2,1.6895966529846191,40.7997210820516,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Pedra_Dourada,2024-12-31T00:00:00,1.2800000000000002,1.289313554763794,0.7276214659213823,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Pedra_do_Anta,2024-12-31T00:00:00,1.379166666666667,1.5453736782073977,12.051263676669269,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Piedade_de_Caratinga,2024-12-31T00:00:00,1.68,2.1877245903015137,30.22170180366153,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Pocrane,2024-12-31T00:00:00,1.7968750000000002,1.3053700923919678,-27.353316597316585,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Presidente_Bernardes,2024-12-31T00:00:00,1.110144927536232,1.500728726387024,35.183135927812835,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sabinopolis,2024-12-31T00:00:00,1.2,1.2751383781433103,6.26153151194255,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Santa_Barbara,2024-12-31T00:00:00,1.333333333333333,1.2510557174682615,-6.170821189880351,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Santo_Antonio_do_Grama,2024-12-31T00:00:00,1.565217391304348,1.8720879554748533,19.60561937756008,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Domingos_do_Prata,2024-12-31T00:00:00,1.05,1.309001326560974,24.66679300580705,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Geraldo,2024-12-31T00:00:00,1.3189189189189188,1.974686861038208,49.720110365601855,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Jose_da_Barra,2024-12-31T00:00:00,1.709523809523809,2.1566176414489746,26.15312108754452,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Jose_do_Alegre,2024-12-31T00:00:00,1.8000000000000005,1.729111909866333,-3.938227229648181,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Miguel_do_Anta,2024-12-31T00:00:00,1.55974025974026,1.5236012935638428,-2.316986174508021,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Sebastiao_da_Vargem_Alegre,2024-12-31T00:00:00,1.2800000000000002,1.546161413192749,20.793860405683496,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Sebastiao_do_Anta,2024-12-31T00:00:00,1.8000000000000005,1.7891627550125122,-0.6020691659715588,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Senhora_dos_Remedios,2024-12-31T00:00:00,1.8000000000000005,1.8256993293762207,1.4277405209011351,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Teixeiras,2024-12-31T00:00:00,1.5,1.502452373504639,0.1634915669759114,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Visconde_do_Rio_Branco,2024-12-31T00:00:00,1.333333333333333,1.2594884634017944,-5.538365244865397,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Abre_Campo,2025-12-31T00:00:00,0.0,1.6655458211898804,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Aimores,2025-12-31T00:00:00,0.0,1.6707184314727783,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Alvarenga,2025-12-31T00:00:00,0.0,1.044216275215149,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Andrelandia,2025-12-31T00:00:00,0.0,1.6850661039352417,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Antonio_Dias,2025-12-31T00:00:00,0.0,1.4409348964691162,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Antonio_Prado_de_Minas,2025-12-31T00:00:00,0.0,1.433761715888977,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Bocaiuva,2025-12-31T00:00:00,0.0,2.7188844680786133,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Bom_Jesus_do_Amparo,2025-12-31T00:00:00,0.0,1.535327672958374,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Campo_Belo,2025-12-31T00:00:00,0.0,1.6471089124679563,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Capela_Nova,2025-12-31T00:00:00,0.0,1.9198215007781985,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Capitao_Eneas,2025-12-31T00:00:00,0.0,2.789811611175537,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Casa_Grande,2025-12-31T00:00:00,0.0,1.9790575504302976,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Cataguases,2025-12-31T00:00:00,0.0,1.206183910369873,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Caxambu,2025-12-31T00:00:00,0.0,1.586400032043457,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Coimbra,2025-12-31T00:00:00,0.0,1.8460649251937864,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Conselheiro_Pena,2025-12-31T00:00:00,0.0,1.4768214225769043,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Corrego_Novo,2025-12-31T00:00:00,0.0,1.7266011238098145,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Cruzilia,2025-12-31T00:00:00,0.0,1.460141658782959,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Divisopolis,2025-12-31T00:00:00,0.0,1.688731670379639,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Esmeraldas,2025-12-31T00:00:00,0.0,2.335734844207764,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Espirito_Santo_do_Dourado,2025-12-31T00:00:00,0.0,1.4577800035476685,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Eugenopolis,2025-12-31T00:00:00,0.0,1.6441971063613892,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Felicio_dos_Santos,2025-12-31T00:00:00,0.0,4.701175212860107,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Formiga,2025-12-31T00:00:00,0.0,1.617342233657837,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Guaraciaba,2025-12-31T00:00:00,0.0,1.6848763227462769,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Guiricema,2025-12-31T00:00:00,0.0,2.314732313156128,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Iapu,2025-12-31T00:00:00,0.0,1.4854533672332764,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Ijaci,2025-12-31T00:00:00,0.0,1.937638282775879,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Imbe_de_Minas,2025-12-31T00:00:00,0.0,1.316575050354004,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Inhapim,2025-12-31T00:00:00,0.0,1.7506060600280762,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Irai_de_Minas,2025-12-31T00:00:00,0.0,3.1012380123138428,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Itamarati_de_Minas,2025-12-31T00:00:00,0.0,1.178289771080017,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Jequeri,2025-12-31T00:00:00,0.0,1.9903571605682373,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Lamim,2025-12-31T00:00:00,0.0,1.9341202974319456,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Mar_de_Espanha,2025-12-31T00:00:00,0.0,1.8796230554580688,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Mata_Verde,2025-12-31T00:00:00,0.0,1.739024639129639,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Monte_Alegre_de_Minas,2025-12-31T00:00:00,0.0,3.076512098312378,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Nova_Era,2025-12-31T00:00:00,0.0,1.716371774673462,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Nova_Ponte,2025-12-31T00:00:00,0.0,2.4929356575012207,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Paula_Candido,2025-12-31T00:00:00,0.0,1.648883819580078,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Pecanha,2025-12-31T00:00:00,0.0,2.191730499267578,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Pedra_Bonita,2025-12-31T00:00:00,0.0,1.846157789230347,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Pedra_Dourada,2025-12-31T00:00:00,0.0,1.3544111251831057,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Pedra_do_Anta,2025-12-31T00:00:00,0.0,1.5638341903686523,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Piedade_de_Caratinga,2025-12-31T00:00:00,0.0,1.735344648361206,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Pocrane,2025-12-31T00:00:00,0.0,1.3556817770004272,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Presidente_Bernardes,2025-12-31T00:00:00,0.0,1.5060696601867676,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sabinopolis,2025-12-31T00:00:00,0.0,1.2564631700515747,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Santa_Barbara,2025-12-31T00:00:00,0.0,1.1891542673110962,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Santo_Antonio_do_Grama,2025-12-31T00:00:00,0.0,1.861076593399048,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Domingos_do_Prata,2025-12-31T00:00:00,0.0,1.1802594661712646,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Geraldo,2025-12-31T00:00:00,0.0,1.9742432832717896,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Jose_da_Barra,2025-12-31T00:00:00,0.0,2.0911765098571777,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Jose_do_Alegre,2025-12-31T00:00:00,0.0,1.81784987449646,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Miguel_do_Anta,2025-12-31T00:00:00,0.0,1.540987491607666,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Sebastiao_da_Vargem_Alegre,2025-12-31T00:00:00,0.0,1.565782070159912,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Sao_Sebastiao_do_Anta,2025-12-31T00:00:00,0.0,1.7349777221679688,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Senhora_dos_Remedios,2025-12-31T00:00:00,0.0,1.8048629760742188,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Teixeiras,2025-12-31T00:00:00,0.0,1.556614875793457,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_2_2025,Visconde_do_Rio_Branco,2025-12-31T00:00:00,0.0,1.32207989692688,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_2_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:07:56
V43_cluster_3_2025,Aiuruoca,2024-12-31T00:00:00,1.8000000000000005,1.510265827178955,-16.09634293450251,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Albertina,2024-12-31T00:00:00,1.56,1.5182232856750488,-2.677994508009694,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Baependi,2024-12-31T00:00:00,1.439779005524862,1.2450065612792969,-13.527940294876167,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Bandeira_do_Sul,2024-12-31T00:00:00,1.5,1.4246675968170166,-5.022160212198893,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Borda_da_Mata,2024-12-31T00:00:00,1.5,1.3674408197402954,-8.837278683980305,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Brazopolis,2024-12-31T00:00:00,1.501216545012166,1.338196873664856,-10.859170976295689,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Bueno_Brandao,2024-12-31T00:00:00,1.8000000000000005,1.412974834442139,-21.501398086547866,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Cachoeira_de_Minas,2024-12-31T00:00:00,1.73984375,1.644270658493042,-5.493199691464128,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Caldas,2024-12-31T00:00:00,1.68,1.390010118484497,-17.261302471160885,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Cambuquira,2024-12-31T00:00:00,1.7400000000000002,1.428088903427124,-17.925925090395182,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Campanha,2024-12-31T00:00:00,1.5689448441247,1.384274959564209,-11.770323555479523,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Careacu,2024-12-31T00:00:00,1.560169491525424,1.2604193687438965,-19.21266403488335,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Carmo_da_Cachoeira,2024-12-31T00:00:00,1.44,1.4736196994781494,2.334701352649269,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Carmo_de_Minas,2024-12-31T00:00:00,1.56,1.3692622184753418,-12.226780866965273,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Carrancas,2024-12-31T00:00:00,1.6428571428571432,1.4293543100357056,-12.99582460652229,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Carvalhopolis,2024-12-31T00:00:00,1.62,1.4756979942321775,-8.907531220235947,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Conceicao_das_Pedras,2024-12-31T00:00:00,1.5598885793871868,1.516597867012024,-2.7752438826220507,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Conceicao_do_Rio_Verde,2024-12-31T00:00:00,1.5,1.5403542518615725,2.690283457438152,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Conceicao_dos_Ouros,2024-12-31T00:00:00,1.8000000000000005,1.3585058450698853,-24.527453051673053,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Congonhal,2024-12-31T00:00:00,1.8000000000000005,1.3748977184295654,-23.61679342057971,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Cordislandia,2024-12-31T00:00:00,1.439887640449438,1.3559304475784302,-5.830815579804685,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Cristina,2024-12-31T00:00:00,1.619736842105263,1.538791537284851,-4.997435553494152,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Datas,2024-12-31T00:00:00,1.0,1.0553168058395386,5.531680583953857,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Dom_Vicoso,2024-12-31T00:00:00,1.2,1.328484296798706,10.70702473322551,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Fama,2024-12-31T00:00:00,1.679838709677419,1.528031349182129,-9.03702001988285,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Fortaleza_de_Minas,2024-12-31T00:00:00,1.5598425196850392,1.4437534809112549,-7.442356347435945,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Heliodora,2024-12-31T00:00:00,1.5601255886970171,1.3413920402526855,-14.020252602036548,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Ibitiura_de_Minas,2024-12-31T00:00:00,1.360264900662252,1.3865621089935305,1.9332417030297049,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Inconfidentes,2024-12-31T00:00:00,1.8000000000000005,1.7278459072113037,-4.008560710483142,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Ingai,2024-12-31T00:00:00,1.621004566210046,1.4911956787109375,-8.007928552761907,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Itajuba,2024-12-31T00:00:00,1.068965517241379,1.3352068662643433,24.90644877956763,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Itutinga,2024-12-31T00:00:00,1.8000000000000005,1.457944631576538,-19.00307602352568,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Jesuania,2024-12-31T00:00:00,1.5,1.2914440631866455,-13.9037291208903,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Lambari,2024-12-31T00:00:00,1.56,1.3656654357910156,-12.457343859550283,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Luminarias,2024-12-31T00:00:00,1.380229885057471,1.463834285736084,6.057280861958136,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Maria_da_Fe,2024-12-31T00:00:00,1.477777777777778,1.382581114768982,-6.441879451723046,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Monsenhor_Paulo,2024-12-31T00:00:00,1.5899728997289972,1.4494510889053345,-8.83800037394436,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Monte_Siao,2024-12-31T00:00:00,1.5,1.4513044357299805,-3.2463709513346357,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Natercia,2024-12-31T00:00:00,1.8000000000000005,1.4554753303527832,-19.14025942484539,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Olimpio_Noronha,2024-12-31T00:00:00,1.5,1.269651174545288,-15.35658836364746,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Ouro_Fino,2024-12-31T00:00:00,1.5,1.416952133178711,-5.536524454752604,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Paraisopolis,2024-12-31T00:00:00,1.5066666666666668,1.304354190826416,-13.427819192937,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Pedralva,2024-12-31T00:00:00,1.5600790513833993,1.502110481262207,-3.715745690565403,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Pirangucu,2024-12-31T00:00:00,1.333333333333333,1.235336184501648,-7.349786162376383,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Piranguinho,2024-12-31T00:00:00,1.6807610993657498,1.4192328453063965,-15.560108700638262,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Poco_Fundo,2024-12-31T00:00:00,1.380192991366176,1.295384168624878,-6.144707535237551,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Pocos_de_Caldas,2024-12-31T00:00:00,1.7400000000000002,1.426140069961548,-18.03792701370416,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Pouso_Alegre,2024-12-31T00:00:00,1.7878787878787883,1.4475141763687134,-19.03734267768215,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Pouso_Alto,2024-12-31T00:00:00,1.53,1.5497117042541504,1.2883466832778014,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Santa_Rita_de_Caldas,2024-12-31T00:00:00,1.8000000000000005,1.7427661418914795,-3.1796587838067087,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Santa_Rita_do_Sapucai,2024-12-31T00:00:00,1.5,1.419856071472168,-5.342928568522135,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Bento_Abade,2024-12-31T00:00:00,1.5,1.421892762184143,-5.207149187723795,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Goncalo_do_Sapucai,2024-12-31T00:00:00,1.5,1.4319539070129397,-4.536406199137369,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Joao_da_Mata,2024-12-31T00:00:00,1.32,1.143489122390747,-13.372036182519164,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Joao_del_Rei,2024-12-31T00:00:00,1.80168776371308,1.6320934295654297,-9.41308130983444,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Lourenco,2024-12-31T00:00:00,1.3799999999999997,1.5760421752929688,14.205954731374574,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Sebastiao_da_Bela_Vista,2024-12-31T00:00:00,1.44,1.3820152282714844,-4.026720258924692,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Tome_das_Letras,2024-12-31T00:00:00,2.1,1.258589267730713,-40.06717772710891,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Senador_Jose_Bento,2024-12-31T00:00:00,0.9,1.2875783443450928,43.06426048278808,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Serrania,2024-12-31T00:00:00,1.32,1.3441739082336426,1.8313566843668567,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Silvianopolis,2024-12-31T00:00:00,1.56025641025641,1.0806550979614258,-30.73862149466621,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Soledade_de_Minas,2024-12-31T00:00:00,1.5,1.5874402523040771,5.829350153605143,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Tocos_do_Moji,2024-12-31T00:00:00,1.5,1.3885483741760254,-7.430108388264974,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Tres_Coracoes,2024-12-31T00:00:00,1.56,1.4218575954437256,-8.855282343350927,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Turvolandia,2024-12-31T00:00:00,1.44,1.5591063499450684,8.271274301740862,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Virginia,2024-12-31T00:00:00,1.6599999999999997,1.4801182746887207,-10.836248512727652,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Aiuruoca,2025-12-31T00:00:00,0.0,1.3931233882904053,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Albertina,2025-12-31T00:00:00,0.0,1.440296649932861,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Baependi,2025-12-31T00:00:00,0.0,1.115200161933899,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Bandeira_do_Sul,2025-12-31T00:00:00,0.0,1.2227346897125244,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Borda_da_Mata,2025-12-31T00:00:00,0.0,1.1411151885986328,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Brazopolis,2025-12-31T00:00:00,0.0,1.1665844917297363,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Bueno_Brandao,2025-12-31T00:00:00,0.0,1.2406917810440063,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Cachoeira_de_Minas,2025-12-31T00:00:00,0.0,1.481172800064087,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Caldas,2025-12-31T00:00:00,0.0,1.189730525016785,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Cambuquira,2025-12-31T00:00:00,0.0,1.2797216176986694,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Campanha,2025-12-31T00:00:00,0.0,1.2607386112213137,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Careacu,2025-12-31T00:00:00,0.0,1.1624300479888916,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Carmo_da_Cachoeira,2025-12-31T00:00:00,0.0,1.223036289215088,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Carmo_de_Minas,2025-12-31T00:00:00,0.0,1.2318943738937378,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Carrancas,2025-12-31T00:00:00,0.0,1.2609446048736572,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Carvalhopolis,2025-12-31T00:00:00,0.0,1.3088043928146362,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Conceicao_das_Pedras,2025-12-31T00:00:00,0.0,1.3992886543273926,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Conceicao_do_Rio_Verde,2025-12-31T00:00:00,0.0,1.3815103769302368,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Conceicao_dos_Ouros,2025-12-31T00:00:00,0.0,1.1966497898101809,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Congonhal,2025-12-31T00:00:00,0.0,1.115769386291504,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Cordislandia,2025-12-31T00:00:00,0.0,1.1842942237854004,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Cristina,2025-12-31T00:00:00,0.0,1.3430120944976809,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Datas,2025-12-31T00:00:00,0.0,0.8162447810173035,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Dom_Vicoso,2025-12-31T00:00:00,0.0,1.143874168395996,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Fama,2025-12-31T00:00:00,0.0,1.431290626525879,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Fortaleza_de_Minas,2025-12-31T00:00:00,0.0,1.316259741783142,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Heliodora,2025-12-31T00:00:00,0.0,1.110719084739685,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Ibitiura_de_Minas,2025-12-31T00:00:00,0.0,1.0958343744277954,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Inconfidentes,2025-12-31T00:00:00,0.0,1.353203535079956,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Ingai,2025-12-31T00:00:00,0.0,1.3736491203308103,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Itajuba,2025-12-31T00:00:00,0.0,0.9614173769950868,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Itutinga,2025-12-31T00:00:00,0.0,1.3711204528808594,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Jesuania,2025-12-31T00:00:00,0.0,1.1726651191711426,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Lambari,2025-12-31T00:00:00,0.0,1.2141553163528442,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Luminarias,2025-12-31T00:00:00,0.0,1.2306344509124756,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Maria_da_Fe,2025-12-31T00:00:00,0.0,1.2373205423355105,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Monsenhor_Paulo,2025-12-31T00:00:00,0.0,1.244963526725769,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Monte_Siao,2025-12-31T00:00:00,0.0,1.273987054824829,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Natercia,2025-12-31T00:00:00,0.0,1.3553502559661863,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Olimpio_Noronha,2025-12-31T00:00:00,0.0,1.1456222534179688,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Ouro_Fino,2025-12-31T00:00:00,0.0,1.1035799980163574,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Paraisopolis,2025-12-31T00:00:00,0.0,0.9295976161956788,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Pedralva,2025-12-31T00:00:00,0.0,1.3613994121551514,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Pirangucu,2025-12-31T00:00:00,0.0,1.2172234058380127,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Piranguinho,2025-12-31T00:00:00,0.0,1.3374871015548706,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Poco_Fundo,2025-12-31T00:00:00,0.0,1.036679744720459,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Pocos_de_Caldas,2025-12-31T00:00:00,0.0,1.2334898710250854,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Pouso_Alegre,2025-12-31T00:00:00,0.0,1.2872012853622437,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Pouso_Alto,2025-12-31T00:00:00,0.0,1.465095043182373,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Santa_Rita_de_Caldas,2025-12-31T00:00:00,0.0,1.6565524339675903,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Santa_Rita_do_Sapucai,2025-12-31T00:00:00,0.0,1.200973391532898,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Bento_Abade,2025-12-31T00:00:00,0.0,1.2410835027694702,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Goncalo_do_Sapucai,2025-12-31T00:00:00,0.0,1.0564539432525637,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Joao_da_Mata,2025-12-31T00:00:00,0.0,0.9058709144592284,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Joao_del_Rei,2025-12-31T00:00:00,0.0,1.529332160949707,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Lourenco,2025-12-31T00:00:00,0.0,1.1062427759170532,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Sebastiao_da_Bela_Vista,2025-12-31T00:00:00,0.0,1.279166340827942,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Sao_Tome_das_Letras,2025-12-31T00:00:00,0.0,1.079735517501831,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Senador_Jose_Bento,2025-12-31T00:00:00,0.0,0.938621997833252,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Serrania,2025-12-31T00:00:00,0.0,0.9719011187553406,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Silvianopolis,2025-12-31T00:00:00,0.0,0.9087804555892944,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Soledade_de_Minas,2025-12-31T00:00:00,0.0,1.1878749132156372,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Tocos_do_Moji,2025-12-31T00:00:00,0.0,1.2291547060012815,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Tres_Coracoes,2025-12-31T00:00:00,0.0,1.1744439601898191,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Turvolandia,2025-12-31T00:00:00,0.0,1.1941626071929932,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_3_2025,Virginia,2025-12-31T00:00:00,0.0,1.4213216304779053,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_3_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:08:31
V43_cluster_4_2025,Abadia_dos_Dourados,2024-12-31T00:00:00,2.6116071428571423,2.631427764892578,0.758943476228652,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Acucena,2024-12-31T00:00:00,1.6666666666666672,1.5183279514312744,-8.900322914123564,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Agua_Boa,2024-12-31T00:00:00,1.7064935064935067,1.247786283493042,-26.88010363092525,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Aguas_Vermelhas,2024-12-31T00:00:00,3.0,3.2753071784973145,9.17690594991048,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Angelandia,2024-12-31T00:00:00,1.870967741935484,2.243711233139038,19.922496943638237,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Aricanduva,2024-12-31T00:00:00,1.320245398773006,1.2941179275512695,-1.9789859707913824,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Ataleia,2024-12-31T00:00:00,0.7529411764705883,0.9558554887771606,26.94955710321663,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Bandeira,2024-12-31T00:00:00,1.15,1.2913576364517212,12.291968387106198,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Berilo,2024-12-31T00:00:00,1.6818181818181819,2.2240779399871826,32.24247210734599,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Berizal,2024-12-31T00:00:00,3.5516129032258075,4.946549415588379,39.276141583323984,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Bonfinopolis_de_Minas,2024-12-31T00:00:00,2.1,3.4778788089752197,65.6132766178676,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Buritis,2024-12-31T00:00:00,2.69967707212056,3.2154600620269775,19.10535875690039,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Buritizeiro,2024-12-31T00:00:00,2.7000000000000006,3.3187265396118164,22.91579776340058,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Capelinha,2024-12-31T00:00:00,1.62007678089009,1.7197884321212769,6.154748491389653,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Carai,2024-12-31T00:00:00,1.2,1.4888761043548584,24.073008696238205,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Caranaiba,2024-12-31T00:00:00,1.5,3.0006933212280273,100.04622141520183,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Catuji,2024-12-31T00:00:00,1.138461538461538,1.5299474000930786,34.3872716297975,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Congonhas_do_Norte,2024-12-31T00:00:00,1.2,1.0984110832214355,-8.465743064880368,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Coroaci,2024-12-31T00:00:00,2.1,2.4150261878967285,15.001247042701351,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Cuparaque,2024-12-31T00:00:00,1.020408163265306,1.3877251148223877,35.99706125259402,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Diamantina,2024-12-31T00:00:00,2.967637540453075,3.3240315914154053,12.00935242610251,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Formoso,2024-12-31T00:00:00,3.6000000000000005,3.4336705207824707,-4.62026331159805,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Franciscopolis,2024-12-31T00:00:00,0.9,1.965348720550537,118.37208006117079,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Frei_Gaspar,2024-12-31T00:00:00,1.2,1.4716469049453735,22.637242078781135,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Grao_Mogol,2024-12-31T00:00:00,2.0333333333333337,1.2922983169555664,-36.44434506775904,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Indaiabira,2024-12-31T00:00:00,2.511111111111111,2.5417978763580322,1.2220393239924354,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Itabirinha,2024-12-31T00:00:00,0.8918918918918919,1.0544675588607788,18.22818084196611,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Itacambira,2024-12-31T00:00:00,0.5,0.7992141842842102,59.84283685684204,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Itaipe,2024-12-31T00:00:00,0.9,0.9921963214874268,10.244035720825192,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Itamarandiba,2024-12-31T00:00:00,2.1352380952380954,2.394059896469116,12.121449210194998,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Itambacuri,2024-12-31T00:00:00,1.084388185654009,1.0646414756774902,-1.8210001028929712,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Jequitinhonha,2024-12-31T00:00:00,2.4,2.734693765640259,13.945573568344122,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Joao_Pinheiro,2024-12-31T00:00:00,3.0,2.978304386138916,-0.7231871287027996,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Jose_Goncalves_de_Minas,2024-12-31T00:00:00,1.5,1.6629722118377686,10.864814122517902,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Juiz_de_Fora,2024-12-31T00:00:00,1.166666666666667,1.2736715078353882,9.17184352874753,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Ladainha,2024-12-31T00:00:00,1.12,1.1851890087127686,5.820447206497182,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Malacacheta,2024-12-31T00:00:00,1.5,1.7740206718444824,18.268044789632164,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Mantena,2024-12-31T00:00:00,1.2,1.198272943496704,-0.1439213752746545,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Minas_Novas,2024-12-31T00:00:00,1.6204545454545451,2.000861644744873,23.47533291553216,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Monte_Formoso,2024-12-31T00:00:00,0.6800000000000002,0.9193174242973328,35.19373886725479,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Ninheira,2024-12-31T00:00:00,2.819758276405675,3.174901008605957,12.594793503114737,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Nova_Belem,2024-12-31T00:00:00,0.9,1.093895435333252,21.543937259250214,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Novo_Cruzeiro,2024-12-31T00:00:00,1.7997542997542997,1.2526744604110718,-30.39747366726195,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Novorizonte,2024-12-31T00:00:00,1.333333333333333,1.5817813873291016,18.633604049682642,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Ouro_Verde_de_Minas,2024-12-31T00:00:00,2.5,2.640718460083008,5.6287384033203125,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Padre_Paraiso,2024-12-31T00:00:00,0.7212121212121212,0.7303701639175415,1.2698126440288666,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Paracatu,2024-12-31T00:00:00,2.7003236245954687,2.6599385738372803,-1.4955633610115326,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Pedra_Azul,2024-12-31T00:00:00,0.9,1.42648446559906,58.49827395545112,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Pirapora,2024-12-31T00:00:00,2.7000000000000006,3.7843985557556152,40.162909472430165,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Pote,2024-12-31T00:00:00,1.125,1.1853355169296265,5.3631570604112415,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Rio_Pardo_de_Minas,2024-12-31T00:00:00,3.064285714285715,2.934446334838867,-4.237182546050975,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Santa_Barbara_do_Monte_Verde,2024-12-31T00:00:00,1.3,1.6431729793548584,26.39792148883526,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Santa_Maria_do_Suacui,2024-12-31T00:00:00,1.333333333333333,0.916595458984375,-31.255340576171857,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Santo_Antonio_do_Retiro,2024-12-31T00:00:00,1.9666666666666672,1.5377459526062012,-21.809527833583015,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Sao_Goncalo_do_Rio_Preto,2024-12-31T00:00:00,2.5238095238095246,4.006374359130859,58.74313498443022,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Sao_Joao_do_Manteninha,2024-12-31T00:00:00,0.9,1.3144452571868896,46.04947302076551,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Sao_Joao_do_Paraiso,2024-12-31T00:00:00,3.5396226415094336,4.185850143432617,18.256960342179497,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Sao_Sebastiao_do_Maranhao,2024-12-31T00:00:00,1.380952380952381,1.2323246002197266,-10.76270136339911,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Senador_Modestino_Goncalves,2024-12-31T00:00:00,2.706666666666667,3.4955246448516846,29.144999194027736,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Setubinha,2024-12-31T00:00:00,1.020238095238095,1.2191095352172852,19.492649892942804,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Taiobeiras,2024-12-31T00:00:00,3.1206349206349207,3.5279860496520996,13.053469546328724,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Teofilo_Otoni,2024-12-31T00:00:00,1.05,1.0996975898742676,4.733103797549289,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Turmalina,2024-12-31T00:00:00,1.8507692307692305,1.5020885467529297,-18.839770956824236,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Urucuia,2024-12-31T00:00:00,1.920433996383363,2.2484185695648193,17.078669394476968,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Vargem_Grande_do_Rio_Pardo,2024-12-31T00:00:00,1.8000000000000003,2.008024215698242,11.55690087212455,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Varzea_da_Palma,2024-12-31T00:00:00,3.0,3.4149765968322754,13.832553227742514,validacao,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Abadia_dos_Dourados,2025-12-31T00:00:00,0.0,2.4765257835388184,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Acucena,2025-12-31T00:00:00,0.0,1.726494550704956,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Agua_Boa,2025-12-31T00:00:00,0.0,1.4224402904510498,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Aguas_Vermelhas,2025-12-31T00:00:00,0.0,3.1038339138031006,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Angelandia,2025-12-31T00:00:00,0.0,2.1245200634002686,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Aricanduva,2025-12-31T00:00:00,0.0,1.302097201347351,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Ataleia,2025-12-31T00:00:00,0.0,0.8565579652786255,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Bandeira,2025-12-31T00:00:00,0.0,1.2187752723693848,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Berilo,2025-12-31T00:00:00,0.0,2.054595708847046,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Berizal,2025-12-31T00:00:00,0.0,4.158535003662109,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Bonfinopolis_de_Minas,2025-12-31T00:00:00,0.0,2.9666831493377686,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Buritis,2025-12-31T00:00:00,0.0,2.997976779937744,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Buritizeiro,2025-12-31T00:00:00,0.0,2.9702024459838867,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Capelinha,2025-12-31T00:00:00,0.0,1.6874194145202637,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Carai,2025-12-31T00:00:00,0.0,1.293999195098877,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Caranaiba,2025-12-31T00:00:00,0.0,2.678504228591919,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Catuji,2025-12-31T00:00:00,0.0,1.3307057619094849,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Congonhas_do_Norte,2025-12-31T00:00:00,0.0,1.1714409589767456,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Coroaci,2025-12-31T00:00:00,0.0,2.3478426933288574,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Cuparaque,2025-12-31T00:00:00,0.0,1.272919774055481,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Diamantina,2025-12-31T00:00:00,0.0,3.399359703063965,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Formoso,2025-12-31T00:00:00,0.0,3.441256046295166,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Franciscopolis,2025-12-31T00:00:00,0.0,1.4973307847976685,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Frei_Gaspar,2025-12-31T00:00:00,0.0,1.2099488973617554,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Grao_Mogol,2025-12-31T00:00:00,0.0,1.607941746711731,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Indaiabira,2025-12-31T00:00:00,0.0,2.404356002807617,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Itabirinha,2025-12-31T00:00:00,0.0,0.9984323978424072,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Itacambira,2025-12-31T00:00:00,0.0,0.7040485143661499,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Itaipe,2025-12-31T00:00:00,0.0,0.9506897330284119,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Itamarandiba,2025-12-31T00:00:00,0.0,2.3053629398345947,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Itambacuri,2025-12-31T00:00:00,0.0,1.0297354459762573,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Jequitinhonha,2025-12-31T00:00:00,0.0,2.63916015625,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Joao_Pinheiro,2025-12-31T00:00:00,0.0,3.0870821475982666,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Jose_Goncalves_de_Minas,2025-12-31T00:00:00,0.0,1.6145895719528198,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Juiz_de_Fora,2025-12-31T00:00:00,0.0,1.3409297466278076,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Ladainha,2025-12-31T00:00:00,0.0,1.0951576232910156,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Malacacheta,2025-12-31T00:00:00,0.0,1.665936827659607,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Mantena,2025-12-31T00:00:00,0.0,1.3036022186279297,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Minas_Novas,2025-12-31T00:00:00,0.0,1.8038816452026367,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Monte_Formoso,2025-12-31T00:00:00,0.0,0.7571280002593994,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Ninheira,2025-12-31T00:00:00,0.0,2.9687507152557373,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Nova_Belem,2025-12-31T00:00:00,0.0,1.0053024291992188,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Novo_Cruzeiro,2025-12-31T00:00:00,0.0,1.5388422012329102,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Novorizonte,2025-12-31T00:00:00,0.0,1.4124847650527954,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Ouro_Verde_de_Minas,2025-12-31T00:00:00,0.0,2.5377302169799805,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Padre_Paraiso,2025-12-31T00:00:00,0.0,0.7291418313980103,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Paracatu,2025-12-31T00:00:00,0.0,2.5582175254821777,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Pedra_Azul,2025-12-31T00:00:00,0.0,1.2475961446762085,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Pirapora,2025-12-31T00:00:00,0.0,3.373021125793457,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Pote,2025-12-31T00:00:00,0.0,1.1631484031677246,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Rio_Pardo_de_Minas,2025-12-31T00:00:00,0.0,2.9502108097076416,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Santa_Barbara_do_Monte_Verde,2025-12-31T00:00:00,0.0,1.7393031120300293,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Santa_Maria_do_Suacui,2025-12-31T00:00:00,0.0,1.1357862949371338,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Santo_Antonio_do_Retiro,2025-12-31T00:00:00,0.0,1.5533208847045898,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Sao_Goncalo_do_Rio_Preto,2025-12-31T00:00:00,0.0,3.4534361362457275,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Sao_Joao_do_Manteninha,2025-12-31T00:00:00,0.0,1.1519789695739746,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Sao_Joao_do_Paraiso,2025-12-31T00:00:00,0.0,3.827282190322876,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Sao_Sebastiao_do_Maranhao,2025-12-31T00:00:00,0.0,1.319304347038269,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Senador_Modestino_Goncalves,2025-12-31T00:00:00,0.0,3.0452699661254883,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Setubinha,2025-12-31T00:00:00,0.0,1.1448460817337036,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Taiobeiras,2025-12-31T00:00:00,0.0,3.2636876106262207,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Teofilo_Otoni,2025-12-31T00:00:00,0.0,1.0717381238937378,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Turmalina,2025-12-31T00:00:00,0.0,1.6184682846069336,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Urucuia,2025-12-31T00:00:00,0.0,2.099437713623047,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Vargem_Grande_do_Rio_Pardo,2025-12-31T00:00:00,0.0,1.9400962591171265,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
V43_cluster_4_2025,Varzea_da_Palma,2025-12-31T00:00:00,0.0,3.256619691848755,0.0,teste,V43,LSTM,"./Treinos/26_11_2025_features_por_cluster/Modelos/V43_cluster_4_2025_(2025)
    Modelo LSTM treinado com dados de 2012 a 2023, validado com os dados de 2024 e testado com os dados de 2025.
    Para esse treinamento foi utilizado o dataset V43.
    O dataset foi dividido em 5 Clusters.
Nesta versão cadacluster tem seu proprio conjunto de features.

    O modelo foi treinado com os seguintes Hiperparâmetros:
    input_size: 6  (-1 significa que usou a janela de contexto maxima)
    h: 1 (horizonte de previsão)

    encoder_n_layers = 4
    learning_rate: 0.00013034723280377263
    encoder_hidden_size: 192
    decoder_layers: 1
    decoder_hidden_size: 64
    batch_size: 32
    dropout: 0.3
    weight_decay: 0.0001
    steps: 1000
    ",2025-11-27T00:09:05
